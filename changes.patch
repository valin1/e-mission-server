diff --git a/Data Generator - Demo.ipynb b/Data Generator - Demo.ipynb
new file mode 100644
index 00000000..5702fbeb
--- /dev/null
+++ b/Data Generator - Demo.ipynb	
@@ -0,0 +1,350 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# Create Fake User\n",
+    "\n",
+    "- Config object\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#Imports\n",
+    "from emission.simulation.client import EmissionFakeDataGenerator\n",
+    "from emission.simulation.fake_user import FakeUser\n",
+    "import emission.storage.timeseries.cache_series as estcs\n",
+    "import requests\n",
+    "import numpy as np\n",
+    "import pandas as pd\n",
+    "from time import sleep"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#Step1 : specify a config object for user\n",
+    "client_config = {\n",
+    "    'emission_server_base_url': 'http://localhost:8080',\n",
+    "    'register_user_endpoint': '/profile/create',\n",
+    "    'user_cache_endpoint': '/usercache/put'\n",
+    "}\n",
+    "\n",
+    "user_config = {\n",
+    "            \"email\" : 'fake_user_129',\n",
+    "    \n",
+    "            \"locations\" :\n",
+    "            [\n",
+    "               {\n",
+    "                    'label': 'home',\n",
+    "                    'coordinate': [37.77264255,-122.399714854263]\n",
+    "                },\n",
+    "\n",
+    "                {\n",
+    "                    'label': 'work',\n",
+    "                    'coordinate': [37.42870635,-122.140926605802]\n",
+    "                },\n",
+    "                {\n",
+    "                    'label': 'family',\n",
+    "                    'coordinate': [37.87119, -122.27388]\n",
+    "                }\n",
+    "            ],\n",
+    "            \"transition_probabilities\":\n",
+    "            [\n",
+    "                np.random.dirichlet(np.ones(3), size=1)[0],\n",
+    "                np.random.dirichlet(np.ones(3), size=1)[0],\n",
+    "                np.random.dirichlet(np.ones(3), size=1)[0]\n",
+    "            ],\n",
+    "    \n",
+    "            \"modes\" : \n",
+    "            {\n",
+    "                \"CAR\" : [['home', 'family']],\n",
+    "                \"TRANSIT\" : [['home', 'work'], ['work', 'home']]  \n",
+    "            },\n",
+    "\n",
+    "            \"default_mode\": \"CAR\",\n",
+    "            \"initial_state\" : \"home\",\n",
+    "            \"radius\" : \".1\"\n",
+    "        }\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "np.random.dirichlet(np.ones(3), size=1)[0]"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "client = EmissionFakeDataGenerator(client_config)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "fake_user = client.create_fake_user(user_config)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Simulate User Behavior"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "measurements = []\n",
+    "for _ in range(4):\n",
+    "    \"\"\"\n",
+    "    \n",
+    "    \"\"\"\n",
+    "    temp = fake_user.take_trip()\n",
+    "    print('# of location measurements:', len(temp))\n",
+    "    measurements.append(temp)\n",
+    "    #try:\n",
+    "        #respons = requests.post('server_address', payload={'data':measurements})\n",
+    "    #except:\n",
+    "        \n",
+    "    #sleep(2)\n",
+    "\n",
+    "print('Path:',fake_user._path)\n",
+    "#Run pipeline\n"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# Push data to server"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "len(fake_user._measurements_cache)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "fake_user.sync_data_to_server()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "len(fake_user._measurements_cache)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "location_data = [entry.data for sublist in measurements for entry in sublist if entry.metadata.key == 'background/filtered_location']\n",
+    "#meta_data = [entry.metadata for sublist in measurements for entry in sublist if entry.metadata.key == 'background/filtered_location']"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "pd.DataFrame(location_data)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Run pipeline manually \n",
+    "#(tsdb_count, ucdb_count) = estcs.insert_entries(override_uuid, measurements)\n",
+    "#print(\"Finished loading %d entries into the usercache and %d entries into the timeseries\" %\n",
+    "#(ucdb_count, tsdb_count))"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Run intake pipeline"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "email = fake_user._email"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "!source activate emission\n",
+    "!./e-mission-py.bash bin/debug/intake_single_user.py -e 'fake_user_129'"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {
+    "collapsed": true
+   },
+   "source": [
+    "## Display data\n",
+    "- Show trip entries\n",
+    "- Show trips on the map "
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from uuid import UUID\n",
+    "import arrow\n",
+    "fake_user_id = UUID(fake_user._uuid)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import emission.storage.timeseries.abstract_timeseries as esta\n",
+    "import emission.storage.decorations.analysis_timeseries_queries as esda\n",
+    "import emission.core.wrapper.entry as ecwe\n",
+    "import emission.storage.decorations.trip_queries as esdt\n",
+    "import emission.storage.timeseries.timequery as estt"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "print(fake_user_id)\n",
+    "ts = esta.TimeSeries.get_time_series(fake_user_id)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Raw trips\n",
+    "rt_df = ts.get_data_df('segmentation/raw_trip', time_query=None)\n",
+    "raw_trips = rt_df[[\"start_loc\", \"end_loc\", \"start_ts\", \"end_ts\"]]\n",
+    "raw_trips['start_time'] = raw_trips[\"start_ts\"].apply(lambda x : arrow.get(x).format())\n",
+    "raw_trips['end_time'] = raw_trips[\"end_ts\"].apply(lambda x : arrow.get(x).format())\n",
+    "raw_trips['end_coord'] = raw_trips[\"end_loc\"].apply(lambda x : dict(x)['coordinates'])\n",
+    "raw_trips['start_coord'] = raw_trips[\"start_loc\"].apply(lambda x : dict(x)['coordinates'])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "raw_trips[['start_time', 'end_time',\"start_coord\", \"end_coord\"]]"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# Get all cleaned trips for the first user\n",
+    "entry_it = ts.find_entries([\"analysis/cleaned_trip\"], time_query=None)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "for ct in entry_it:\n",
+    "    cte = ecwe.Entry(ct)\n",
+    "    print(\"=== Trip:\", cte.data.start_loc, \"->\", cte.data.end_loc)\n",
+    "    section_it = esdt.get_sections_for_trip(\"analysis/cleaned_section\", fake_user_id, cte.get_id())\n",
+    "    for sec in section_it:\n",
+    "        print(\"  --- Section:\", sec.data.start_loc, \"->\", sec.data.end_loc, \" on \", sec.data.sensed_mode)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  }
+ ],
+ "metadata": {
+  "kernelspec": {
+   "display_name": "Python 2",
+   "language": "python",
+   "name": "python2"
+  },
+  "language_info": {
+   "codemirror_mode": {
+    "name": "ipython",
+    "version": 2
+   },
+   "file_extension": ".py",
+   "mimetype": "text/x-python",
+   "name": "python",
+   "nbconvert_exporter": "python",
+   "pygments_lexer": "ipython2",
+   "version": "2.7.15"
+  }
+ },
+ "nbformat": 4,
+ "nbformat_minor": 2
+}
diff --git a/README.md b/README.md
index 954e6f87..6086b0f3 100644
--- a/README.md
+++ b/README.md
@@ -13,7 +13,7 @@ repo](https://github.com/amplab/e-mission-phone)
 The current build status is:
 [![Build Status](https://amplab.cs.berkeley.edu/jenkins/buildStatus/icon?job=e-mission-server)](https://amplab.cs.berkeley.edu/jenkins/view/E-Mission/job/e-mission-server/)
 
-[![Join the chat at https://gitter.im/e-mission/e-mission-server](https://badges.gitter.im/e-mission/e-mission-server.svg)](https://gitter.im/e-mission/e-mission-server?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)
+**Issues:** Since this repository is part of a larger project, all issues are tracked [in the central docs repository](https://github.com/e-mission/e-mission-docs/issues). If you have a question, [as suggested by the open source guide](https://opensource.guide/how-to-contribute/#communicating-effectively), please file an issue instead of sending an email. Since issues are public, other contributors can try to answer the question and benefit from the answer.
 
 The backend in turn consists of two parts - a summary of their code structure is shown below.
 -![][Python_Structure]
@@ -21,170 +21,28 @@ The webapp supports a REST API, and accesses data from the database to fulfill
 the queries.  A set of background scripts pull the data from external sources, and
 preprocessing results ensures reasonable performance.
 
-The installation instructions below are generally targeted towards OSX and \*nix shells such as bash. If you want to use Windows, we recomend using PowerShell (https://technet.microsoft.com/en-us/scriptcenter/dd742419), which provides similarly rich commands. If you really want to use the Command Prompt, most commands should work, but you may need to convert `/` -> `\` to make the commands work.
+## Installation: ##
+----------
+- For **deployers** (i.e. if you want to primarily *use* the system as opposed to modify/develop it, the [docker installation](https://github.com/e-mission/e-mission-docker) is probably the easiest way to get started.
+- For **builders** (i.e. if you want to write new scripts or modify existing scripts) the [manual install](https://github.com/e-mission/e-mission-docs/blob/master/docs/e-mission-server/manual_install.md) will make it easier to edit files directly on your local filesystem. Make sure to use a POSIX-compliant CLI; you may want to look into [gitbash](https://openhatch.org/missions/windows-setup/install-git-bash) or similar on Windows.
 
 ## Additional Documentation: ##
 ----------
 Additional documentation has been moved to its own repository [e-mission-docs](https://github.com/e-mission/e-mission-docs). Specific e-mission-server additional documentation can be found here:
 https://github.com/e-mission/e-mission-docs/tree/master/docs/e-mission-server
 
-
-## Install/update: ##
--------------------
-
-### Installation ###
-is as simple as cloning the github repository.
-
-- If you do not plan to make changes to the code, clone the master repository.
-
-  ```
-  $ git clone https://github.com/e-mission/e-mission-server.git
-  ```
-
-- If you might make changes or develop new features, fork (https://help.github.com/articles/fork-a-repo/) and clone your fork.
-
-  ```
-  $ git clone https://github.com/<username>/e-mission-server.git
-  ```
-
-### Update ###
-is as simple as pulling new changes.
-
-- If you are working off the master repository
-
-  ```
-  $ git pull origin master
-  ```
-
-- If you are working off your fork, you will need to sync your fork with the main repository (https://help.github.com/articles/syncing-a-fork/) and then pull from your fork.
-
-  ```
-  $ git pull origin master
-  ```
-
-## Dependencies: ##
+## Deployment: ##
 -------------------
-
-### Database: ###
-1. Install [Mongodb](http://www.mongodb.org/), version 3.4
-  2. *Windows*: mongodb appears to be installed as a service on Windows devices and it starts automatically on reboot
-  3. *OSX*: You want to install homebrew and then use homebrew to install mongodb. Follow these instruction on how to do so ---> (https://docs.mongodb.com/v3.4/tutorial/install-mongodb-on-ubuntu/)
-  4. *Ubuntu*: http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/
-
-2. Start it at the default port
-
-     `$ mongod`
-
-### Python distribution ###
-We will use a distribution of python that is optimized for scientific
-computing. The [anaconda](https://store.continuum.io/cshop/anaconda/)
-distribution is available for a wide variety of platforms and includes the
-python scientific computing libraries (numpy/scipy/scikit-learn) along with
-native implementations for performance. Using the distribution avoids native
-library inconsistencies between versions.
-
-The distribution also includes its own version of pip, and a separate environment
-management tool called 'conda'.
-
-The distribution also includes an environment management tool called 'conda'. We will set up a separate `emission`
-environment within anaconda to avoid conflicts with other applications.
-
-- Install the anaconda distribution (https://www.anaconda.com/download). Any
-  installer should be fine - setting up the `emission` environment will
-  automatically choose the correct version of python. Since all required
-  packages will be installed using the environment, if you are comfortable with
-  the command line, you can also download the minimalist `miniconda` installer
-  https://conda.io/miniconda.html
-
-- Setup the `emission` environment.
-
-  ```
-  $ source setup/setup.sh
-  ```
-
-- Verify that you are in the right environment - your prompt should start with
-  `(emission)` and the `emission` environment should be starred.
-
-  ```
-  (emission) ...$ conda env list
-  # conda environments:
-  #
-  aws                      /..../anaconda/envs/aws
-  emission              *  /..../anaconda/envs/emission
-  firebase                 /..../anaconda/envs/firebase
-  py27                     /..../anaconda/envs/py27
-  py36                     /..../anaconda/envs/py36
-  xbos                     /..../anaconda/envs/xbos
-  root                     /..../anaconda
-  ```
-
-- Remember to re-run the setup script every time you pull from the main repository because the dependencies may have changed.
-
-  ```
-  $ source setup/setup.sh
-  ```
-
-- When you are done working with e-mission, you can cleanup the environment and then just delete the entire directory.
-
-  ```
-  $ source setup/teardown.sh
-  $ cd ..
-  $ rm -rf e-mission-server
-  ```
-
-### Javascript dependencies ###
-
-Note: It is required only if the user needs a  web interface for the server. Otherwise one can do without it as well.
-
-Tip: Run "bower install" instead if you are prompted password for 'https://github.com' after running "bower update".
-
-    $ cd webapp
-    $ bower update
+- If you just want to run the server, you can use [our docker image](https://github.com/e-mission/e-mission-docker).
+- Alternatively, you can follow the [manual installation instructions](https://github.com/e-mission/e-mission-docs/blob/master/docs/e-mission-server/manual_install.md) to pull from the repo to the server, change the config files slightly and just not change any code.
 
 ## Development: ##
 -------------------
-In order to test out changes to the webapp, you should make the changes locally, test them and then push. Then, deployment is as simple as pulling from the repo to the real server and changing the config files slightly.
-
-Here are the steps for doing this:
-
-1. On OSX, start the database  (Note: mongodb appears to be installed as a service on Windows devices and it starts automatically on reboot). 
-
-        $ mongod
-        2018-05-23T11:06:07.576-0700 I CONTROL  [initandlisten] MongoDB starting : pid=60899 port=27017 dbpath=/data/db 64-bit ...
-        2018-05-23T11:06:07.576-0700 I CONTROL  [initandlisten] db version v3.6.2
-        ...
-        2018-05-23T11:06:08.420-0700 I FTDC     [initandlisten] Initializing full-time diagnostic data capture with directory '/data/db/diagnostic.data'
-
-1. **Optional** Copy configuration files. The files in `conf` can be used to customize the app with custom authentication options or enable external features such as place lookup and the game integration. Look at the samples in `conf/*`, copy them over and modify as necessary - e.g.
-
-        $ find conf -name \*.sample
-        # For the location -> name reverse lookup. Client will lookup if not populated.
-        $ cp conf/net/ext_service/nominatim.json.sample conf/net/ext_service/nominatim.json
-
-1. Start the server
-
-        $ ./e-mission-py.bash emission/net/api/cfc_webapp.py
-        storage not configured, falling back to sample, default configuration
-        Connecting to database URL localhost
-        analysis.debug.conf.json not configured, falling back to sample, default configuration
-        Finished configuring logging for <RootLogger root (WARNING)>
-        Replaced json_dumps in plugin with the one from bson
-        Changing bt.json_loads from <function <lambda> at 0x10f5fdb70> to <function loads at 0x1104b6ae8>
-        Running with HTTPS turned OFF - use a reverse proxy on production
-        Bottle v0.13-dev server starting up (using CherootServer())...
-        Listening on http://0.0.0.0:8080/
-        Hit Ctrl-C to quit.
-
-1. Test your connection to the server
-  * Using a web browser, go to [http://localhost:8080](http://localhost:8080)
-  * Using the iOS emulator, connect to [http://localhost:8080](http://localhost:8080)
-  * Using the android emulator:
-    * change `server.host` in `conf/net/api/webserver.conf` to 0.0.0.0, and 
-    * connect the app to the special IP for the current host in the android emulator - [10.0.2.2](https://developer.android.com/tools/devices/emulator.html#networkaddresses)
+In order to test out changes to the webapp, you should make the changes locally, test them and then push the tested changes to a repository. Note that if the changes are to the server code, you need to restart the server after making changes.
 
 ### Loading test data ###
-
-You may also want to load some test data.
+-------------------
+You may also want to load some test data. Note that for the docker install, you will need to run these scripts from the docker image after [opening a shell](https://stackoverflow.com/a/26496875)
 
 #### Quick start ####
 
@@ -248,9 +106,6 @@ $ ./e-mission-py.bash bin/debug/load_timeline_for_day_and_user.py -n /tmp/data-c
             $ ./e-mission-py.bash bin/debug/load_timeline_for_day_and_user.py /tmp/data-collection-eval/results_dec_2015/ucb.sdb.android.1/timeseries/active_day_2.2015-11-27 shankari@eecs.berkeley.edu
 ```        
 
-
-
-
 ### Creating fake user data ###
 
 You may need a larger or more diverse set of data than the given test data supplies.
diff --git a/bin/check_for_yelp_suggestions.py b/bin/check_for_yelp_suggestions.py
index 33a757bf..46efd64e 100644
--- a/bin/check_for_yelp_suggestions.py
+++ b/bin/check_for_yelp_suggestions.py
@@ -19,20 +19,33 @@ import emission.core.get_database as edb
 from uuid import UUID
 
 
-def handle_insert(tripDict, tripID, collection, uuid):
-    if tripDict == None:
-        collection.insert_one({'uuid': uuid, 'trip_id': tripID})
-        return True
-    else:
-        if tripDict['trip_id'] != tripID:
-            collection.update_one({'uuid': uuid}, {'$set': {'trip_id' : tripID}})
-            return True
-        else:
-            return False
-
 def calculate_single_yelp_suggestion(UUID):
 	logging.debug("About to calculate single suggestion for %s" % UUID)
 	yelp_suggestion_trips = edb.get_yelp_db()
-	return_obj = {'message': "Good job walking and biking! No suggestion to show.",
-    'savings': "0", 'method' : 'bike'}
     all_users = pd.DataFrame()
+    user_id = UUID
+    #TO ADDRESS PREVIOUS PULL REQUEST COMMENTS, have not yet hooked up the database with the suggestion trips
+    time_series = esta.TimeSeries.get_time_series(user_id)
+    cleaned_trips = time_series.get_data_df("analysis/cleaned_trip", time_query = None)
+    num_cleaned_trips = len(cleaned_trips)
+    for i in range(num_cleaned_trips-1, -1, -1):
+        if cleaned_trips.iloc[i]["end_ts"] - cleaned_trips.iloc[i]["start_ts"] < 5*60:
+            continue
+        distance_in_miles = cleaned_trips.iloc[i]["distance"]*0.000621371
+        trip_id = cleaned_trips.iloc[i]["trip_id"]
+        logging.debug("Considering trip from %s -> %s" % (cleaned_trips.iloc[i]["start_fmt_time"], cleaned_trips.iloc[i]["end_fmt_time"]))
+        #Still need to add the database to log suggestion trips
+
+def push_to_user(uuid_list, message):
+    logging.debug("About to send notifications to: %s users" % len(uuid_list))
+    json_data = {
+        "title": "GreenTrip Notification",
+        "message": message
+    }
+    logging.debug(uuid_list)
+    response = pnu.send_visible_notification_to_users(uuid_list,
+                                                        json_data["title"],
+                                                        json_data["message"],
+                                                        json_data,
+                                                        dev = False)
+    pnu.display_response(response)
\ No newline at end of file
diff --git a/bin/debug/common.py b/bin/debug/common.py
index af186d8e..044ebf7d 100644
--- a/bin/debug/common.py
+++ b/bin/debug/common.py
@@ -40,3 +40,33 @@ def read_files_with_prefix(prefix):
     logging.info("Found %d matching files for prefix %s" % (len(matching_files), prefix))
     logging.info("files are %s ... %s" % (matching_files[0:5], matching_files[-5:-1]))
     return matching_files
+
+def purge_entries_for_user(curr_uuid, is_purge_state, db_array=None):
+    logging.info("For uuid = %s, deleting entries from the timeseries" % curr_uuid)
+    if db_array is not None:
+        [ts_db, ats_db, udb, psdb] = db_array
+        logging.debug("db_array passed in with databases %s" % db_array)
+    else:
+        import emission.core.get_database as edb
+
+        ts_db = edb.get_timeseries_db()
+        ats_db = edb.get_analysis_timeseries_db()
+        udb = edb.get_uuid_db()
+        psdb = edb.get_pipeline_state_db()
+        logging.debug("db_array not passed in, looking up databases")
+
+    timeseries_del_result = ts_db.remove({"user_id": curr_uuid})
+    logging.info("result = %s" % timeseries_del_result)
+
+    logging.info("For uuid = %s, deleting entries from the analysis_timeseries" % curr_uuid)
+    analysis_timeseries_del_result = ats_db.remove({"user_id": curr_uuid})
+    logging.info("result = %s" % analysis_timeseries_del_result)
+
+    logging.info("For uuid %s, deleting entries from the user_db" % curr_uuid)
+    user_db_del_result = udb.remove({"uuid": curr_uuid})
+    logging.info("result = %s" % user_db_del_result)
+
+    if is_purge_state:
+        logging.info("For uuid %s, deleting entries from the pipeline_state_db" % curr_uuid)
+        psdb_del_result = psdb.remove({"user_id": curr_uuid})
+        logging.info("result = %s" % psdb_del_result)
diff --git a/bin/debug/purge_multi_timeline_for_range.py b/bin/debug/purge_multi_timeline_for_range.py
index c58f394b..88b6f134 100644
--- a/bin/debug/purge_multi_timeline_for_range.py
+++ b/bin/debug/purge_multi_timeline_for_range.py
@@ -41,6 +41,7 @@ if __name__ == '__main__':
     ats_db = edb.get_analysis_timeseries_db()
     udb = edb.get_uuid_db()
     psdb = edb.get_pipeline_state_db()
+    db_array = [ts_db, ats_db, udb, psdb]
 
     for i, filename in enumerate(sel_file_list):
         if "pipelinestate" in filename:
@@ -60,19 +61,4 @@ if __name__ == '__main__':
                 (len(curr_uuid_list), curr_uuid_list, common.split_user_id(filename)))
         curr_uuid = curr_uuid_list[0]
         if not args.info_only:
-            logging.info("For uuid = %s, deleting entries from the timeseries" % curr_uuid)
-            timeseries_del_result = ts_db.remove({"user_id": curr_uuid})
-            logging.info("result = %s" % timeseries_del_result)
-
-            logging.info("For uuid = %s, deleting entries from the analysis_timeseries" % curr_uuid)
-            analysis_timeseries_del_result = ats_db.remove({"user_id": curr_uuid})
-            logging.info("result = %s" % analysis_timeseries_del_result)
-
-            logging.info("For uuid %s, deleting entries from the user_db" % curr_uuid)
-            user_db_del_result = udb.remove({"uuid": curr_uuid})
-            logging.info("result = %s" % user_db_del_result)
-
-            if args.pipeline_purge:
-                logging.info("For uuid %s, deleting entries from the pipeline_state_db" % curr_uuid)
-                psdb_del_result = psdb.remove({"user_id": curr_uuid})
-                logging.info("result = %s" % psdb_del_result)
+            common.purge_entries_for_user(curr_uuid, args.pipeline_purge, db_array)
diff --git a/bin/debug/purge_user.py b/bin/debug/purge_user.py
new file mode 100644
index 00000000..122fcd9f
--- /dev/null
+++ b/bin/debug/purge_user.py
@@ -0,0 +1,24 @@
+import logging
+import common
+import argparse
+import emission.core.wrapper.user as ecwu
+
+if __name__ == '__main__':
+    logging.basicConfig(level=logging.DEBUG)
+
+    parser = argparse.ArgumentParser(prog="purge_user")
+    group = parser.add_mutually_exclusive_group(required=True)
+    group.add_argument("-e", "--user_email")
+    group.add_argument("-u", "--user_uuid")
+
+    parser.add_argument("-p", "--pipeline-purge", default=False, action='store_true',
+        help="purge the pipeline state as well")
+
+    args = parser.parse_args()
+
+    if args.user_uuid:
+        sel_uuid = uuid.UUID(args.user_uuid)
+    else:
+        sel_uuid = ecwu.User.fromEmail(args.user_email).uuid
+
+    common.purge_entries_for_user(sel_uuid, args.pipeline_purge)
diff --git a/bin/delete_user.py b/bin/delete_user.py
deleted file mode 100644
index cccad37f..00000000
--- a/bin/delete_user.py
+++ /dev/null
@@ -1,26 +0,0 @@
-from __future__ import print_function
-from __future__ import unicode_literals
-from __future__ import division
-from __future__ import absolute_import
-from future import standard_library
-standard_library.install_aliases()
-from builtins import *
-from pymongo import MongoClient
-from get_database import get_uuid_db, get_profile_db, get_moves_db
-from uuid import UUID
-from dao.user import User
-from main import auth
-import sys
-
-def deleteUser(userEmail):
-  deluuid = User.unregister(userEmail)
-  auth.deleteAllTokens(deluuid)
-
-if __name__ == '__main__':
-  if len(sys.argv) != 2:
-    print("USAGE: delete_user.py <userEmail>")
-    exit(1)
-
-  userEmail = sys.argv[1]
-  print("Deleting user %s" % userEmail)
-  deleteUser(sys.argv[1])
diff --git a/conf/log/geojson.conf b/conf/log/geojson.conf
new file mode 100644
index 00000000..45f4d949
--- /dev/null
+++ b/conf/log/geojson.conf
@@ -0,0 +1,40 @@
+{
+    "handlers": {
+        "errors": {
+            "backupCount": 2, 
+            "mode": "a", 
+            "level": "ERROR", 
+            "formatter": "detailed", 
+            "class": "logging.handlers.RotatingFileHandler", 
+            "maxBytes": 1073741824, 
+            "filename": "/var/tmp/geojson-errors.log"
+        }, 
+        "console": {
+            "class": "logging.StreamHandler", 
+            "level": "WARNING"
+        }, 
+        "file": {
+            "backupCount": 8, 
+            "filename": "/var/tmp/geojson.log", 
+            "maxBytes": 1073741824, 
+            "mode": "a", 
+            "formatter": "detailed", 
+            "class": "logging.handlers.RotatingFileHandler"
+        }
+    }, 
+    "version": 1, 
+    "root": {
+        "handlers": [
+            "console", 
+            "file", 
+            "errors"
+        ], 
+        "level": "DEBUG"
+    }, 
+    "formatters": {
+        "detailed": {
+            "class": "logging.Formatter", 
+            "format": "%(asctime)s:%(levelname)s:%(thread)d:%(message)s"
+        }
+    }
+}
diff --git a/conf/net/api/webserver.conf.docker.sample b/conf/net/api/webserver.conf.docker.sample
new file mode 100644
index 00000000..faf7caaa
--- /dev/null
+++ b/conf/net/api/webserver.conf.docker.sample
@@ -0,0 +1,16 @@
+{
+  "paths" : {
+    "static_path" : "webapp/www/",
+    "python_path" : "main",
+    "log_base_dir" : ".",
+    "log_file" : "debug.log"
+  },
+  "__comment" : "Fill this in for the production server. port will almost certainly be 80 or 443. For iOS, using localhost allows you to test without an internet connection. For AWS and android, make sure that the host 0.0.0.0, localhost does not seem to work",
+  "server" : {
+    "host" : "0.0.0.0",
+    "port" : "8080",
+    "__comment": "1 hour = 60 min = 60 * 60 sec",
+    "timeout" : "3600",
+    "auth": "skip"
+  }
+}
diff --git a/conf/net/ext_service/googlemaps.json.sample b/conf/net/ext_service/googlemaps.json.sample
index af22012e..ea92390c 100644
--- a/conf/net/ext_service/googlemaps.json.sample
+++ b/conf/net/ext_service/googlemaps.json.sample
@@ -1,3 +1,6 @@
 {
-	"api_key" : "Get from https://developers.google.com/maps/"
-}
\ No newline at end of file
+	"access_token" : "Get from https://developers.google.com/maps/"
+	"backup_access_token" : "Get from https://developers.google.com/maps/"
+    "nearby_base_url": "https://maps.googleapis.com/maps/api/place/nearbysearch/json?",
+    "search_base_url": "https://maps.googleapis.com/maps/api/geocode/json?"
+}
diff --git a/conf/net/ext_service/yelpfusion.json.sample b/conf/net/ext_service/yelpfusion.json.sample
new file mode 100644
index 00000000..19b7dab9
--- /dev/null
+++ b/conf/net/ext_service/yelpfusion.json.sample
@@ -0,0 +1,13 @@
+{
+    "api_key" : "Get from https://www.yelp.com/developers/documentation/v3",
+    "api_host" : "https://api.yelp.com",
+    "search_path" : "/v3/businesses/search",
+    "business_path" : "/v3/businesses/",
+    "search_limit": 3,
+    "map_quest_key": "Get from https://developer.mapquest.com/",
+    "zip_code_key" : "Get from https://www.zipcodeapi.com/Register",
+    "backup_zip_code_key" : "Also get from https://www.zipcodeapi.com/Register",
+    "zip_code_host": "Get from https://www.zipcodeapi.com/",
+    "zip_code_format": "Get from https://www.zipcodeapi.com/",
+    "zip_code_degree": "Get from https://www.zipcodeapi.com/"
+}
diff --git a/conf/storage/db.conf.docker.sample b/conf/storage/db.conf.docker.sample
new file mode 100644
index 00000000..dfd75cb4
--- /dev/null
+++ b/conf/storage/db.conf.docker.sample
@@ -0,0 +1,5 @@
+{
+    "timeseries": {
+        "url": "e-mission-mongo-1"
+    }
+}
diff --git a/docker/Dockerfile b/docker/Dockerfile
new file mode 100644
index 00000000..1a32140e
--- /dev/null
+++ b/docker/Dockerfile
@@ -0,0 +1,45 @@
+# python 3
+FROM continuumio/miniconda3
+
+MAINTAINER K. Shankari (shankari@eecs.berkeley.edu)
+# set working directory
+WORKDIR /usr/src/app
+
+# clone from repo
+RUN git clone https://github.com/e-mission/e-mission-server.git .
+
+# setup python environment.
+RUN conda env update --name emission --file setup/environment36.yml
+RUN /bin/bash -c "source activate emission; pip install six --upgrade"
+
+# install nodejs, npm and bower
+RUN apt-get update
+RUN apt-get install -y build-essential
+RUN curl -sL https://deb.nodesource.com/setup_8.x | bash -
+RUN apt-get -y install nodejs
+RUN npm install -g bower
+WORKDIR /usr/src/app/webapp
+RUN bower update --allow-root
+WORKDIR /usr/src/app
+
+# install nano and vim for editing
+RUN apt-get -y install nano vim
+
+# cleanup
+RUN apt-get -y remove --purge build-essential
+RUN apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*
+
+#declare environment variables
+ENV DB_HOST=''
+ENV WEB_SERVER_HOST=''
+
+#add start script.
+# this is a redundant workdir setting, but it doesn't harm anything and might
+# be useful if the other one is removed for some reason
+WORKDIR /usr/src/app
+ADD start_script.sh /usr/src/app/start_script.sh
+RUN chmod u+x /usr/src/app/start_script.sh
+
+EXPOSE 8080
+
+CMD ["/bin/bash", "/usr/src/app/start_script.sh"]
diff --git a/docker/README.md b/docker/README.md
new file mode 100644
index 00000000..c327a758
--- /dev/null
+++ b/docker/README.md
@@ -0,0 +1,61 @@
+# Docker usage instructions
+This project is now published on dockerhub!
+https://hub.docker.com/r/emission/e-mission-server/
+
+Both the standard Dockerfile and the docker-compose.yml are in this directory (docker) and should be specified using `-f`. Once we split out the docker stuff into a separate repository, this should become simpler.
+
+Instructions on re-building the image are [in the build instructions](#Docker_Build_Instructions)
+
+1. (optional) If you want to use `swarm` for container management, initialize Swarm
+    ```
+   docker swarm init 
+   ``` 
+   For more details on how to do manage a swarm please see the official documentation: https://docs.docker.com/get-started/part4/ 
+
+
+2. Configure the compose file. 
+    * Update the port mappings and environment variables if necessary. 
+    For more details on how to configure compose files please see the official documentation: https://docs.docker.com/compose/compose-file/#service-configuration-reference 
+
+3. Deploy directly
+
+   ```
+    docker-compose -f docker/docker-compose.yml up -d
+   ```
+
+    or to swarm if you initalized it in step 1
+
+   ```
+    docker stack deploy -c docker-compose.yml emission
+   ```
+   There are many ways you can manage your deployment. Again, please see the official documentation for more details: https://docs.docker.com/get-started/part4/
+
+4. Test your connection to the server
+  * Using a web browser, go to [http://localhost:8080](http://localhost:8080)
+  * Using safari in the iOS emulator, go to [http://localhost:8080](http://localhost:8080)
+  * Using chrome in the android emulator, go to [http://10.0.2.2:8080](http://10.0.2.2:8080) 
+    This is the [special IP for the current host in the android emulator](https://developer.android.com/tools/devices/emulator.html#networkaddresses)
+
+### Docker Build Instructions
+#### emission-server image
+
+1. Build local docker image
+
+   ```
+   docker build -f docker/Dockerfile -t emission/e-mission-server:latest ./docker
+   ```
+
+1. Tag the release (make sure you are in the owners group for emission, or
+    replace emission by your own namespace)
+
+   ```
+   docker tag emission/e-mission-server:latest emission/e-mission-server:<version>
+   ```
+   
+1. Push the release 
+
+   ```
+   docker login
+   docker push emission/e-mission-server:<version>
+   docker push emission/e-mission-server:latest
+   ```
diff --git a/docker/docker-compose.yml b/docker/docker-compose.yml
new file mode 100644
index 00000000..3b020dee
--- /dev/null
+++ b/docker/docker-compose.yml
@@ -0,0 +1,42 @@
+version: "3"
+services:
+  web-server:
+    image: emission/e-mission-server:latest
+    depends_on:
+      - db
+    environment:
+      - DB_HOST=db
+      - WEB_SERVER_HOST=0.0.0.0
+    deploy:
+      replicas: 1
+      restart_policy:
+        condition: on-failure
+    ports:
+      #This is a default port mapping. In production you might want to use 80:8080,
+      - "8080:8080"
+    networks:
+      - emission
+  db:
+    image: mongo:latest
+    deploy:
+      replicas: 1
+      restart_policy:
+        condition: on-failure
+    ports:
+      #This port binding allows you to access the database server outside the host machine. Remove this is you don't need this
+      #functionality
+      - "27017:27017"
+
+    #Volumes is the preferred way to persist data generated by a container. In this case we use a volume to persist the contents
+    #of the data base. Learn more about how to use volumes here: https://docs.docker.com/storage/volumes/
+    # And learn how to configure volumes in your compose file here: https://docs.docker.com/compose/compose-file/#volume-configuration-reference
+    volumes:
+      - mongo-data:/data/db
+    networks:
+       - emission
+
+networks:
+  emission:
+
+volumes:
+  mongo-data:
diff --git a/docker/start_script.sh b/docker/start_script.sh
new file mode 100755
index 00000000..c7217c2d
--- /dev/null
+++ b/docker/start_script.sh
@@ -0,0 +1,29 @@
+#!/usr/bin/env bash
+#Configure web server
+
+#set database URL using environment variable
+echo ${DB_HOST}
+if [ -z ${DB_HOST} ] ; then
+    local_host=`hostname -i`
+    sed "s_localhost_${local_host}_" conf/storage/db.conf.sample > conf/storage/db.conf
+else
+    sed "s_localhost_${DB_HOST}_" conf/storage/db.conf.sample > conf/storage/db.conf
+fi
+cat conf/storage/db.conf
+
+#set Web Server host using environment variable
+echo ${WEB_SERVER_HOST}
+if [ -z ${WEB_SERVER_HOST}} ] ; then
+    local_host=`hostname -i`
+    sed "s_localhost_${local_host}_" conf/net/api/webserver.conf.sample > conf/net/api/webserver.conf
+else
+    sed "s_localhost_${WEB_SERVER_HOST}_" conf/net/api/webserver.conf.sample > conf/net/api/webserver.conf
+fi
+cat conf/net/api/webserver.conf
+
+#TODO: start cron jobs
+# change python environment
+source activate emission
+
+# launch the webapp
+./e-mission-py.bash emission/net/api/cfc_webapp.py
diff --git a/e-mission-locust.bash b/e-mission-locust.bash
new file mode 100755
index 00000000..45a87869
--- /dev/null
+++ b/e-mission-locust.bash
@@ -0,0 +1,8 @@
+#
+# Simple script to ensure that the pythonpath is set correctly before executing the command.
+# As we increase the number of directories that we need, this becomes useful.
+# Maybe we can restructure the code to avoid this, but this is a useful placeholder until then.
+
+# Make sure that the python here is the anaconda python if that is not the one in the path
+
+PYTHONPATH=. locust $*
diff --git a/emission/analysis/plotting/leaflet_osm/ipython_helper.py b/emission/analysis/plotting/leaflet_osm/ipython_helper.py
index 8e8e3939..c4012552 100644
--- a/emission/analysis/plotting/leaflet_osm/ipython_helper.py
+++ b/emission/analysis/plotting/leaflet_osm/ipython_helper.py
@@ -10,18 +10,19 @@ standard_library.install_aliases()
 from builtins import str
 from builtins import range
 from builtins import *
-import IPython.display as idisp
-import html as hgen
+
+import branca.element as bre
  
-def inline_map(map):
+def inline_map(m):
     """
     Embeds the HTML source of the map directly into the IPython notebook.
     
     This method will not work if the map depends on any files (json data). Also this uses
     the HTML5 srcdoc attribute, which may not be supported in all browsers.
     """
-    map._build_map()
-    return idisp.HTML('<iframe srcdoc="{srcdoc}" style="width: 100%; height: 510px; border: none"></iframe>'.format(srcdoc=map.HTML.replace('"', '&quot;')))
+    fig = bre.Figure()
+    fig.add_subplot(1,1,1).add_child(m)
+    return fig
 
 def inline_maps(map_list):
     """
@@ -34,24 +35,9 @@ def inline_maps(map_list):
     nRows: Number of rows
     nCols: Number of columns
     """
-    nRows = len(map_list)
-    # nCols = max([len(row) for row in map_list])
-    hb = hgen.HTML()
-    t = hb.table(width="100%")
-    for r in range(nRows):
-        row = t.tr
-        for c in range(len(map_list[r])):
-            currMap = map_list[r][c]
-            currMap._build_map()
-            row.td('<iframe srcdoc="{srcdoc}" style="width: 100%; height: 510px; border: none"></iframe>'.format(srcdoc=currMap.HTML.replace('"', '&quot;')))
-    return idisp.HTML('<iframe srcdoc="{srcdoc}" style="width: 100%; height: {ht}px; border: none"></iframe>'.format(srcdoc=str(t).replace('"', '&quot;'), ht=510*nRows))
- 
-def embed_map(map, path="map.html"):
-    """
-    Embeds a linked iframe to the map into the IPython notebook.
-    
-    Note: this method will not capture the source of the map into the notebook.
-    This method should work for all maps (as long as they use relative urls).
-    """
-    map.create_map(path=path)
-    return idisp.IFrame(src="files/{path}".format(path=path), width="100%", height="510")
+    ncols = 2
+    nrows = (len(map_list)/ncols) + 1
+    fig = bre.Figure()
+    for i, m in enumerate(map_list):
+        fig.add_subplot(nrows,ncols,i+1).add_child(m)
+    return fig
diff --git a/emission/analysis/result/metrics/simple_metrics.py b/emission/analysis/result/metrics/simple_metrics.py
index 6e8a33b3..53b8304d 100644
--- a/emission/analysis/result/metrics/simple_metrics.py
+++ b/emission/analysis/result/metrics/simple_metrics.py
@@ -27,13 +27,13 @@ def get_count(mode_section_grouped_df):
 def get_distance(mode_section_grouped_df):
     ret_dict = {}
     for (mode, mode_section_df) in mode_section_grouped_df:
-        ret_dict[mode] = mode_section_df.distance.sum()
+        ret_dict[mode] = float(mode_section_df.distance.sum())
     return ret_dict
 
 def get_duration(mode_section_grouped_df):
     ret_dict = {}
     for (mode, mode_section_df) in mode_section_grouped_df:
-        ret_dict[mode] = mode_section_df.duration.sum()
+        ret_dict[mode] = float(mode_section_df.duration.sum())
     return ret_dict
 
 def get_median_speed(mode_section_grouped_df):
@@ -45,5 +45,5 @@ def get_median_speed(mode_section_grouped_df):
         if np.isnan(mode_median):
             logging.debug("still found nan for mode %s, skipping")
         else:
-            ret_dict[mode] = mode_median
+            ret_dict[mode] = float(mode_median)
     return ret_dict
diff --git a/emission/core/get_database.py b/emission/core/get_database.py
index a267ada9..35bf76e4 100644
--- a/emission/core/get_database.py
+++ b/emission/core/get_database.py
@@ -21,6 +21,7 @@ url = config_data["timeseries"]["url"]
 
 print("Connecting to database URL "+url)
 _current_db = MongoClient(url).Stage_database
+#config_file.close()
 
 def _get_current_db():
     return _current_db
diff --git a/emission/core/wrapper/entry.py b/emission/core/wrapper/entry.py
index 216a2887..40a64eab 100644
--- a/emission/core/wrapper/entry.py
+++ b/emission/core/wrapper/entry.py
@@ -32,36 +32,80 @@ class Entry(ecwb.WrapperBase):
 
   @staticmethod
   def _getData2Wrapper():
-    return {"background/location": "location",
+    return {
+            ### BEGIN: incoming data types ###
+            # all location points from the phone
+            "background/location": "location",
+            # "valid" location points from the phone, after removing low-accuracy points
             "background/filtered_location": "location",
+            # "motionactivity" results from the phone, indicating walk/bike or "motorized"
             "background/motion_activity": "motionactivity",
+            # battery readings, to determine power drain empirically
             "background/battery": "battery",
+            # transition events for the tracking finite state machine on the phone
             "statemachine/transition": "transition",
+            # phone sensing configuration (e.g. sensing frequency, geofencing,...)
             "config/sensor_config": "sensorconfig",
+            # phone sync configuration (sync interval,...)
             "config/sync_config": "syncconfig",
+            # user consent time + protocol version
             "config/consent": "consentconfig",
+            # webapp API call time, measured on the server
             "stats/server_api_time": "statsevent",
+            # intended to log the occurrence of errors in the webapp
             "stats/server_api_error": "statsevent",
+            # pipeline stage time, measured on the server
             "stats/pipeline_time": "statsevent",
+            # intended to log the occurrence of errors in the pipeline
             "stats/pipeline_error": "statsevent",
+            # time for various client operations, measured on the client
+            # comparison with the server_api_time can help debug networking issues
             "stats/client_time": "statsevent",
+            # events, such as button presses, on the client
             "stats/client_nav_event": "statsevent",
+            # errors detected on the client. Again, can be correlated with
+            # server calls to debug networking issues
             "stats/client_error": "statsevent",
+            # incidents (smiley/frownie) reported by the user from the phone
             "manual/incident": "incident",
+            # user confirmation of the travel mode, potentially selected from a
+            # rich set of travel modes that cannot be detected using sensors
             "manual/mode_confirm": "userlabel",
+            # user confirmation of the travel purpose
             "manual/purpose_confirm": "userlabel",
+            # user confirmation of the destination (unsure how this will
+            # interact with purpose
+            "manual/destination_confirm": "userlabel",
+            ### END: incoming data types ###
+            ### BEGIN: analysis result data types ###
+            ### ** BEGIN: objects generated after the initial segmentation step **
+            # trips from one place to another
             "segmentation/raw_trip": "rawtrip",
+            # places between trips
             "segmentation/raw_place": "rawplace",
+            # sections within a trip (e.g. walk -> bus -> walk has 3 sections)
             "segmentation/raw_section": "section",
+            # stops between sections
             "segmentation/raw_stop": "stop",
+            # untracked time (e.g. when phone was out of battery)
             "segmentation/raw_untracked": "untrackedtime",
+            ### ** END: objects generated after the initial segmentation step **
+            # object indicating which points need to be removed from the trajectory
+            # because they represent zig-zags
             "analysis/smoothing": "smoothresults",
+            ### ** BEGIN: objects generated after the second cleaned segmentation step
+            ### same explanations as the corresponding segmentation/* objects
             "analysis/cleaned_trip": "cleanedtrip",
             "analysis/cleaned_place": "cleanedplace",
             "analysis/cleaned_section": "cleanedsection",
             "analysis/cleaned_stop": "stop",
             "analysis/cleaned_untracked": "untrackedtime",
+            # Resampled locations to ensure that the point density is
+            # consistent across operating systems and sampling frequencies
             "analysis/recreated_location": "recreatedlocation",
+            ### ** END: objects generated after the second cleaned segmentation step
+            ### ** BEGIN: metric outputs. These are not currently stored
+            ### they are generated on demand instead
             "metrics/daily_user_count": "modestattimesummary",
             "metrics/daily_mean_count": "modestattimesummary",
             "metrics/daily_user_distance": "modestattimesummary",
@@ -70,9 +114,19 @@ class Entry(ecwb.WrapperBase):
             "metrics/daily_mean_duration": "modestattimesummary",
             "metrics/daily_user_median_speed": "modestattimesummary",
             "metrics/daily_mean_median_speed": "modestattimesummary",
+            ### ** END: metric outputs.
+            ### ** BEGIN: prediction objects
+            # the generated model for the random forest based mode inference
+            # saved so that it can be used for prediction without retraining
             "mode_inference/model": "modeinfermodel",
+            # the predicted mode for a particular section
             "inference/prediction": "modeprediction",
+            # equivalent of cleaned_section, but with the mode set to the 
+            # inferred mode instead of just walk/bike/motorized
+            # used for consistency and to make the client work whether or not we were
+            # running the inference step
             "analysis/inferred_section": "inferredsection",
+            ### ** END: prediction objects
             }
 
   @staticmethod
@@ -86,6 +140,18 @@ class Entry(ecwb.WrapperBase):
       result_entry._populateDependencies()
       return result_entry
 
+  @staticmethod
+  def create_fake_entry(user_id, key, data, write_ts, create_id=False):
+      """Method used to create Synthetic entries"""
+      
+      result_entry = Entry()
+      result_entry['_id'] = boi.ObjectId()
+      result_entry.user_id = user_id
+      result_entry.metadata = ecwm.Metadata.create_metadata_for_fake_result(key, write_ts)
+      result_entry.data = data
+      result_entry._populateDependencies()
+      return result_entry
+
   @staticmethod
   def get_dedup_list(key):
       key_class = ecwb.WrapperBase._get_class(Entry._getData2Wrapper()[key])
diff --git a/emission/core/wrapper/metadata.py b/emission/core/wrapper/metadata.py
index 11ffeef8..1a4280d7 100644
--- a/emission/core/wrapper/metadata.py
+++ b/emission/core/wrapper/metadata.py
@@ -43,7 +43,20 @@ class Metadata(ecwb.WrapperBase):
       m.write_local_dt = esdl.get_local_date(m.write_ts, m.time_zone)
       m.write_fmt_time = arrow.get(m.write_ts).to(m.time_zone).isoformat()
       return m
+  @staticmethod
+  def create_metadata_for_fake_result(key, write_ts):
+      import emission.storage.decorations.local_date_queries as esdl
+      import arrow
 
+      m = Metadata()
+      m.key = key
+      m.platform = "server"
+      m.write_ts = write_ts
+      m.time_zone = "America/Los_Angeles"
+      m.write_local_dt = esdl.get_local_date(m.write_ts, m.time_zone)
+      m.write_fmt_time = arrow.get(m.write_ts).to(m.time_zone).isoformat()
+      return m
+      
   def isAndroid(self):
     return self.platform == "android"
 
diff --git a/emission/core/wrapper/suggestion_sys.py b/emission/core/wrapper/suggestion_sys.py
index 36ccca3e..f4f29617 100644
--- a/emission/core/wrapper/suggestion_sys.py
+++ b/emission/core/wrapper/suggestion_sys.py
@@ -6,48 +6,52 @@ import requests
 import json
 import logging
 import re
-import emission.core.get_database as edb
+
 import emission.storage.timeseries.abstract_timeseries as esta
 import argparse
 import pprint
-
-
-
-try:
-    # For Python 3.0 and later
-    from urllib.error import HTTPError
-    from urllib.parse import quote
-    from urllib.parse import urlencode
-except ImportError:
-    # Fall back to Python 2's urllib2 and urllib
-    from urllib2 import HTTPError
-    from urllib import quote
-    from urllib import urlencode
-
+import requests
+import os
+import emission.net.ext_service.geocoder.nominatim as geo
+import bson
 
 # Yelp Fusion no longer uses OAuth as of December 7, 2017.
 # You no longer need to provide Client ID to fetch Data
 # It now uses private keys to authenticate requests (API Key)
 # You can find it on
 # https://www.yelp.com/developers/v3/manage_app
-API_KEY= 'jBC0box-WQr7jvQvXlI9sJuw17wfN9AYFMnu5ebxsYkgQoKTjjIRD0I_tAePUasbaIbXj28cmj4nUBDHrVxtrfHU2l6TM4E61Kk3EVeSbLZsxStLxkAVlkHK9xJ6W3Yx' 
-ACCESS_TOKEN = 'AIzaSyAbnpsty2SAzEX9s1VVIdh5pTHUPMjn3lQ' #GOOGLE MAPS ACCESS TOKEN
-JACK_TOKEN = 'AIzaSyAXG_8bZvAAACChc26JC6SFzhuWysRqQPo'
 
-MAPQUEST_KEY = 'AuwuGlPC5f3Ru7PGahKAtGcs4WdvARem'
-# API constants, you shouldn't have to change these.
-API_HOST = 'https://api.yelp.com'
-SEARCH_PATH = '/v3/businesses/search'
-BUSINESS_PATH = '/v3/businesses/'  # Business ID will come after slash.
+#RESTRUCTURE CODE FOR GOOGLE MAPS SO CAN GET RID OF IT AND JUST USE NOMINATIM.PY
+yelp_json_path = 'conf/net/ext_service/yelpfusion.json'
 
+"""
+Checks if conf files exists or not. The conf files will be given to the user through request.
+"""
+
+try:
+    yelp_json = open('conf/net/ext_service/yelpfusion.json', 'r')
+    yelp_auth = json.load(yelp_json)
+except:
+    print("yelp not configured, cannot generate suggestions")
 
-# Defaults for our simple example.
-DEFAULT_TERM = 'dinner'
-DEFAULT_LOCATION = 'San Francisco, CA'
-SEARCH_LIMIT = 3
-LOCATION = '37.871942'
 
-#Helper function to query into Yelp's API
+YELP_API_KEY = yelp_auth['api_key']
+MAPQUEST_KEY = yelp_auth['map_quest_key']
+API_HOST = yelp_auth['api_host']
+SEARCH_PATH = yelp_auth['search_path']
+BUSINESS_PATH = yelp_auth['business_path']
+SEARCH_LIMIT = yelp_auth['search_limit']
+
+ZIPCODE_API_KEY = yelp_auth['zip_code_key']
+ZIP_HOST_URL = yelp_auth['zip_code_host']
+ZIP_FORMAT = yelp_auth['zip_code_format']
+ZIP_DEGREE = yelp_auth['zip_code_degree']
+BACKUP_ZIP_KEY = yelp_auth['backup_zip_code_key']
+
+
+"""
+YELP API: Helper function to query into the API domain.
+"""
 def request(host, path, api_key, url_params=None):
     """Given your API_KEY, send a GET request to the API.
     Args:
@@ -61,17 +65,19 @@ def request(host, path, api_key, url_params=None):
         HTTPError: An error occurs from the HTTP request.
     """
     url_params = url_params or {}
-    url = '{0}{1}'.format(host, quote(path.encode('utf8')))
+    url = '{0}{1}'.format(host, path)
     headers = {
         'Authorization': 'Bearer %s' % api_key,
     }
 
-    print(u'Querying {0} ...'.format(url))
+    # print('Querying {0} ...'.format(url))
 
     response = requests.request('GET', url, headers=headers, params=url_params)
-
     return response.json()
 
+"""
+YELP API: Function to query based on search terms
+"""
 def search(api_key, term, location):
     """Query the Search API by a search term and location.
     Args:
@@ -88,202 +94,200 @@ def search(api_key, term, location):
     }
     return request(API_HOST, SEARCH_PATH, api_key, url_params=url_params)
 
-def business_reviews(api_key, business_id):
+def lat_lon_search(api_key, lat, lon, radius):
+    """Query Search API using latitude and longitude.
+    Args:
+        lat (float) : latitude
+        lon (float) : longitude
+        radius (int) : radius of search in meters
+    Returns:
+        dict: The JSON response form the request.
+    """
+    url_params = {
+        'latitude': lat,
+        'longitude': lon,
+        'radius' : radius,
+        'limit': SEARCH_LIMIT,
+        'sort_by': 'distance',
+        'categories' : 'food,restaurants,shopping,hotels,beautysvc,auto,education,collegeuniv,financialservices,publicservicesgovt'
+    }
+    return request(API_HOST, SEARCH_PATH, api_key, url_params=url_params)
+
+"""
+YELP API: Function to retrieve details of the business with the specified id
+"""
+def business_details(api_key, business_id):
     business_path = BUSINESS_PATH + business_id
 
     return request(API_HOST, business_path, api_key)
 
-def calculate(json_file):
-    return json_file["categories"][0]["title"]
+"""
+NOMINATIM API: Creates a Nominatim API Call, returns address in string form and dictionary form separated by streetname,
+    road, neighborhood, etc
+"""
+def return_address_from_location_nominatim(lat, lon):
+    geocode_obj = geo.Geocoder()
+    return geocode_obj.reverse_geocode(lat, lon)
 
-#Not as accurate compared to the below functions
-def get_business_id(api_key, lat, lon):
-    url_params = {
-        'location': lat + ',' + lon
-    }
-    return request(API_HOST, SEARCH_PATH, api_key, url_params=url_params)
+'''
+GOOGLE API: Makes Google Maps API CALL to the domain and returns address given a latitude and longitude
+'''
 
-#Used first semester's code to obtain the business ID and location in order to find address
-def check_against_business_location(location='0, 0', address = ''):
-    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
-        raise ValueError('Location Invalid')
-    base_url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?'
-    location = 'location=' + location
-    try:
-        key_string = '&key=' + ACCESS_TOKEN
-        radius = '&radius=10'
-        url = base_url + location + radius + key_string
-        result = requests.get(url).json()
-        cleaned = result['results']
-        for i in cleaned:
-            #If the street address matches the street address of this business, we return a tuple
-            #signifying success and the business name
-            if address == i['vicinity']:
-                return (True, i['name'])
-        else:
-            return (False, '')
-    except:
-        try:
-            key_string = '&key=' + JACK_TOKEN
-            radius = '&radius=10'
-            url = base_url + location + radius + key_string
-            result = requests.get(url).json()
-            cleaned = result['results']
-            for i in cleaned:
-                if address == i['vicinity']:
-                    return (True, i['name'])
-            else:
-                return (False, '')
-        except:
-            raise ValueError("Something went wrong")
+def return_address_from_google_nomfile(lat, lon):
+    return geo.return_address_from_location_google(lat, lon)
 
-def return_address_from_location_nominatim(lat, lon):
-    
-    base_url = 'https://nominatim.openstreetmap.org/reverse?format=json&'
-    lat_lon = 'lat=' + lat + '&lon=' + lon
-    zoom = '&zoom=18&addressdetails=1'
-    try: 
-        url = base_url + lat_lon + zoom
-        result = requests.get(url).json()
-        return result["display_name"]
-    except:
-        raise ValueError("Something went wrong")
 
+'''
+GOOGLE API: Makes Google Maps API CALL to the domain and returns a list of candidate addresses given a latitude and longitude
+'''
 
-def return_address_from_location_yelp(location='0,0'):
-    """
-    Creates a Google Maps API call that returns the addresss given a lat, lon
-    """
-    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
-        raise ValueError('Location Invalid')
-    base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'
-    latlng = 'latlng=' + location
-    try:
-        #This try block is for our first 150,000 requests. If we exceed this, use Jack's Token.
-        key_string = '&key=' + ACCESS_TOKEN
-        url = base_url + latlng + key_string #Builds the url
-        result = requests.get(url).json() #Gets google maps json file
-        cleaned = result['results'][0]['address_components']
-
-
-        #Address to check against value of check_against_business_location
-        chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
-        business_tuple = check_against_business_location(location, chk)
-        
-        if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
-            address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name']
-            # print(business_tuple[1])
-            # print(cleaned[3]['short_name'])
-            # print(address_comp)
-            return business_tuple[1], cleaned[3]['short_name'], address_comp
-        else: #otherwise, we just return the address
-            # print(cleaned[0]['long_name'])
-            # print(cleaned[1]['short_name'])
-            # print(cleaned[3]['short_name'])
-            return cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] + ', ' + cleaned[3]['short_name']
-    except:
-        try:
-            #Use Jack's Token in case of some invalid request problem with other API Token
-            key_string = '&key=' + JACK_TOKEN
-            url = base_url + latlng + key_string #Builds the url
-            result = requests.get(url).json() #Gets google maps json file
-            cleaned = result['results'][0]['address_components']
-            #Address to check against value of check_against_business_location
-            chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
-            business_tuple = check_against_business_location(location, chk)
-            if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
-                address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] 
-                # print(address_comp)
-                # print(business_tuple[1])
-                # print(cleaned[3]['short_name'])
-                return business_tuple[1], cleaned[3]['short_name'], address_comp
-            else: #otherwise, we just return the address
-                # print(cleaned[0]['long_name'])
-                # print(cleaned[1]['short_name'])
-                # print(cleaned[3]['short_name'])
-                return cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] + ', ' + cleaned[3]['short_name']
-        except:
-            raise ValueError("Something went wrong")
+def return_address_from_google_candidates_nomfile(lat, lon):
+    return geo.return_list_of_addresses_from_location_google(lat, lon)
 
+'''
+GOOGLE API: (SAM) Makes Google Maps API CALL to the domain and returns a list of candidate addresses given a latitude and longitude
+'''
+
+def return_address_from_google_candidates_nomfile_sam(lat, lon):
+    return geo.businesses_nearby_google(lat, lon)
+
+
+'''
+YELP API: Function to find the business matching the address
+'''
 def match_business_address(address):
     business_path = SEARCH_PATH
     url_params = {
         'location': address.replace(' ', '+')
     }
-    return request(API_HOST, business_path, API_KEY, url_params)
-'''
-Function to find the review of the original location of the end point of a trip
-'''
-def review_start_loc(location = '0,0'):
-    try:
-        #Off at times if the latlons are of a location that takes up a small spot, especially boba shops
+    return request(API_HOST, business_path, YELP_API_KEY, url_params)
+
+"""
+NOMINATIM API: Checks if location given by nominatim call is a residential location
+
+"""
+def is_service_nominatim(business):
+    if "Hall" in business:
+        return False
+    return True
 
-        #IF RETURN_ADDRESS_FROM_LOCATION HAS A BUSINESS LOCATION ATTACHED TO THE ADDRESS
-        if (len(return_address_from_location_yelp(location)) == 3):
-            business_name, city, address = return_address_from_location_yelp(location)
-        #print(business_reviews(API_KEY, business_name.replace(' ', '-') + '-' + city))
-            return business_reviews(API_KEY, business_name.replace(' ', '-') + '-' + city)['rating']
-    except:
-        try:
-            #This EXCEPT part may error, because it grabs a list of businesses instead of matching the address to a business
-            address = return_address_from_location_yelp(location)
-            return match_business_address(address)
-        except:
-            raise ValueError("Something went wrong")
-    
 '''
-Function that RETURNS a list of categories that the business falls into
+NOMINATIM VERS: Function that RETURNS a list of categories that the business falls into
+
+Using the Google reverse lookup in the except clause, in case Nominatim's results are too vague.
+Will first try Nominatim's reverse lookup, but if Nominatim returns a broad "address"
+of the street and the city, without a full address with a specific location
+Such as Piedmont Ave, Berkeley, CA
+
+Then the function will enter the Google reverse lookup and choose a business that is closest to
+latitude and longitude given
 '''
-def category_of_business(location = '0,0'):
+
+
+### BEGIN: Pulled out candidate functions so that we can evaluate individual accuracies
+def find_destination_business_google(lat, lon):
+    return return_address_from_google_nomfile(lat, lon)
+
+def find_candidates_business_google(lat, lon):
+    return return_address_from_google_candidates_nomfile_sam(lat, lon)
+
+def find_destination_business_yelp(lat, lon):
+    yelp_from_lat_lon = lat_lon_search(YELP_API_KEY, lat, lon, 350)
+    if yelp_from_lat_lon == {}:
+        return (None, None, None, False)
+    businesses = yelp_from_lat_lon['businesses']
+    if businesses == []:
+        return (None, None, None, False)
+    business_name = businesses[0]['name']
+    address = businesses[0]['location']['address1']
+    city = businesses[0]['location']['city']
+    #If there is no commercial establishment in a 50 meter (1/2 block) radius of coordinate
+    #It is safe to assume the area is not a commercial establishment
+    location_is_service = True
+    print((business_name, address, city, location_is_service))
+    return (business_name, address, city, location_is_service)
+
+def find_candidates_business_yelp(lat, lon):
+    yelp_from_lat_lon = lat_lon_search(YELP_API_KEY, lat, lon, 125)
+    if yelp_from_lat_lon == {}:
+        return (None, None, None, False)
+    businesses = yelp_from_lat_lon['businesses']
+    # if businesses == []:
+    #     return find_destination_business(lat, lon)
+    results = []
+    for b in businesses:
+        business_name = b['name']
+        address = b['location']['address1']
+        city = b['location']['city']
+        location_is_service = True
+        results.append([business_name, address, city, location_is_service])
+    return results
+
+
+
+
+def find_destination_business_nominatim(lat, lon):
+    string_address, address_dict = return_address_from_location_nominatim(lat, lon)
+    business_key = list(address_dict.keys())[0]
+    business_name = address_dict[business_key]
+    city = get_city_from_address(address_dict)
+    if city is None:
+        city = ''
+    return (business_name, string_address, city,
+        (not is_service_nominatim(business_name)))
+### END: Pulled out candidate functions so that we can evaluate individual accuracies
+
+## Current combination of candidate functions;
+## First try nominatim, and if it fails, fall back to google
+## Is that the right approach?
+
+def find_destination_business(lat, lon):
+    #Off at times if the latlons are of a location that takes up a small spot, especially boba shops
+    # print(return_address_from_location_google(location))
+    # print(len(return_address_from_location_google(location)))
+    #IF RETURN_ADDRESS_FROM_LOCATION HAS A BUSINESS LOCATION ATTACHED TO THE ADDRESS
     try:
-        #Off at times if the latlons are of a location that takes up a small spot, especially boba shops
-        # print(return_address_from_location_yelp(location))
-        # print(len(return_address_from_location_yelp(location)))
-        #IF RETURN_ADDRESS_FROM_LOCATION HAS A BUSINESS LOCATION ATTACHED TO THE ADDRESS
-        if (len(return_address_from_location_yelp(location)) == 3):
-            business_name, city, address = return_address_from_location_yelp(location)
-            categories = []
-            for c in business_reviews(API_KEY, business_name.replace(' ', '-') + '-' + city)['categories']:
-                categories.append(c['alias'])
-            return categories
-        else:
-            # print(search(API_KEY, '', return_address_from_location_yelp(location)))
-            return None
+        return_tuple = find_destination_business_nominatim(lat, lon)
+        logging.debug("Nominatim found destination business %s " % str(return_tuple))
+        return return_tuple
     except:
-        try:
-            address = return_address_from_location_yelp(location)
-            return match_business_address(address)
-        except:
-            raise ValueError("Something went wrong")
-'''
-Function that RETURNS TRUE or FALSE if the categories of the two points match 
-'''
-def match_category(location0 = '0,0', location1 = '0,0'):
-    categories0 = category_of_business(location0)
-    categories1 = category_of_business(location1)
-    for category in categories0:
-        if category in categories1:
-            return True
-    return False
+        #USE GOOGLE API JUST IN CASE if nominatim doesn't work
+        return_tuple = return_address_from_google_nomfile(lat, lon)
+        logging.debug("Nominatim failed, Google found destination business %s "
+            % str(return_tuple))
+        return return_tuple
+
 
 '''
-Function that RETURNS distance between addresses
+Function that RETURNS distance between lat,lng pairs
 '''
-def distance(address1, address2):
-    address1 = address1.replace(' ', '+')
-    address2 = address2.replace(' ', '+')
 
-    url = 'http://www.mapquestapi.com/directions/v2/route?key=' + MAPQUEST_KEY + '&from=' + address1 + '&to=' + address2
+def distance(start_lat, start_lon, end_lat, end_lon):
+#     logging.debug("Calculating distance between %s %s %s %s of types %s %s %s %s" %
+#         (start_lat, start_lon, end_lat, end_lon,
+#          type(start_lat), type(start_lon), type(end_lat), type(end_lon)))
+    start_lat_lon = start_lat + "," + start_lon
+    end_lat_lon = end_lat + "," + end_lon
+
+    url = 'http://www.mapquestapi.com/directions/v2/route?key=' + MAPQUEST_KEY + '&from=' + start_lat_lon + '&to=' + end_lat_lon
     response = requests.get(url)
-    return response.json()['route']['distance']
+    response_json = response.json()
+#     logging.debug("mapquest response = %s " % response_json)
+    print("distance")
+    print(response_json['route']['distance'])
+    return response_json['route']['distance']
+    # except:
+    #     url = 'http://www.mapquestapi.com/directions/v2/route?key=' + BACKUP_MAPQUEST_KEY + '&from=' + address1 + '&to=' + address2
+    #     response = requests.get(url)
+    #     print(response.json())
+    #     return response.json()['route']['distance']
+
 
 '''
 Two functions that RETURN latitude and longitude coordinates from GEOJSON file
 '''
 def geojson_to_latlon(geojson):
-    coordinates = geojson["coordinates"]
-    lon = str(coordinates[0])
-    lat = str(coordinates[1])
+    lat, lon = geojson_to_lat_lon_separated(geojson)
     lat_lon = lat + ',' + lon
     return lat_lon
 
@@ -292,71 +296,49 @@ def geojson_to_lat_lon_separated(geojson):
     lon = str(coordinates[0])
     lat = str(coordinates[1])
     return lat, lon
-'''
-Determines the motion type in words from sensed mode.
-'''
-def sensed_to_motion_type(value):
-    if value == 0:
-        return "IN_VEHICLE"
-    elif value == 1:
-        return "BIKING"
-    elif value == 2:
-        return "ON_FOOT"
-    elif value == 3:
-        return "STILL"
-    elif value == 4:
-        return "UNKNOWN"
-    elif value == 5:
-        return "TILTING"
-    elif value == 7:
-        return "WALKING"
-    elif value == 8:
-        return "RUNNING"
-    elif value == 9:
-        return "NONE"
-    elif value == 10:
-        return "STOPPED_WHILE_IN_VEHICLE"
-    elif value == 11:
-        return "AIR_ON_HSR"
 
 '''
-Determines the mode that was mostly used through out the trip. 
+REWRITE def check_mode_from_trip(cleaned_trip, cleaned_sections, section_counter, trip_counter):
+Mode number correspondence:
+0: "IN_VEHICLE"
+1: "BIKING"
+2: "ON_FOOT"
+3: "STILL"
+4: "UNKNOWN"
+5: "TILTING"
+7: "WALKING"
+8: "RUNNING"
+9: "NONE"
+10: "STOPPED_WHILE_IN_VEHICLE"
+11: "AIR_ON_HSR"
 '''
-def most_used_mode_from_trip(cleaned_trip, cleaned_sections, section_counter, trip_counter):
+def check_mode_from_trip(cleaned_trip, cleaned_sections, section_counter, trip_counter):
     end_location = cleaned_trip.iloc[trip_counter]["end_loc"]
     end_loc_lat, end_loc_lon = geojson_to_lat_lon_separated(end_location)
     modes_from_section = []
     endsec_location = cleaned_sections.iloc[section_counter]["end_loc"]
-    endsec_loc_lat, endsec_loc_lon = geojson_to_lat_lon_separated(endsec_location)
-    #If a trip is a whole section to start off with 
-    mode_word = ''
+    endsec_loc_lat, endsec_loc_lon = geojson_to_lat_lon_separated(end_sec_location)
+    # Trash value for mode
+    mode = -10
     if (endsec_loc_lat == end_loc_lat and endsec_loc_lon == end_loc_lon):
-        return sensed_to_motion_type(cleaned_sections.iloc[section_counter]["sensed_mode"]), section_counter + 1
-
-    while endsec_loc_lat!= end_loc_lat and endsec_loc_lon!=end_loc_lon and section_counter < len(cleaned_sections) :
-        modes_from_section.append(sensed_to_motion_type(cleaned_sections.iloc[section_counter]["sensed_mode"]))
+        mode = cleaned_sections.iloc[section_counter]["sensed_mode"]
+        return mode, section_counter + 1
+    while endsec_loc_lat != end_loc_lat and endsec_loc_lon != end_loc_lon and section_counter < len(cleaned_sections) :
+        mode = cleaned_sections.iloc[section_counter]["sensed_mode"]
+        modes_from_section.append(mode)
         endsec_location = cleaned_sections.iloc[section_counter]["end_loc"]
-        endsec_loc_lat, endsec_loc_lon = geojson_to_lat_lon_separated(endsec_location)
-        section_counter +=1
+        endsec_loc_lon, endsec_loc_lon = geojson_to_lat_lon_separated(endsec_location)
+        if (mode == 0):
+            return mode, section_counter+1
+    return mode, section_counter + 1
 
-    return most_common_mode(modes_from_section), section_counter
 
 '''
-Given a list of modes, should RETURN the most used mode.
-'''
-
-def most_common_mode(list_modes):
-    return max(set(list_modes), key = list_modes.count)
-
-# Should return the section counter, so you know which index to start off with 
-'''
-New and cleaned up version of yelp-suggestion that detects if there is a better-reviewed place of the same 
-category near the user based on the trip point. 
+DUMMY HELPER FUNCTION TO TEST if server and phone side are connected
 '''
 
 def dummy_starter_suggestion(uuid):
-    all_users = pd.DataFrame(list(edb.get_uuid_db().find({}, {"uuid": 1, "_id": 0})))
-    user_id = all_users.iloc[all_users[all_users.uuid == uuid].index.tolist()[0]].uuid
+    user_id = uuid
     time_series = esta.TimeSeries.get_time_series(user_id)
     cleaned_sections = time_series.get_data_df("analysis/cleaned_trip", time_query = None)
     real_cleaned_sections = time_series.get_data_df("analysis/inferred_section", time_query = None)
@@ -366,247 +348,298 @@ def dummy_starter_suggestion(uuid):
         modes_from_trips[i], section_counter = most_used_mode_from_trip(cleaned_sections, real_cleaned_sections, section_counter, i)
     return modes_from_trips
 
-def calculate_yelp_server_suggestion(uuid):
-    #Given a single UUID, create a suggestion for them
-    return_obj = { 'message': "Good job walking and biking! No suggestion to show.",
-    'savings': "0", 'start_lat' : '0.0', 'start_lon' : '0.0',
-    'end_lat' : '0.0', 'end_lon' : '0.0', 'method' : 'bike'}
-    all_users = pd.DataFrame(list(edb.get_uuid_db().find({}, {"uuid": 1, "_id": 0})))
-    user_id = all_users.iloc[all_users[all_users.uuid == uuid].index.tolist()[0]].uuid
-    time_series = esta.TimeSeries.get_time_series(user_id)
-    cleaned_sections = time_series.get_data_df("analysis/cleaned_trip", time_query = None)
-    real_cleaned_sections = time_series.get_data_df("analysis/inferred_section", time_query = None)
-    yelp_suggestion_trips = edb.get_yelp_db()
-    modes_from_trips = {}
-    section_counter = 0
-    for i in range(len(cleaned_sections)):
-        modes_from_trips[i], section_counter = most_used_mode_from_trip(cleaned_sections, real_cleaned_sections, section_counter, i)
-    
-    if len(cleaned_sections) == 0:
-        return_obj['message'] = 'Suggestions will appear once you start taking trips!'
-        return return_obj
-    for i in range(len(cleaned_sections) - 1, -1, -1):
-        distance_in_miles = cleaned_sections.iloc[i]["distance"] * 0.000621371
-        mode = modes_from_trips[i]
-        start_lat_lon = geojson_to_latlon(cleaned_sections.iloc[i]["start_loc"])
-        end_lat_lon = geojson_to_latlon(cleaned_sections.iloc[i]["end_loc"])
-        # tripDict = yelp_suggestion_trips.find_one({'uuid': uuid})
-        endpoint_categories = category_of_business(end_lat_lon)
-        # print(endpoint_categories)
-        business_locations = {}
-        if len(return_address_from_location_yelp(start_lat_lon))==1:
-            begin_address = return_address_from_location_yelp(start_lat_lon)
-        else:
-            begin_address = return_address_from_location_yelp(start_lat_lon)[2]
-        if len(return_address_from_location_yelp(end_lat_lon)) == 1:
-            continue
-        city = return_address_from_location_yelp(end_lat_lon)[1]
-        address = return_address_from_location_yelp(end_lat_lon)[2]
-        location_review = review_start_loc(end_lat_lon)
-        ratings_bus = {}
-        error_message = 'Sorry, unable to retrieve datapoint'
-        error_message_categor = 'Sorry, unable to retrieve datapoint because datapoint is a house or datapoint does not belong in service categories'
+'''
+ZIPCODEAPI
+
+As nominatim sometimes is unable to provide a specific location with the city and instead returns
+a postcode (zipcode) and the country name. For the suggestions that we built, the suggestions
+require which city (city name) it is in order to look for other similar categoried services
+in the area. Thus, this function takes in the INPUT of a zipcode, and RETURNS the name of the city.
+
+'''
+def zipcode_to_city(zipcode):
+    # Use this API key first.
+    url = ZIP_HOST_URL + ZIPCODE_API_KEY + ZIP_FORMAT + zipcode + ZIP_DEGREE
+    response = requests.request('GET', url=url)
+    results = response.json()
+
+    if "error_code" in results:
+        # In case the first API key runs out of requests per hour.
+        url = ZIP_HOST_URL + BACKUP_ZIP_KEY + ZIP_FORMAT + zipcode + ZIP_DEGREE
+        response = requests.request('GET', url=url)
+        response_json = response.json()
+        return response_json["city"]
+    else:
+        return None
+
+def get_city_from_address(address_dict):
+    if "city" in address_dict:
+        return address_dict["city"]
+    if "town" in address_dict:
+        return address_dict["town"]
+
+    # Falling back to zipcode
+    zipcode = address_dict["postcode"]
+    city = zipcode_to_city(zipcode)
+    # Note that `zipcode_to_city` returns None if the result is not json
+    return city
+
+'''
+NOMINATIM
+In progress-nominatim yelp server suggestion function, first just trying to make end-to-end work before robustifying this function.
+
+Mode number correspondence:
+0: "IN_VEHICLE"
+1: "BIKING"
+2: "ON_FOOT"
+3: "STILL"
+4: "UNKNOWN"
+5: "TILTING"
+7: "WALKING"
+8: "RUNNING"
+9: "NONE"
+10: "STOPPED_WHILE_IN_VEHICLE"
+11: "AIR_ON_HSR"
+'''
+
+def calculate_yelp_server_suggestion_singletrip_nominatim(uuid, tripidstr):
+    user_id = uuid
+    tripid = bson.objectid.ObjectId(tripidstr)
+    timeseries = esta.TimeSeries.get_time_series(user_id)
+    cleaned_trips = timeseries.get_entry_from_id("analysis/cleaned_trip", tripid)
+    '''
+    Used the abstract time series method, wanted to make sure this was what you were asking for
+    '''
+    start_location = cleaned_trips.data.start_loc
+    end_location = cleaned_trips.data.end_loc
+    '''
+    Distance in miles because the current calculated distances is through MapQuest which uses miles,
+    still working on changing those functions, because haven't found any functions through nominatim
+    that calculates distance between points.
+    '''
+    suggestion_result = calculate_yelp_server_suggestion_for_locations(start_location, end_location, cleaned_trips.data.distance)
+    # we could fill in the tripid here as well since we know it, but we weren't doing it before,
+    # so let's not mess it up
+    return suggestion_result
+
+
+def calculate_yelp_server_suggestion_for_locations_business_id(start_loc, end_id, given_distance):
+    distance_in_miles = given_distance * 0.000621371
+    start_lat, start_lon = geojson_to_lat_lon_separated(start_loc)
+    endpoint_categories = []
+    business_locations = {}
+    yelp_call = business_details(YELP_API_KEY, end_id)
+    categories_dict = yelp_call['categories']
+    for c in categories_dict:
+        endpoint_categories.append(c['alias'])
+    city = yelp_call['location']['city']
+    location_review = yelp_call['rating']
+    ratings_bus = {}
+    error_message = 'Sorry, unable to retrieve datapoint'
+    error_message_categor = 'Sorry, unable to retrieve datapoint because datapoint is a house or datapoint does not belong in service categories'
+
+    start_lat_lon = start_lat + "," + start_lon
+    try:
         if (endpoint_categories):
             for categor in endpoint_categories:
-                queried_bus = search(API_KEY, categor, city)['businesses']
+                queried_bus = search(YELP_API_KEY, categor, city)['businesses']
                 for q in queried_bus:
                     if q['rating'] >= location_review:
                         #'Coordinates' come out as two elements, latitude and longitude
-                        ratings_bus[q['name']] = q['rating']
-                        obtained = q['location']['display_address'][0] + q['location']['display_address'][1] 
-                        obtained.replace(' ', '+')
-                        business_locations[q['name']] = obtained
-        else: 
-            return {'message' : error_message_categor, 'method': 'bike'}
-        for a in business_locations:
-            calculate_distance = distance(start_lat_lon, business_locations[a])
-            #Will check which mode the trip was taking for the integrated calculate yelp suggestion
-            if calculate_distance < distance_in_miles and calculate_distance < 5 and calculate_distance >= 1:
-                try:
-                    message = "Why didn't you bike from " + begin_address + " to " + a + " (tap me to view) " + a + \
-                    " has better reviews, closer to your original starting point, and has a rating of " + str(ratings_bus[a])
-                    #Not sure to include the amount of carbon saved
-                    #Still looking to see what to return with this message, because currently my latitude and longitudes are stacked together in one string
-                    # insert_into_db(tripDict, i, yelp_suggestion_trips, uuid)
-                    return {'message' : message, 'method': 'bike'}
-
-                    #insert_into_db(tripDict, trip_id, suggestion_trips, uuid)
-                    break
-                except ValueError as e:
-                    continue
-            elif calculate_distance < distance_in_miles and calculate_distance < 1:
-                try: 
-                    message = "Why didn't you walk from " + begin_address + " to " + a + " (tap me to view) " + a + \
-                    " has better reviews, closer to your original starting point, and has a rating of " + str(ratings_bus[a])
-                    # insert_into_db(tripDict, i, yelp_suggestion_trips, uuid)
-                    return {'message' : message, 'method': 'walk'}
-                    break
-                except ValueError as e:
-                    continue
-            elif calculate_distance < distance_in_miles and calculate_distance >= 5 and calculate_distance <= 15:
-                try: 
-                    message = "Why didn't you check out public transportation from " + begin_address + " to " + a + " (tap me to view) " + a + \
-                    " has better reviews, closer to your original starting point, and has a rating of " + str(ratings_bus[a])
-                    # insert_into_db(tripDict, i, yelp_suggestion_trips, uuid)
-                    return {'message' : message, 'method': 'public'}
-                    break
-                except ValueError as e:
-                    continue
-
-
-#########################################################################################################
-#SEMESTER 1: If user could've taken a more sustainable transportation route, then suggest that sustainable
-#transportation route. 
-
-def return_address_from_location(location='0,0'):
-    """
-    Creates a Google Maps API call that returns the addresss given a lat, lon
-    """
-    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
-        raise ValueError('Location Invalid')
-    base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'
-    latlng = 'latlng=' + location
-    try:
-        #This try block is for our first 150,000 requests. If we exceed this, use Jack's Token.
-        key_string = '&key=' + ACCESS_TOKEN
-        url = base_url + latlng + key_string #Builds the url
-        result = requests.get(url).json() #Gets google maps json file
-        cleaned = result['results'][0]['address_components']
-        #Address to check against value of check_against_business_location
-        chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
-        business_tuple = check_against_business_location(location, chk)
-        if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
-            return business_tuple[1]
-        else: #otherwise, we just return the address
-            return cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] + ', ' + cleaned[3]['short_name']
-    except:
-        try:
-            #Use Jack's Token in case of some invalid request problem with other API Token
-            key_string = '&key=' + JACK_TOKEN
-            url = base_url + latlng + key_string #Builds the url
-            result = requests.get(url).json() #Gets google maps json file
-            cleaned = result['results'][0]['address_components']
-            #Address to check against value of check_against_business_location
-            chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
-            business_tuple = check_against_business_location(location, chk)
-            if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
-                return business_tuple[1]
-            else: #otherwise, we just return the address
-                return cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] + ', ' + cleaned[3]['short_name']
-        except:
-            raise ValueError("Something went wrong")
-
-def check_against_business_location(location='0, 0', address = ''):
-    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
-        raise ValueError('Location Invalid')
-    base_url = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json?'
-    location = 'location=' + location
-    try:
-        key_string = '&key=' + ACCESS_TOKEN
-        radius = '&radius=10'
-        url = base_url + location + radius + key_string
-        result = requests.get(url).json()
-        cleaned = result['results']
-        for i in cleaned:
-            #If the street address matches the street address of this business, we return a tuple
-            #signifying success and the business name
-            if address == i['vicinity']:
-                return (True, i['name'])
+                        ratings_bus[q['name']] = (q['rating'], q['alias'])
+                        obtained_lat = q['coordinates']['latitude'] 
+                        obtained_lon = q['coordinates']['longitude']
+                        obtained = str(obtained_lat) + ',' + str(obtained_lon)
+                        # obtained.replace(' ', '+')
+                        business_locations[q['alias']] = (obtained_lat, obtained_lon)
         else:
-            return (False, '')
+            return ''
     except:
-        try:
-            key_string = '&key=' + JACK_TOKEN
-            radius = '&radius=10'
-            url = base_url + location + radius + key_string
-            result = requests.get(url).json()
-            cleaned = result['results']
-            for i in cleaned:
-                if address == i['vicinity']:
-                    return (True, i['name'])
-            else:
-                return (False, '')
+        return ''
+    for a in business_locations:
+        try:     
+            calculate_distance = distance(str(start_lat), str(start_lon), str(business_locations[a][0]), str(business_locations[a][1]))
         except:
-            raise ValueError("Something went wrong")
-def insert_into_db(tripDict, tripID, collection, uuid):
-    if tripDict == None:
-        collection.insert_one({'uuid': uuid, 'trip_id': tripID})
-    else:
-        if tripDict['trip_id'] != tripID:
-            collection.update_one({'uuid': uuid}, {'$set': {'trip_id' : tripID}})
-def calculate_single_suggestion(uuid):
-    #Given a single UUID, create a suggestion for them
-    return_obj = { 'message': "Good job walking and biking! No suggestion to show.",
-    'savings': "0", 'start_lat' : '0.0', 'start_lon' : '0.0',
-    'end_lat' : '0.0', 'end_lon' : '0.0', 'method' : 'bike'}
-    all_users = pd.DataFrame(list(edb.get_uuid_db().find({}, {"uuid": 1, "_id": 0})))
-    user_id = all_users.iloc[all_users[all_users.uuid == uuid].index.tolist()[0]].uuid
-    time_series = esta.TimeSeries.get_time_series(user_id)
-    cleaned_sections = time_series.get_data_df("analysis/inferred_section", time_query = None)
-    suggestion_trips = edb.get_suggestion_trips_db()
-    #Go in reverse order because we check by most recent trip
-    counter = 40
-    if len(cleaned_sections) == 0:
-        return_obj['message'] = 'Suggestions will appear once you start taking trips!'
-        return return_obj
-    for i in range(len(cleaned_sections) - 1, -1, -1):
-        counter -= 1
-        if counter < 0:
-            #Iterate 20 trips back
-            return return_obj
-        if cleaned_sections.iloc[i]["end_ts"] - cleaned_sections.iloc[i]["start_ts"] < 5 * 60:
             continue
-        distance_in_miles = cleaned_sections.iloc[i]["distance"] * 0.000621371
-        mode = cleaned_sections.iloc[i]["sensed_mode"]
-        start_loc = cleaned_sections.iloc[i]["start_loc"]["coordinates"]
-        start_lat = str(start_loc[0])
-        start_lon = str(start_loc[1])
-        trip_id = cleaned_sections.iloc[i]['trip_id']
-        tripDict = suggestion_trips.find_one({'uuid': uuid})
-        end_loc = cleaned_sections.iloc[i]["end_loc"]["coordinates"]
-        end_lat = str(end_loc[0])
-        end_lon = str(end_loc[1])
-        if mode == 5 and distance_in_miles >= 5 and distance_in_miles <= 15:
-            logging.debug("15 >= distance >= 5 so I'm considering distance: " + str(distance_in_miles))
-            #Suggest bus if it is car and distance between 5 and 15
-            default_message = return_obj['message']
+        if calculate_distance < distance_in_miles and calculate_distance < 5 and calculate_distance >= 1:
             try:
-                message = "Try public transportation from " + return_address_from_location(start_lon + "," + start_lat) + \
-                " to " + return_address_from_location(end_lon + "," + end_lat) + " (tap me to view)"
-                #savings per month, .465 kg co2/mile for car, 0.14323126 kg co2/mile for bus
-                savings = str(int(distance_in_miles * 30 * .465 - 0.14323126 * distance_in_miles * 30))
-                return {'message' : message, 'savings' : savings, 'start_lat' : start_lat,
-                'start_lon' : start_lon, 'end_lat' : end_lat, 'end_lon' : end_lon, 'method': 'public'}
-                insert_into_db(tripDict, trip_id, suggestion_trips, uuid)
-                break
+                return a
             except ValueError as e:
-                return_obj['message'] = default_message
                 continue
-        elif (mode == 5 or mode == 3 or mode == 4) and (distance_in_miles < 5 and distance_in_miles >= 1):
-            logging.debug("5 > distance >= 1 so I'm considering distance: " + str(distance_in_miles))
-            #Suggest bike if it is car/bus/train and distance between 5 and 1
+        elif calculate_distance < distance_in_miles and calculate_distance < 1:
             try:
-                message = "Try biking from " + return_address_from_location(start_lon + "," + start_lat) + \
-                " to " + return_address_from_location(end_lon + "," + end_lat) + " (tap me to view)"
-                savings = str(int(distance_in_miles * 30 * .465))  #savings per month, .465 kg co2/mile
-                insert_into_db(tripDict, trip_id, suggestion_trips, uuid)
-                return {'message' : message, 'savings' : savings, 'start_lat' : start_lat,
-                'start_lon' : start_lon, 'end_lat' : end_lat, 'end_lon' : end_lon, 'method': 'bike'}
-                break
-            except:
+                return a
+            except ValueError as e:
                 continue
-        elif (mode == 5 or mode == 3 or mode == 4) and (distance_in_miles < 1):
-            logging.debug("1 > distance so I'm considering distance: " + str(distance_in_miles))
-            #Suggest walking if it is car/bus/train and distance less than 1
+        elif calculate_distance < distance_in_miles and calculate_distance >= 5 and calculate_distance <= 15:
             try:
-                message = "Try walking/biking from " + return_address_from_location(start_lon + "," + start_lat) + \
-                " to " + return_address_from_location(end_lon + "," + end_lat) + " (tap me to view)"
-                savings = str(int(distance_in_miles * 30 * .465)) #savings per month, .465 kg co2/mile
-                insert_into_db(tripDict, trip_id, suggestion_trips, uuid)
-                return {'message' : message, 'savings' : savings, 'start_lat' : start_lat,
-                'start_lon' : start_lon, 'end_lat' : end_lat, 'end_lon' : end_lon, 'method': 'walk'}
-                break
-            except:
+                return a
+            except ValueError as e:
                 continue
-    return return_obj
 
+    return ''
+
+
+
+def calculate_yelp_server_suggestion_for_locations(start_location, end_location, distance):
+    end_lat, end_lon = geojson_to_lat_lon_separated(end_location)
+    orig_end_business_details = find_destination_business_yelp(end_lat, end_lon)
+    logging.debug("orig_end_business_details = %s " % str(orig_end_business_details))
+    if not orig_end_business_details[-1]:
+        # This is not a service, so we bail right now
+        return format_suggestion(0, 0, None, None)
+    business_name = orig_end_business_details[0].lower()
+    city = orig_end_business_details[2].lower()
+    orig_end_bid_hack = business_name.replace(' ', '-') + '-' + city.replace(' ', '-')
+    orig_bus_details = business_details(YELP_API_KEY, orig_end_bid_hack)
+    if orig_bus_details is None or 'error' in orig_bus_details:
+        # the hack doesn't work
+        # this is a corner case anyway since we should be able to return the bid
+        # from the query too
+        logging.info("hack for %s did not work, skipping suggestion" % orig_end_bid_hack)
+        return format_suggestion(0, 0, None, None)
+    else:
+        logging.info("hack worked, found bid %s" % orig_bus_details["alias"])
+    return calculate_yelp_server_suggestion_for_business(start_location, orig_bus_details, distance)
+
+def calculate_yelp_server_suggestion_for_bid(start_location, orig_bid, distance):
+    orig_bus_details = business_details(YELP_API_KEY, orig_bid)
+    return calculate_yelp_server_suggestion_for_business(start_location, orig_bus_details, distance)
+
+def calculate_yelp_server_suggestion_for_business(start_location, orig_bus_details, distance):
+    distance_in_miles = distance * 0.000621371
+    start_lat, start_lon = geojson_to_lat_lon_separated(start_location)
+
+    alt_sugg_list = get_potential_suggestions(orig_bus_details)
+    fill_distances(start_lat, start_lon, alt_sugg_list)
+    final_sugg = get_selected_suggestion(alt_sugg_list, distance_in_miles)
+
+    return format_suggestion(start_lat, start_lon, orig_bus_details, final_sugg)
+
+#
+# Returns a list of potential suggestions. Each entry is a {"bdetails":
+# business_details_obj} map. We do this to make it easier to add on other calculated
+# state (e.g. new distance, ...) later.
+#
+
+def get_potential_suggestions(orig_bus_details):
+    logging.info("Finding potential suggestions for %s with categories %s" %
+        (orig_bus_details['name'], orig_bus_details['categories']))
+    endpoint_categories = [c['alias'] for c in orig_bus_details['categories']]
+    orig_city = orig_bus_details['location']['city']
+    orig_end_rating = orig_bus_details['rating']
+
+    suggestion_list = []
+    try:
+        for categor in endpoint_categories:
+            queried_bus = search(YELP_API_KEY, categor, orig_city)['businesses']
+            for q in queried_bus:
+                if q['rating'] >= orig_end_rating:
+                    suggestion_list.append({"bdetails": q})
+    except Exception as e:
+        logging.info("Found error %s while looking up suggestions for bid %s, returning empty" % (e.message, orig_end_bid))
+
+    # no matter what happens above, we return the suggestion_list
+    return suggestion_list
+
+# Non functional programming;
+# fills distances into existing object
+
+def fill_distances(start_lat, start_lon, sugg_list):
+    for sugg_obj in sugg_list:
+        curr_sugg_details = sugg_obj["bdetails"]
+        try:
+            curr_sugg_coords = curr_sugg_details["coordinates"]
+            logging.debug("calculating distance for %s at location %s" %
+                (curr_sugg_details['alias'], curr_sugg_coords))
+            # The inputs to distance have to be strings; otherwise
+            # str + float fails
+            # Error unsupported operand type(s) for +: 'float' and 'str'
+            alt_distance = distance(start_lat, start_lon,
+                str(curr_sugg_coords["latitude"]), str(curr_sugg_coords["longitude"]))
+            logging.debug("While considering %s, calculated new distance %s" %
+                (curr_sugg_details["alias"], alt_distance))
+        except Exception as e:
+            logging.info("Error %s while calculating distance for %s,returning inf" %
+                (e, curr_sugg_details["alias"]))
+            alt_distance = float('inf')
+
+        sugg_obj["alt_distance"] = alt_distance
+
+#
+# sugg_list is the list of alternatives
+# distance_in_miles is the distance of the original trip
+# Every single check in here currently checks for calculate_distance <
+# distance_in_miles so theoretically, we could introduce a separate filter step
+# before this and simplify this function even further. But since
+# `get_selected_suggestion` is under active development, I will leave
+# it unchanged
+# Don't need any try/catch blocks here because we have them in the preceding functions
+
+def get_selected_suggestion(sugg_list, distance_in_miles):
+    for sugg_obj in sugg_list:
+        calculate_distance = sugg_obj["alt_distance"]
+        #Will check which mode the trip was taking for the integrated calculate yelp suggestion
+        if calculate_distance < distance_in_miles and calculate_distance < 5 and calculate_distance >= 1:
+            sugg_obj['mode'] = 'bike'
+            return sugg_obj
+        elif calculate_distance < distance_in_miles and calculate_distance < 1:
+            sugg_obj['mode'] = 'walk'
+            return sugg_obj
+        elif calculate_distance < distance_in_miles and calculate_distance >= 5 and calculate_distance <= 15:
+            sugg_obj['mode'] = 'public'
+            return sugg_obj
+    return None
+
+def format_suggestion(start_lat, start_lon, orig_bus_details,
+                      alt_sugg):
+    if alt_sugg is None:
+        if orig_bus_details is None:
+            logging.info("No dest business -> no suggestion")
+        else:
+            logging.info("For %s, found no suggestion" % (orig_bus_details["alias"]))
+        return {
+            'message': 'Sorry, unable to retrieve datapoint because datapoint is a house or datapoint does not belong in service categories',
+            'question': None,
+            'suggested_loc': None,
+            'method': 'bike',
+            'rating': None,
+            'businessid': None
+        }
+    else:
+        logging.info("For %s, found suggestion %s with mode %s" %
+            (orig_bus_details["alias"], alt_sugg["bdetails"]["alias"], alt_sugg["mode"]))
+        begin_string_address, begin_address_dict = return_address_from_location_nominatim(start_lat, start_lon)
+        # TODO: Can't we just use the business name here directly instead of an
+        # address. Seems like that will be a lot more meaningful to people
+        end_string_address = " ".join(orig_bus_details["location"]["display_address"])
+        alt_bus_details = alt_sugg["bdetails"]
+        return {
+            'message': 'We saw that you took a vehicle from '+begin_string_address
+                + ' to '+ end_string_address,
+            'suggested_loc': 'Instead, there is '+ alt_bus_details['name']+' which has better reviews and is closer to your starting point',
+            'method': alt_sugg["mode"],
+            'rating': alt_bus_details['rating'],
+            'businessid': alt_bus_details['alias']
+        }
+
+def calculate_yelp_server_suggestion_nominatim(uuid):
+    user_id = uuid
+    time_series = esta.TimeSeries.get_time_series(user_id)
+    cleaned_trips = time_series.get_data_df("analysis/cleaned_trip", time_query = None)
+    real_cleaned_sections = time_series.get_data_df("analysis/inferred_section", time_query = None)
+    # modes_from_trips = {}
+    section_counter = 0
+    # for i in range(len(cleaned_trips)):
+    #     modes_from_trips[i], section_counter = check_mode_from_trip(cleaned_trips, cleaned_sections, section_counter, i)
+    if len(cleaned_trips) == 0:
+        return_obj['message'] = 'Suggestions will appear once you start taking trips!'
+        return return_obj
+    for i in range(len(cleaned_trips) - 1, -1, -1):
+        distance_in_miles = cleaned_trips.iloc[i]["distance"] * 0.000621371
+        # mode = modes_from_trips[i]
+        start_lat, start_lon = geojson_to_lat_lon_separated(cleaned_trips.iloc[i]["start_loc"])
+        end_lat, end_lon = geojson_to_lat_lon_separated(cleaned_trips.iloc[i]["end_loc"])
+        suggestion_result = calculate_yelp_server_suggestion_for_locations(cleaned_trips.iloc[i]["start_loc"], cleaned_trips.iloc[i]["end_loc"], cleaned_trips.iloc[i]["distance"])
+        suggestion_result['tripid'] = cleaned_trips.iloc[i]["_id"]
+        return suggestion_result
diff --git a/emission/tests/storageTests/TestCommonPlaceQueries.py b/emission/incomplete_tests/TestCommonPlaceQueries.py
similarity index 100%
rename from emission/tests/storageTests/TestCommonPlaceQueries.py
rename to emission/incomplete_tests/TestCommonPlaceQueries.py
diff --git a/emission/tests/storageTests/TestCommonTripQueries.py b/emission/incomplete_tests/TestCommonTripQueries.py
similarity index 100%
rename from emission/tests/storageTests/TestCommonTripQueries.py
rename to emission/incomplete_tests/TestCommonTripQueries.py
diff --git a/emission/tests/storageTests/TestTourModelQueries.py b/emission/incomplete_tests/TestTourModelQueries.py
similarity index 100%
rename from emission/tests/storageTests/TestTourModelQueries.py
rename to emission/incomplete_tests/TestTourModelQueries.py
diff --git a/emission/tests/analysisTests/TestClusterPipeline.py b/emission/incomplete_tests/tourModelTests/TestClusterPipeline.py
similarity index 100%
rename from emission/tests/analysisTests/TestClusterPipeline.py
rename to emission/incomplete_tests/tourModelTests/TestClusterPipeline.py
diff --git a/emission/tests/analysisTests/TestFeaturization.py b/emission/incomplete_tests/tourModelTests/TestFeaturization.py
similarity index 100%
rename from emission/tests/analysisTests/TestFeaturization.py
rename to emission/incomplete_tests/tourModelTests/TestFeaturization.py
diff --git a/emission/tests/analysisTests/TestRepresentatives.py b/emission/incomplete_tests/tourModelTests/TestRepresentatives.py
similarity index 100%
rename from emission/tests/analysisTests/TestRepresentatives.py
rename to emission/incomplete_tests/tourModelTests/TestRepresentatives.py
diff --git a/emission/tests/analysisTests/tourModelTests/__init__.py b/emission/incomplete_tests/tourModelTests/__init__.py
similarity index 100%
rename from emission/tests/analysisTests/tourModelTests/__init__.py
rename to emission/incomplete_tests/tourModelTests/__init__.py
diff --git a/emission/tests/analysisTests/tourModelTests/common.py b/emission/incomplete_tests/tourModelTests/common.py
similarity index 100%
rename from emission/tests/analysisTests/tourModelTests/common.py
rename to emission/incomplete_tests/tourModelTests/common.py
diff --git a/emission/integrationTests/suggestionsys/README b/emission/integrationTests/suggestionsys/README
new file mode 100644
index 00000000..275e6196
--- /dev/null
+++ b/emission/integrationTests/suggestionsys/README
@@ -0,0 +1,72 @@
+The suggestion system requires several different components to come together to work
+- we have to correctly figure out what the trip destination and its category were
+- we have to then come up with a set of potential alternatives
+- we have to pick the best alternative
+All of these involve mini-algorithms that are likely to change the results as
+we tweak them
+
+We will use these python tests to effectively create ad-hoc mini datasets that
+can track how the algorithms work across a fairly broad set of use cases, not
+just one
+
+These are not unit tests since they depend on external results which may change
+over time. We can convert them into unit tests through mocking, but kind of
+running out of time for that here
+
+NOTE: We may want to remove/edit the "find_destination_business" if we choose
+depending on the API we choose for the lookup.
+
+NOTE #2: If you comment out the line 
+"import emission.storage.timeseries.abstract_timeseries as esta"
+in suggestion_sys, you don't need to have the database running. Please make
+sure not to commit this change
+
+NOTE #3: To invoke the sugg functions in here interactively, open an emission
+environment loaded ipython terminal (i.e. ./e-mission-ipy.bash) or jupyter
+notebook (i.e.  ./e-mission-juypter.bash notebook) and `import
+emission.core.wrapper.suggestion_sys as sugg`.  You can look for examples of
+other interactive code from the `sugg` module in
+https://github.com/e-mission/e-mission-docs/issues/382
+
+INSTRUCTIONS
+-----------
+- Configure nominatim, google and yelp in the `conf/net` directory. You can use
+  the values on the server to start with.
+- Pick an _interesting_ use case, hopefully one that is not already covered -
+  suburban big box store in mall, suburban big box store standalone, strip
+  mall, downtown restaurant,....
+- Look up the related latlng using https://www.openstreetmap.org, zoom in as
+  much as you can go, click on the right toolbar -> Layers -> Map Data.  For
+  bigger buildings, you may need to click on the associated nodes You can also
+  get the yelp business id by searching yelp for the business and looking at the
+  id in the URL (e.g. in
+  https://www.yelp.com/biz/kohls-mountain-view-mountain-view-2?osq=kohl%27s+mountain+view,
+  the business id is kohls-mountain-view-mountain-view-2)
+- Use the OSM map data or suggestion system methods - e.g.
+  `return_address_from_location_nominatim` or
+  `business_reviews` or maybe even yelp - e.g.
+    ```
+    sugg.request(sugg.API_HOST, sugg.SEARCH_PATH, sugg.YELP_API_KEY,
+        url_params={'latitude': 37.701995, 'longitude': -122.4706021,
+        'radius': 100, 'limit': 50})
+    ```
+    to find your options
+    - especially for the address, this may be inconsistent across potential
+      APIs, which is why I have the note above.
+    - you may want to use the yelp bid to directly get the categories, for example
+        ```
+        In [2]: sugg.business_reviews(sugg.YELP_API_KEY, "kohls-mountain-view-mountain-view-2")
+        Out[2]:
+        {'alias': 'kohls-mountain-view-mountain-view-2',
+         'categories': [{'alias': 'deptstores', 'title': 'Department Stores'},
+          {'alias': 'menscloth', 'title': "Men's Clothing"},
+          {'alias': 'womenscloth', 'title': "Women's Clothing"}],
+         'coordinates': {'latitude': 37.4028391, 'longitude': -122.1082734},
+          ...
+        ```
+- find the output of the correct answer
+- put it into the dataset
+- run the harness to make sure that the json is in the right format
+- rinse, repeat
+
+Let me know if anything in here is unclear
diff --git a/emission/integrationTests/suggestionsys/algorithm_test_harness.py b/emission/integrationTests/suggestionsys/algorithm_test_harness.py
new file mode 100644
index 00000000..5f38d35b
--- /dev/null
+++ b/emission/integrationTests/suggestionsys/algorithm_test_harness.py
@@ -0,0 +1,199 @@
+import sys
+import logging
+# Change this to INFO if you want less verbose logging
+logging.basicConfig(level=logging.DEBUG)
+import argparse
+import json
+import random
+import geojson as gj
+import math
+
+import emission.core.wrapper.suggestion_sys as sugg
+
+### Add noise from a uniform distribution with range `noise_in_meters`
+def add_noise(loc_geojson, noise_in_meters):
+    # Formula from
+    # http://www.movable-type.co.uk/scripts/latlong.html
+    # section "Destination point given distance and bearing from start point"
+    R = 6371e3 # radius of the earth in meters from the same location
+
+    # if we don't have this check, then the subsequent randrange call fails
+    # with the error
+    # ValueError: empty range for randrange()
+    if noise_in_meters == 0:
+        logging.info("noise_in_meters = 0, skipping add_noise")
+        return loc_geojson
+    delta_dist = float(random.randrange(noise_in_meters))
+    brng = math.radians(random.randrange(360))
+
+    old_lat = math.radians(loc_geojson["coordinates"][1])
+    new_lat = math.asin(math.sin(old_lat)*math.cos(delta_dist/R) +
+                    math.cos(old_lat)*math.sin(delta_dist/R)*math.cos(brng) );
+    old_lng = math.radians(loc_geojson["coordinates"][0])
+    new_lng = old_lng + math.atan2(
+        math.sin(brng)*math.sin(delta_dist/R)*math.cos(old_lat),
+        math.cos(delta_dist/R)-math.sin(old_lat)*math.sin(old_lat));
+    new_loc = gj.Point((math.degrees(new_lng), math.degrees(new_lat)))
+    logging.info("After adding noise, converted %s -> %s" %
+        (loc_geojson["coordinates"], new_loc["coordinates"]))
+    return new_loc
+
+
+def test_find_destination_business(cfn, params, exp_output, noise_in_meters):
+    noisy_loc = add_noise(params["loc"], noise_in_meters)
+    lat, lon = sugg.geojson_to_lat_lon_separated(noisy_loc)
+    result = cfn(lat, lon)
+    name = result[0]
+    # exp_output is a list of valid names
+
+    if name in exp_output:
+        logging.debug("found match! name = %s, comparing with %s" %
+            (name, exp_output))
+        return True
+    else:
+        logging.debug("no match! name = %s, comparing with %s" %
+            (name, exp_output))
+        return False
+
+def test_calculate_yelp_server_suggestion_for_locations(cfn, params, exp_output, noise_in_meters):
+    noisy_start_loc = add_noise(params["start_loc"], noise_in_meters)
+    # # noisy_end_loc = add_noise(params["end_loc"], noise_in_meters)
+    # noisy_end_business = add_noise(params["end_business"], noise_in_meters)
+    noisy_end_business = params["end_business_id"]
+    # input_end_business = params["end_business"]
+    end_loc_coord = sugg.business_details(sugg.YELP_API_KEY, noisy_end_business)['coordinates']
+    end_loc_lat = end_loc_coord['latitude']
+    end_loc_lon = end_loc_coord['longitude']
+
+    noisy_end_loc = {'coordinates': [end_loc_lon, end_loc_lat]}
+    start_lat, start_lon = sugg.geojson_to_lat_lon_separated(noisy_start_loc)
+    end_lat, end_lon = sugg.geojson_to_lat_lon_separated(noisy_end_loc)
+
+    distance_in_miles = sugg.distance(start_lat, start_lon, end_lat, end_lon)
+    distance_in_meters = distance_in_miles / 0.000621371
+    logging.debug("distance in meters = %s" % distance_in_meters)
+    # calculation function expects distance in meters
+    result = cfn(noisy_start_loc, noisy_end_business, distance_in_meters)
+    if result == exp_output:
+        logging.debug("found match! name = %s, comparing with %s" %
+                (result, exp_output))
+        return True
+    else:
+        logging.debug("no match! name = %s, comparing with %s" %
+                (result, exp_output))
+        return False
+
+
+def test_single_instance(test_fn, cfn, instance, noise_in_meters):
+    logging.debug("-----" + instance["test_name"] + "------")
+    param = instance["input"]
+    exp_output = instance["output"]
+    result = test_fn(cfn, param, exp_output, noise_in_meters)
+    if not result:
+        logging.debug("Test %s failed, output = %s, expected %s "
+            % (instance["test_name"], result, exp_output))
+    return result
+
+# Note: this has to be here because it needs to be after the
+# wrapper function is defined but before we use the keys as valid choices while
+# setting up the parser
+
+TEST_WRAPPER_MAP = {
+    "find_destination_business": test_find_destination_business,
+    "calculate_yelp_server_suggestion_for_locations": test_calculate_yelp_server_suggestion_for_locations
+}
+
+CANDIDATE_ALGORITHMS = {
+    "find_destination_business": [
+        sugg.find_destination_business_google,
+        sugg.find_destination_business_yelp,
+        sugg.find_destination_business_nominatim,
+        sugg.find_destination_business
+    ],
+    "calculate_yelp_server_suggestion_for_locations": [
+        sugg.calculate_yelp_server_suggestion_for_locations_business_id
+    ], 
+    "find_candidate_business": [
+        sugg.find_candidates_business_yelp
+    ]
+}
+
+
+if __name__ == '__main__':
+    parser = argparse.ArgumentParser()
+#     parser.add_argument("-d", "--debug", type=int,
+#         help="set log level to DEBUG")
+    parser.add_argument("algorithm",
+        choices=TEST_WRAPPER_MAP.keys(),
+        help="the algorithm to test")
+    parser.add_argument("--candidates", nargs="*",
+        help="the candidate implementations of the algorithm; see suggestion_sys for details")
+    parser.add_argument("-f", "--infile",
+        help="the file that has the inputs and expected outputs. default is emission/integrationTests/suggestionsys/{algorithm}.dataset.json")
+    parser.add_argument("-t", "--test", nargs="+",
+        help="run only the test with the specific name, to make it easier to debug individual instances")
+    parser.add_argument("-n", "--noise", type=int, default=0,
+        help="maximum noise (in meters) to add to the locations. Noise from a uniform distribution with this range will be added")
+    parser.add_argument("-s", "--seed",
+        help="random seed to use for reproducibility while trying to debug lookup")
+
+    args = parser.parse_args()
+#     if args.debug:
+#         logging.basicConfig(level=logging.DEBUG)
+#     else:
+#         logging.basicConfig(level=logging.INFO)
+
+    logging.info("Configuring random with seed %s" % args.seed)
+    random.seed(args.seed)
+
+    if args.infile is None:
+        args.infile = ("emission/integrationTests/suggestionsys/%s.dataset.json"
+            % (args.algorithm))
+
+    test_fn = TEST_WRAPPER_MAP[args.algorithm]
+    logging.info("Mapped algorithm %s -> %s" % (args.algorithm, test_fn))
+
+    all_candidate_fn_list = CANDIDATE_ALGORITHMS[args.algorithm]
+    all_candidate_name_list = [c.__name__ for c in CANDIDATE_ALGORITHMS[args.algorithm]]
+    if args.candidates is None:
+        args.candidates = all_candidate_name_list
+
+    logging.info("specified candidates = %s" % args.candidates)
+    invalid_candidate_fn_names = [c for c in args.candidates
+        if c not in all_candidate_name_list]
+    if len(invalid_candidate_fn_names) > 0:
+        print("Did not find candidate algorithms %s" % invalid_candidate_fn_names)
+        exit(1)
+
+    candidate_fns = [fn for fn in all_candidate_fn_list if fn.__name__ in args.candidates]
+    logging.info("Comparing candidate functions %s" % candidate_fns)
+
+    dataset = json.load(open(args.infile))
+
+    if args.test is not None:
+        logging.info("Running single test %s" % args.test)
+        test_instance = [i for i in dataset if i["test_name"] == " ".join(args.test)][0]
+        logging.debug("Found test instance %s" % test_instance)
+        for cfn in candidate_fns:
+            test_single_instance(test_fn, cfn, test_instance, args.noise)
+        exit(0)
+
+    cfn2resultlist= []
+    for cfn in candidate_fns:
+        successfulTests = 0
+        failedTests = 0
+        for instance in dataset:
+            result = test_single_instance(test_fn, cfn, instance, args.noise)
+            if result:
+                successfulTests = successfulTests + 1
+            else:
+                failedTests = failedTests + 1
+            logging.debug("For candidate %s, after instance %s, successfulTests = %d, failedTests = %d"
+                % (cfn.__name__, instance["test_name"], successfulTests, failedTests))
+        cfn2resultlist.append((cfn.__name__, successfulTests, failedTests))
+        logging.info("Testing candidate %s complete, overall accuracy = %s " %
+            (cfn.__name__, (successfulTests * 100) / (successfulTests + failedTests)))
+
+    logging.info("Test complete, comparison results = ")
+    for cfn_name, successfulTests, failedTests in cfn2resultlist:
+        logging.info("candidate: %s, accuracy = %s" % (cfn_name, (successfulTests * 100) / (successfulTests + failedTests)))
diff --git a/emission/integrationTests/suggestionsys/calculate_yelp_server_suggestion_for_locations.dataset.json b/emission/integrationTests/suggestionsys/calculate_yelp_server_suggestion_for_locations.dataset.json
new file mode 100644
index 00000000..727d4c13
--- /dev/null
+++ b/emission/integrationTests/suggestionsys/calculate_yelp_server_suggestion_for_locations.dataset.json
@@ -0,0 +1,501 @@
+[
+    {
+        "test_name": "Sunnyvale -> Mountain View Kohls",
+        "test_type": "From suburban residential area (between Wolfe and Braly School) to suburban big box store",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.0154871, 37.3635335],
+                "type": "Point"
+            },
+            "end_business_id": "kohls-mountain-view-mountain-view-2"
+        },
+        "output": "target-sunnyvale-2"
+    }
+,
+    {
+        "test_name": "Martinez -> Italian Homemade",
+        "test_type": "From urban residential area (Channing and Telegraph) to Main Street type commercial district italian restaurant",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "the-italian-homemade-company-berkeley-3"
+        },
+        "output": "gypsys-trattoria-italiano-berkeley-2"
+    }
+,
+    {
+        "test_name": "Martinez -> Jong Ga",
+        "test_type": "From urban residential area (Channing and Telegraph) to Midtown type commercial district korean barbecue",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "jong-ga-house-oakland"
+        },  
+        "output": "ohgane-korean-restaurant-oakland"
+    }
+,
+    {
+        "test_name": "Martinez -> T Pumps",
+        "test_type": "From urban residential area (Channing and Telegraph) to Midtown type Main Street boba tea shop",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "tpumps-san-francisco"
+        },
+        "output": "four-barrel-coffee-san-francisco"
+    }
+,
+    {
+        "test_name": "Martinez -> Berkeley Bowl West",
+        "test_type": "From urban residential area (Channing and Telegraph) to industrial area grocery store",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "berkeley-bowl-west-berkeley-2"
+        },
+        "output": "whole-foods-market-berkeley-7"
+    }
+,
+    {
+        "test_name": "Martinez -> SFO",
+        "test_type": "From urban residential area (Channing and Telegraph) to large international airport",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "san-francisco-international-airport-sfo-san-francisco-3"
+        },
+        "output": ""
+    }
+,
+    {
+        "test_name": "Martinez -> SF House",
+        "test_type": "From urban residential area (Channing and Telegraph) to medium density house in Richmond District SF",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "the-house-san-francisco"
+        },
+        "output": ""
+    }
+,
+    {
+        "test_name": "SF House -> Pho K&K",
+        "test_type": "From medium density house in Richmond District SF to urban Pho restaurant in Berkeley",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.469817, 37.779966],
+                "type": "Point"
+            },
+            "end_business_id": "pho-k-and-k-berkeley"
+        },
+        "output": "le-pho-berkeley-6"
+    }
+,
+    {
+        "test_name": "SF House -> Home Cafe",
+        "test_type": "From medium density house in Richmond District to lower medium density cafe in Sunset District",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.469817, 37.779966],
+                "type": "Point"
+            },
+            "end_business_id": "home-san-francisco-28"   
+        },
+        "output": "rise-and-grind-coffee-and-tea-san-francisco"
+    }
+,
+    {
+        "test_name": "Martinez -> China Village",
+        "test_type": "From urban residential area (Channing and Telegraph) to Main Street type commercial district restaurant",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "china-village-albany-3"     
+        },
+        "output": "chengdu-style-restaurant-berkeley"
+    }
+,
+    {
+        "test_name": "Martinez -> O'hair Park",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban large park surrounded by open space",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "o-hair-park-novato"
+        },
+        "output": "willard-park-berkeley"
+    }
+,
+    {
+        "test_name": "Martinez -> NUSD",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban office for school district",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "novato-unified-school-district-novato"
+        },
+        "output": ""
+    }
+,
+   {
+        "test_name": "Martinez -> Ohana Family BBQ",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban Hawaiian Restaurant in strip mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "ohana-hawaiian-bbq-petaluma"
+        },
+        "output": "matiki-island-bbq-and-brew-berkeley-4"
+    }
+,
+    {
+        "test_name": "Martinez -> Michaels Petaluma",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban arts supplies in strip mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "michaels-petaluma-2"
+        },
+        "output": "the-ink-stone-berkeley"
+    }
+,
+    {
+        "test_name": "Martinez -> FedEX Print",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban print and sign shop in strip mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "fedex-office-print-and-ship-center-petaluma-2"
+        },
+        "output": "zee-zee-copy-berkeley"
+    }
+,
+    {
+        "test_name": "Martinez -> Planet Fitness Rohnert Park",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban gym in strip mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "planet-fitness-rohnert-park-rohnert-park"
+        },
+        "output": "equinox-berkeley-berkeley-2"
+    }
+,
+    {
+        "test_name": "Martinez -> Cottage Gardens",
+        "test_type": "From urban residential area (Channing and Telegraph) to rural garden store",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "cottage-gardens-of-petaluma-petaluma"
+        },
+        "output": "east-bay-nursery-berkeley"
+    }
+,   
+    {
+        "test_name": "Martinez -> Play n Learn Petaluma",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban child care center next to park",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "play-and-learn-pre-school-petaluma"
+        },
+        "output": ""
+    }
+,
+    {
+        "test_name": "Martinez -> Dick's SPorting",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban sports good store in strip mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "dicks-sporting-goods-petaluma"
+        },
+        "output": "berkeley-sports-berkeley"
+    }
+,
+    {
+        "test_name": "Martinez -> Tea Room Petaluma",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban downtown tea room",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "tea-room-cafe-petaluma-4"
+        },
+        "output": "sodoi-coffee-tasting-house-berkeley-2"
+    }
+,   
+    {
+        "test_name": "Martinez -> Petaluma Accupuncture",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban downtown accupuncture clinic",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "petaluma-community-acupuncture-petaluma"
+        },
+        "output": ""
+    }
+,
+    {
+        "test_name": "Martinez -> Main Street Computer Repair",
+        "test_type": "From urban residential area (Channing and Telegraph) to suburban downtown computer repair shop",
+        "input": {
+            "start_loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            },
+            "end_business_id": "main-street-computer-store-petaluma"
+        },
+        "output": "computerland-of-berkeley-berkeley-4"
+    }
+,
+    {
+        "test_name": "99 Ranch Market -> Jang Su Jang",
+        "test_type": "From super market to another plaza with a Korean BBQ restaurant",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.9168968, 37.4227499],
+                "type": "Point"
+            },
+            "end_business_id": "jang-su-jang-milpitas-3"
+        },
+        "output": "pinoy-bbq-atbp-milpitas"
+    }
+,
+    {
+        "test_name": "99 Ranch Market -> Layang Layang",
+        "test_type": "From super market to a Malaysian cuisine restaurant",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.9168968, 37.4227499],
+                "type": "Point"
+            },
+            "end_business_id": "layang-layang-milpitas"
+        },
+        "output": "banana-leaf-restaurant-milpitas"
+    }
+, 
+    {
+        "test_name": "Bank of America -> Lucky",
+        "test_type": "From a bank in a suburban area to a grocery store",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.893570078292, 37.4330339],
+                "type": "Point"
+            },
+            "end_business_id": "lucky-milpitas-3"
+        },
+        "output": "safeway-milpitas"
+    }
+,
+    {
+        "test_name": "Bank of America -> T4",
+        "test_type": "From a bank in a suburban area to a boba shop in another plaza",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.893570078292, 37.4330339],
+                "type": "Point"
+            },
+            "end_business_id": "t4-milpitas"
+        },
+        "output": "kokoro-ramen-milpitas"
+    }
+, 
+    {
+        "test_name": "Bank of America -> Black Angus",
+        "test_type": "From a bank in a suburban area to a traditional American restaurant in Union city",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.893570078292, 37.4330339],
+                "type": "Point"
+            },
+            "end_business_id": "black-angus-steakhouse-milpitas"
+        },
+        "output": "red-lobster-milpitas"
+    }
+,
+    {
+        "test_name": "Milpitas High School -> Sally's Beauty Salon",
+        "test_type": "From a high school in the suburbs to a hair salon",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.902181662713, 37.4505958],
+                "type": "Point"
+            },
+            "end_business_id": "sally-beauty-salon-milpitas"
+        },
+        "output": "simple-hair-milpitas"
+    }
+,
+    {
+        "test_name": "Milpitas High School -> ShengKee Bakery",
+        "test_type": "From a high school in the suburbs to a bakery in a plaza",
+        "input": {
+            "start_loc": {
+                "coordinates": [-121.902181662713, 37.4505958],
+                "type": "Point"
+            },
+            "end_business_id": "sheng-kee-bakery-milpitas-2"
+        },
+        "output": "meka-bakery-milpitas-2"
+    }
+,
+    {
+        "test_name": "Illinois Institute of Art -> Goddess and the Baker",
+        "test_type": "From Chicago-based Illinois Institute of Art to a Cafe",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6266294, 41.8854453],
+                "type": "Point"
+            },
+            "end_business_id": "goddess-and-the-baker-chicago"
+            
+        },
+        "output": "argo-tea-chicago-28"
+    }
+,
+    {
+        "test_name": "Wood Oaks Junior High School -> California Pizza Kitchen",
+        "test_type": "From a middle school to California Pizza Kitchen in a Shopping Mall",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.8807004, 42.1289512],
+                "type": "Point"
+            },
+            "end_business_id": "california-pizza-kitchen-at-northbrook-court-northbrook-3"
+            
+        
+        },
+        "output": "lou-malnatis-pizzeria-northbrook-2"
+    }
+,
+    {
+        "test_name": "Davis CTA Station -> Lou Malnati's",
+        "test_type": "From a CTA Station to the best deep dish restaurant in the Chicagoland area",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6834458, 42.0478385],
+                "type": "Point"
+            },
+            "end_business_id": "lou-malnatis-pizzeria-evanston-2"
+            
+        
+        },
+        "output": "papa-johns-pizza-evanston-2"
+    }
+,
+    {
+        "test_name": "CVS Pharmacy -> Bangers and Lace",
+        "test_type": "From CVS Pharmacy to a bar",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6815653, 42.0489605],
+                "type": "Point"
+            },
+            "end_business_id": "bangers-and-lace-evanston-evanston-3"
+        },
+        "output": "celtic-knot-public-house-evanston"
+    }
+,
+    {
+        "test_name": "Gioradano's -> Jimmy John's",
+        "test_type": "From a pizza place to a bus stop in Evanston near Northwestern's campus",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6795324, 42.0460200],
+                "type": "Point"
+            },
+            "end_business_id": "jimmy-johns-evanston"
+        },
+        "output": "soulwich-evanston"
+    }
+,
+    {
+        "test_name": "Apartment Building -> LA Fitness",
+        "test_type": "From a randomly chosen apartment to an LA Fitness in downtown Evanston",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6823290, 42.0498415],
+                "type": "Point"
+            },
+            "end_business_id" : "la-fitness-evanston"
+        },
+        "output": "evanston-athletic-club-evanston"
+    }
+,
+    {
+        "test_name": "Walgreens -> Potbelly's Sandwich Shop",
+        "test_type": "From a pharmacy to one of the best fast food sandwich shops out there",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6247427, 41.8830264],
+                "type": "Point"
+            },
+            "end_business_id": "potbelly-sandwich-shop-chicago-3"
+        },
+        "output": "subway-chicago"
+    }
+,
+    {
+        "test_name": "Chicago Architecture Foundation -> Chase Bank Northbrook",
+        "test_type": "From an architecture foundation in downtown Chicago to a Chase in the north suburbs",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.6247942, 41.8784582],
+                "type": "Point"
+            },
+            "end_business_id" : "chase-bank-northbrook-2"
+        },
+        "output": ""
+    }
+,
+    {
+        "test_name": "Chase Bank Northbrook -> Trader Joe's in Lincoln Park",
+        "test_type": "From a Chase Bank in the North Suburbs to a grocery store in Chicago",
+        "input": {
+            "start_loc": {
+                "coordinates": [-87.8264886, 42.1307608],
+                "type": "Point"
+            },
+            "end_business_id": "trader-joes-chicago-5"
+        },
+        "output": "sunset-foods-northbrook"
+    }
+
+]
diff --git a/emission/integrationTests/suggestionsys/find_candidate_business.dataset.json b/emission/integrationTests/suggestionsys/find_candidate_business.dataset.json
new file mode 100644
index 00000000..ec02ea5d
--- /dev/null
+++ b/emission/integrationTests/suggestionsys/find_candidate_business.dataset.json
@@ -0,0 +1,435 @@
+[
+    {
+        "test_name": "Mountain View Kohls",
+        "test_type": "Suburban big box store in local anchor shopping center ",
+        "input": {
+            "loc": {
+                "coordinates": [-122.1078300, 37.4035500],
+                "type": "Point"
+            }
+        },
+        "output": ["Kohl's Mountain View", "350 Showers Drive", "Mountain View", true]
+    },
+    {
+        "test_name": "Manhattan Beach Kettle",
+        "test_type": "Non-chain restaurant in suburban downtown area",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4097008, 33.8853681],
+                "type": "Point"
+            }
+        },
+        "output": ["The Kettle", "1138 Highland Ave", "Manhattan Beach", true]
+    },
+    {
+        "test_name": "Manhattan Beach Beckers",
+        "test_type": "Suburban bakery, non-chain",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4106739, 33.8842780],
+                "type": "Point"
+            }
+        },
+        "output": ["Becker's Bakery", "Manhattan Beach Ave", "Manhattan Beach", true]
+    },
+
+    {
+        "test_name": "Manhattan Beach FISHBAR", 
+        "test_type": "Suburban local bar/restaurant, non-chain",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4182952, 33.9017119], 
+                "type": "Point"
+            }
+        },
+        "output": ["FishBar", "3801 Highland Ave", "Manhattan Beach", true]
+    },
+
+    {
+        "test_name": "El Segundo Umi",
+        "test_type": "Sushi restaurant in small shopping center",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3947103, 33.9024449],
+                "type": "Point"
+            }
+        },
+        "output": ["Umi by Hamasaku", "860 S Sepulveda Blvd", "El Segundo", true]
+    },
+
+    {
+        "test_name": "Redondo Beach Captain Kidd's",
+        "test_type": "Fish market in seaside town",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3923475, 33.8434248],
+                "type": "Point"
+            }
+        },
+        "output": ["Captain Kidd's", "209 N Harbor Dr", "Redondo Beach", true]
+    },
+
+     {
+        "test_name": "Mira Costa High School Manhattan Beach",
+        "test_type": "Local public school in Los Angeles County",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3893806, 33.8729666],
+                "type": "Point"
+            }
+        },
+        "output": ["Mira Costa High School", "1401 Artesia Blvd", "Manhattan Beach", true]
+    },
+
+
+     {
+        "test_name": "Torrance Black Bear Diner",
+        "test_type": "Small diner in LA County",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3517050, 33.8060869],
+                "type": "Point"
+            }
+        },
+        "output": ["Black Bear Diner", "24021 Hawthorne Blvd", "Torrance", true]
+    },
+
+     {
+        "test_name": "Inglewood In-N-Out Burger",
+        "test_type": "Chain fast food restaurant/drive thru off California freeway",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3324728, 33.9456953],
+                "type": "Point"
+            }
+        },
+        "output": ["In-N-Out Burger", "3411 W Century Blvd", "Inglewood", true]
+    },
+
+    {
+        "test_name": "Torrance Memorial Medical Center",
+        "test_type": "Southern California hospital and medical center",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3468133, 33.8124394],
+                "type": "Point"
+            }
+        },
+        "output": ["Torrance Memorial Medical Center", "Lomita Boulevard", "Torrance", true]
+    }, 
+    {
+        "test_name": "Walmart Supercenter",
+        "test_type": "Suburban big box store by itself in a plaza",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9218589, 37.4310221],
+                "type": "Point"
+            }
+        },
+        "output": ["Walmart Supercenter", "301 Ranch Dr", "Milpitas", true]
+    }, 
+    {   
+        "test_name": "Loving Hut",
+        "test_type": "Restaurant in a large plaza with other restaurants",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9163240, 37.4208679],
+                "type": "Point"
+            }
+        },
+        "output": ["Loving Hut - Milpitas", "516 Barber Ln", "Milpitas", true]
+    }, 
+    {
+        "test_name": "San Francisco Premium Outlets",
+        "test_type": "A large outlet with a lot of stores inside",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8479784, 37.6997385],
+                "type": "Point"
+            }
+        },
+        "output": ["Etro Outlet", "2774 Livermore Outlets Dr", "Livermore", true]
+    },
+    {
+        "test_name": "San Ramon Valley High School",
+        "test_type": "A highschool in a suburban community",
+        "input": {
+            "loc": {
+                "coordinates": [-122.0062950, 37.8273458],
+                "type": "Point"
+            }
+        },
+        "output": ["San Ramon Valley High School", "501 Danville Blvd", "Danville", true]
+    },
+    {
+        "test_name": "Bank of America",
+        "test_type": "A bank that is on the side of a large road",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8937688, 37.4332083],
+                "type": "Point"
+            }
+        },
+        "output": ["Bank of America", "740 E Calaveras Blvd", "Milpitas", true]
+    },
+    {
+        "test_name": "Chevron Milpitas",
+        "test_type": "A gas station next to a highway and neighborhood",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9208686, 37.4520320],
+                "type": "Point"
+            }
+        },
+        "output": ["Chevron", "1551 California Cir", "Milpitas", true]
+    },
+    {
+        "test_name": "Costco",
+        "test_type": "Suburban big box store in a large plaza",
+        "input": {
+            "loc": {
+                "coordinates": [-122.3210599, 37.8989026],
+                "type": "Point"
+            }
+        },
+        "output": ["Costco", "4801 Central Ave", "Richmond", true]
+    }, 
+    {
+        "test_name": "Layang Layang",
+        "test_type": "A restaurant in a plaza with Save Marts",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9110908, 37.4289207],
+                "type": "Point"
+            }
+        },
+        "output": ["Layang Layang", "181 W Calaveras Blvd", "Milpitas", true]
+    }, 
+    {
+        "test_name": "Kaiser Permanente Pediatrics Building",
+        "test_type": "Clinic next to a road",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8938994, 37.4320244],
+                "type": "Point"
+            }
+        },
+        "output": ["Kaiser Permanente Pediatrics Building", "Los Coches Street", "Milpitas", true]
+    }, 
+    {
+        "test_name": "Taco Bell",
+        "test_type": "Chain fast-food restaurant",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8758283, 37.4171766],
+                "type": "Point"
+            }
+        },
+        "output": ["Taco Bell", "1365 S Park Victoria", "Milpitas", true]
+    },
+    {
+        "test_name": "Northbrook Village Hall",
+        "test_type": "Village hall in downtown area in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.8311015, 42.1296436],
+                "type": "Point"
+            }
+        },
+        "output": ["Northbrook Village Hall", "Village Hall Northbrook", "Northbrook Village Hall", true]
+    },
+
+    {
+        "test_name": "Patisserie Coralie",
+        "test_type": "A local patisserie in downtown area in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6799562,  42.0461498],
+                "type": "Point"
+            }
+        },
+        "output": ["Patisserie Coralie", "Patisserie Coralie Evanston"]
+    },
+
+    {
+        "test_name": "Northbrook Public Library",
+        "test_type": "Where I spent a lot of my childhood, reading, studying and crying in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.8310260,  42.1305753],
+                "type": "Point"
+            }
+        },
+        "output": ["Northbrook Public Library", "Northbrook Public Library Northbrook"]
+    },
+    {
+        "test_name": "Town Cleaners",
+        "test_type": "A local dry cleaners in a North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6803244,  42.0454404],
+                "type": "Point"
+            }
+        },
+        "output": ["Town Cleaners", "Town Cleaners Evanston"]
+    },
+
+    {
+        "test_name": "RadioShack Evanston",
+        "test_type": "A RadioShack for music-related tech products in a North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6815733, 42.0483088],
+                "type": "Point"
+            }
+        },
+        "output": ["RadioShack", "RadioShack Evanston"]
+    },
+
+    {
+        "test_name": "Music Institute of Chicago",
+        "test_type": "A music institute of study in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6807234, 42.0449701],
+                "type": "Point"
+            }
+        },
+        "output": ["Music Institute of Chicago", "Music Institute of Chicago Evanston"]
+    },
+    {
+        "test_name": "Squash Blossom",
+        "test_type": "A local jewlery store in Vail, CO ",
+        "input": {
+            "loc": {
+                "coordinates": [-106.3744452, 39.6405737],
+                "type": "Point"
+            }
+        },
+        "output": ["Squash Blossom", "Squash Blossom Vail 2"]
+    },
+
+    {
+        "test_name": "Garfinkel's",
+        "test_type": "A locally owned restaurant in Vail, CO (Lionshead Village) ",
+        "input": {
+            "loc": {
+                "coordinates": [-106.3878760, 39.6432528],
+                "type": "Point"
+            }
+        },
+        "output": ["Garfinkel's", "Garfinkel's Vail"]
+    },
+
+    {
+        "test_name": "Art Institute of Chicago Garden",
+        "test_type": "World-Renowned museum of art in Chicago, garden ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6236237, 41.8795675],
+                "type": "Point"
+            }
+        },
+        "output": ["Art Institute of Chicago", "Art Institute of Chicago Chicago 3", "The Art Institute of Chicago", "Art Institute of Chicago"]
+    },
+    {
+        "test_name": "Pekoe San Jose",
+        "test_type": "Tea shop along major road in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.790188997984, 37.3145584994999],
+                "type": "Point"
+            }
+        },
+        "output": ["Pekoe", "Pekoe San Jose"]
+    },
+    {
+        "test_name": "Mission San Jose High School Fremont",
+        "test_type": "Suburban high school in residential area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.93371753373, 37.5441242756684],
+                "type": "Point"
+            }
+        },
+        "output": ["Mission San Jose High School", "Mission San Jose High School Fremont"]
+    },
+    {
+        "test_name": "Giraffe Learning Center",
+        "test_type": "after school tutoring place in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.946624755859, 37.5413246154785],
+                "type": "Point"
+            }
+        },
+        "output": ["Giraffe Learning Center", "Giraffe Learning Center Fremont"]
+    },
+    {
+        "test_name": "Costco",
+        "test_type": "large wholesale store w/ food court in suburban strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.973287, 37.501845],
+                "type": "Point"
+            }
+        },
+        "output": ["Costco", "Costco Fremont"]
+    },
+    {
+        "test_name": "Ohlone College",
+        "test_type": "large community college in suburban area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.914514, 37.530557],
+                "type": "Point"
+            }
+        },
+        "output": ["Ohlone College", "Ohlone College Fremont"]
+    },
+    {
+        "test_name": "Holiday Inn San Jose - Silicon Valley",
+        "test_type": "large hotel in urban area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.908210754395, 37.3615913391113],
+                "type": "Point"
+            }
+        },
+        "output": ["Holiday Inn San Jose - Silicon Valley", "Holiday Inn San Jose Silicon Valley San Jose", "Holiday Inn"]
+    },
+    {
+        "test_name": "Annie Hair & Beauty",
+        "test_type": "barber shop in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9293976, 37.4890594],
+                "type": "Point"
+            }
+        },
+        "output": ["Annie Hair & Beauty", "Annie Hair & Beauty Fremont"]
+    },
+    {
+        "test_name": "Quik Stop",
+        "test_type": "gas station near highway onramp",
+        "input": {
+            "loc": {
+                "coordinates": [-121.99445, 37.5580042422888],
+                "type": "Point"
+            }
+        },
+        "output": ["Quik Stop", "Quik Stop Fremont"]
+    },
+    {
+        "test_name": "Department of Motor Vehicles",
+        "test_type": "DMV office in central area of town",
+        "input": {
+            "loc": {
+                "coordinates": [-122.00728, 37.55314],
+                "type": "Point"
+            }
+        },
+        "output": ["Department of Motor Vehicles", "Department of Motor Vehicles Fremont 4"]
+    }
+
+]
\ No newline at end of file
diff --git a/emission/integrationTests/suggestionsys/find_destination_business.dataset.json b/emission/integrationTests/suggestionsys/find_destination_business.dataset.json
new file mode 100644
index 00000000..ddd3a518
--- /dev/null
+++ b/emission/integrationTests/suggestionsys/find_destination_business.dataset.json
@@ -0,0 +1,568 @@
+[
+    {
+        "test_name": "Mountain View Kohls",
+        "test_type": "Suburban big box store in local anchor shopping center ",
+        "input": {
+            "loc": {
+                "coordinates": [-122.1078300, 37.4035500],
+                "type": "Point"
+            }
+        },
+        "output": ["Kohl's", "Kohl's Mountain View"]
+    },
+    {
+        "test_name": "Manhattan Beach Kettle",
+        "test_type": "Non-chain restaurant in suburban downtown area",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4097008, 33.8853681],
+                "type": "Point"
+            }
+        },
+        "output": ["Kettle", "The Kettle Manhattan Beach"]
+    },
+    {
+        "test_name": "Manhattan Beach Beckers",
+        "test_type": "Suburban bakery, non-chain",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4106739, 33.8842780],
+                "type": "Point"
+            }
+        },
+        "output": ["Becker's Bakery and Deli", "Becker's Bakery Manhattan Beach"]
+    },
+
+    {
+        "test_name": "Manhattan Beach FISHBAR",
+        "test_type": "Suburban local bar/restaurant, non-chain",
+        "input": {
+            "loc": {
+                "coordinates": [-118.4182952, 33.9017119],
+                "type": "Point"
+            }
+        },
+        "output": ["FISHBAR", "Fishbar Manhattan Beach 2"]
+    },
+
+    {
+        "test_name": "El Segundo Umi",
+        "test_type": "Sushi restaurant in small shopping center",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3947103, 33.9024449],
+                "type": "Point"
+            }
+        },
+        "output": ["Umi", "Umi by Hamasuku El Segundo"]
+    },
+
+    {
+        "test_name": "Redondo Beach Captain Kidd's",
+        "test_type": "Fish market in seaside town",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3923475, 33.8434248],
+                "type": "Point"
+            }
+        },
+        "output": ["Captain Kidds Fish Market", "Captain Kidds Redondo Beach 4"]
+    },
+
+     {
+        "test_name": "Mira Costa High School Manhattan Beach",
+        "test_type": "Local public school in Los Angeles County",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3893806, 33.8729666],
+                "type": "Point"
+            }
+        },
+        "output": ["Mira Costa High School", "Mira Costa High School Manhattan Beach"]
+    },
+
+     {
+        "test_name": "Torrance Black Bear Diner",
+        "test_type": "Small diner in LA County",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3517050, 33.8060869],
+                "type": "Point"
+            }
+        },
+        "output": ["Black Bear Diner", "Black Bear Diner Torrance"]
+    },
+
+     {
+        "test_name": "Inglewood In-N-Out Burger",
+        "test_type": "Chain fast food restaurant/drive thru off California freeway",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3324728, 33.9456953],
+                "type": "Point"
+            }
+        },
+        "output": ["In-N-Out Burger", "In-N-Out Burger Inglewood"]
+    },
+
+    {
+        "test_name": "Torrance Memorial Medical Center",
+        "test_type": "Southern California hospital and medical center",
+        "input": {
+            "loc": {
+                "coordinates": [-118.3468133, 33.8124394],
+                "type": "Point"
+            }
+        },
+        "output": ["Torrance Memorial Medical Center", "Torrance Memorial Medical Center Torrance"]
+    }, 
+    {
+        "test_name": "Walmart Supercenter",
+        "test_type": "Suburban big box store by itself in a plaza",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9218589, 37.4310221],
+                "type": "Point"
+            }
+        },
+        "output": ["Walmart Supercenter", "Walmart Supercenter Milpitas"]
+    }, 
+    {   
+        "test_name": "Loving Hut",
+        "test_type": "Restaurant in a large plaza with other restaurants",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9163240, 37.4208679],
+                "type": "Point"
+            }
+        },
+        "output": ["Loving Hut", "Loving Hut Milpitas Milpitas"]
+    },
+    {
+        "test_name": "San Francisco Premium Outlets",
+        "test_type": "A large outlet with a lot of stores inside",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8479784, 37.6997385],
+                "type": "Point"
+            }
+        },
+        "output": ["San Francisco Premium Outlets", "San Francisco Premium Outlets Livermore 3"]
+    },
+    {
+        "test_name": "San Ramon Valley High School",
+        "test_type": "A highschool in a suburban community",
+        "input": {
+            "loc": {
+                "coordinates": [-122.0062950, 37.8273458],
+                "type": "Point"
+            }
+        },
+        "output": ["San Ramon Valley High School", "San Ramon Valley High School Danville"]
+    },
+    {
+        "test_name": "Bank of America",
+        "test_type": "A bank that is on the side of a large road",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8937688, 37.4332083],
+                "type": "Point"
+            }
+        },
+        "output": ["Bank of America", "Bank of America Milpitas"]
+    },
+    {
+        "test_name": "Chevron Milpitas",
+        "test_type": "A gas station next to a highway and neighborhood",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9208686, 37.4520320],
+                "type": "Point"
+            }
+        },
+        "output": ["Chevron Milpitas", "Chevron Milpitas 3"]
+    },
+    {
+        "test_name": "Costco",
+        "test_type": "Suburban big box store in a large plaza",
+        "input": {
+            "loc": {
+                "coordinates": [-122.3210599, 37.8989026],
+                "type": "Point"
+            }
+        },
+        "output": ["Costco", "Costco Richmond"]
+    }, 
+    {
+        "test_name": "Layang Layang",
+        "test_type": "A restaurant in a plaza with Save Marts",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9110908, 37.4289207],
+                "type": "Point"
+            }
+        },
+        "output": ["Layang Layang", "Layang Layang Milpitas"]
+    }, 
+    {
+        "test_name": "Kaiser Permanente Pediatrics Building",
+        "test_type": "Clinic next to a road",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8938994, 37.4320244],
+                "type": "Point"
+            }
+        },
+        "output": ["Kaiser Permanente Pediatrics Building", "Kaiser Permanente Pediatrics Building Milpitas 2"]
+    },
+    {
+        "test_name": "Taco Bell",
+        "test_type": "Chain fast-food restaurant",
+        "input": {
+            "loc": {
+                "coordinates": [-121.8758283, 37.4171766],
+                "type": "Point"
+            }
+        },
+        "output": ["Taco Bell", "Taco Bell Milpitas"]
+    },
+
+    {
+        "test_name": "Northbrook Village Hall",
+        "test_type": "Village hall in downtown area in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.8311015, 42.1296436],
+                "type": "Point"
+            }
+        },
+        "output": ["Northbrook Village Hall", "Village Hall Northbrook"]
+    },
+
+    {
+        "test_name": "Patisserie Coralie",
+        "test_type": "A local patisserie in downtown area in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6799562,  42.0461498],
+                "type": "Point"
+            }
+        },
+        "output": ["Patisserie Coralie", "Patisserie Coralie Evanston"]
+    },
+
+    {
+        "test_name": "Northbrook Public Library",
+        "test_type": "Where I spent a lot of my childhood, reading, studying and crying in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.8310260,  42.1305753],
+                "type": "Point"
+            }
+        },
+        "output": ["Northbrook Public Library", "Northbrook Public Library Northbrook"]
+    },
+
+    {
+        "test_name": "Music Institute of Chicago",
+        "test_type": "A music institute of study in North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6807234, 42.0449701],
+                "type": "Point"
+            }
+        },
+        "output": ["Music Institute of Chicago", "Music Institute of Chicago Evanston"]
+    },
+
+    {
+        "test_name": "Town Cleaners",
+        "test_type": "A local dry cleaners in a North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6803244,  42.0454404],
+                "type": "Point"
+            }
+        },
+        "output": ["Town Cleaners", "Town Cleaners Evanston"]
+    },
+
+    {
+        "test_name": "RadioShack Evanston",
+        "test_type": "A RadioShack for music-related tech products in a North suburb of Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6815733, 42.0483088],
+                "type": "Point"
+            }
+        },
+        "output": ["RadioShack", "RadioShack Evanston"]
+    },
+
+    {
+        "test_name": "Squash Blossom",
+        "test_type": "A local jewlery store in Vail, CO ",
+        "input": {
+            "loc": {
+                "coordinates": [-106.3744452, 39.6405737],
+                "type": "Point"
+            }
+        },
+        "output": ["Squash Blossom", "Squash Blossom Vail 2"]
+    },
+
+    {
+        "test_name": "Garfinkel's",
+        "test_type": "A locally owned restaurant in Vail, CO (Lionshead Village) ",
+        "input": {
+            "loc": {
+                "coordinates": [-106.3878760, 39.6432528],
+                "type": "Point"
+            }
+        },
+        "output": ["Garfinkel's", "Garfinkel's Vail"]
+    },
+
+    {
+        "test_name": "Art Institute of Chicago Garden",
+        "test_type": "World-Renowned museum of art in Chicago, garden ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6236237, 41.8795675],
+                "type": "Point"
+            }
+        },
+        "output": ["Art Institute's Gardens", "Art Institute of Chicago Chicago 3"]
+    },
+
+    {
+        "test_name": "Bitcoin of America",
+        "test_type": "A bitcoin front-facing company in Chicago ",
+        "input": {
+            "loc": {
+                "coordinates": [-87.6256760, 41.8805215],
+                "type": "Point"
+            }
+        },
+        "output": ["Bitcoin of America", ""]
+    },
+    {
+        "test_name": "Pekoe San Jose",
+        "test_type": "Tea shop along major road in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.790188997984, 37.3145584994999],
+                "type": "Point"
+            }
+        },
+        "output": ["Pekoe", "Pekoe San Jose"]
+    },
+    {
+        "test_name": "99 Ranch Market Fremont",
+        "test_type": "Asian Supermarket in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.03944, 37.57507],
+                "type": "Point"
+            }
+        },
+        "output": ["99 Ranch Market", "99 Ranch Market Fremont"]
+    },
+    {
+        "test_name": "Mission San Jose High School Fremont",
+        "test_type": "Suburban high school in residential area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.93371753373, 37.5441242756684],
+                "type": "Point"
+            }
+        },
+        "output": ["Mission San Jose High School", "Mission San Jose High School Fremont"]
+    },
+    {
+        "test_name": "Giraffe Learning Center",
+        "test_type": "after school tutoring place in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.946624755859, 37.5413246154785],
+                "type": "Point"
+            }
+        },
+        "output": ["Giraffe Learning Center", "Giraffe Learning Center Fremont"]
+    },
+    {
+        "test_name": "Costco",
+        "test_type": "large wholesale store w/ food court in suburban strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.973287, 37.501845],
+                "type": "Point"
+            }
+        },
+        "output": ["Costco", "Costco Fremont"]
+    },
+    {
+        "test_name": "Ohlone College",
+        "test_type": "large community college in suburban area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.914514, 37.530557],
+                "type": "Point"
+            }
+        },
+        "output": ["Ohlone College", "Ohlone College Fremont"]
+    },
+    {
+        "test_name": "Holiday Inn San Jose - Silicon Valley",
+        "test_type": "large hotel in urban area",
+        "input": {
+            "loc": {
+                "coordinates": [-121.908210754395, 37.3615913391113],
+                "type": "Point"
+            }
+        },
+        "output": ["Holiday Inn San Jose - Silicon Valley", "Holiday Inn San Jose Silicon Valley San Jose", "Holiday Inn"]
+    },
+    {
+        "test_name": "Annie Hair & Beauty",
+        "test_type": "barber shop in strip mall",
+        "input": {
+            "loc": {
+                "coordinates": [-121.9293976, 37.4890594],
+                "type": "Point"
+            }
+        },
+        "output": ["Annie Hair & Beauty", "Annie Hair & Beauty Fremont"]
+    },
+    {
+        "test_name": "Quik Stop",
+        "test_type": "gas station near highway onramp",
+        "input": {
+            "loc": {
+                "coordinates": [-121.99445, 37.5580042422888],
+                "type": "Point"
+            }
+        },
+        "output": ["Quik Stop", "Quik Stop Fremont"]
+    },
+    {
+        "test_name": "Department of Motor Vehicles",
+        "test_type": "DMV office in central area of town",
+        "input": {
+            "loc": {
+                "coordinates": [-122.00728, 37.55314],
+                "type": "Point"
+            }
+        },
+        "output": ["Department of Motor Vehicles", "Department of Motor Vehicles Fremont 4"]
+    }
+    ,
+
+    {
+        "test_name": "Italian Homemade",
+        "test_type": "Main Street type commercial district italian restaurant",
+        "input": {
+            "loc": {
+                "coordinates": [-122.252844, 37.858179],
+                "type": "Point"
+            }
+        },
+        "output": ["Italian Homemade", "the-italian-homemade-company-berkeley-3"]
+    }
+,
+    {
+        "test_name": "Jong Ga House",
+        "test_type": "Midtown type commercial district korean barbecue",
+        "input": {
+            "loc": {
+                "coordinates": [-122.254948, 37.809082],
+                "type": "Point"
+            }
+        },
+        "output": ["Jong Ga House", "jong-ga-house-oakland"]
+    }
+,
+    {
+        "test_name": "T Pumps",
+        "test_type": "Midtown type main street boba tea shop",
+        "input": {
+            "loc": {
+                "coordinates": [-122.478639, 37.763643],
+                "type": "Point"
+            }
+        },
+        "output": ["Tpumps", "tpumps-san-francisco"]
+    }
+,
+    {
+        "test_name": "Martinez Commons",
+        "test_type": "Urban apartment building",
+        "input": {
+            "loc": {
+                "coordinates": [-122.258042, 37.866615],
+                "type": "Point"
+            }
+        },
+        "output": ["Maximo Martinez Commons"]
+    }
+,
+    {
+        "test_name": "Richmond District House",
+        "test_type": "Flats in medium/low density SF richmond district",
+        "input": {
+            "loc": {
+                "coordinates": [-122.469817, 37.779966],
+                "type": "Point"
+            }
+        },
+        "output": []
+    }
+,
+    {
+        "test_name": "Novato Unified School District",
+        "test_type": "Suburban office for school district",
+        "input": {
+            "loc": {
+                "coordinates": [-122.578671, 38.109495],
+                "type": "Point"
+            }
+        },
+        "output": ["Novato Unified School District"]
+    }
+,
+    {
+        "test_name": "Tamalpais Pediatrics",
+        "test_type": "Pediatrician's office in suburban medical complex",
+        "input": {
+            "loc": {
+                "coordinates": [-122.540262, 37.944070],
+                "type": "Point"
+            }
+        },
+        "output": ["Tamalpais Pediatrics", "tamalpais-pediatrics-larkspur"]
+    }
+,
+    {
+        "test_name": "Novato Library",
+        "test_type": "Library in suburban setting",
+        "input": {
+            "loc": {
+                "coordinates": [-122.580147, 38.107132],
+                "type": "Point"
+            }
+        },
+        "output": ["Novato Library", "novato-library-novato"]
+    }
+,
+    {
+        "test_name": "O'hair Park",
+        "test_type": "Large park adjacent to open lands",
+        "input": {
+            "loc": {
+                "coordinates": [-122.619220, 38.116237],
+                "type": "Point"
+            }
+        },
+        "output": ["O'Hair Park", "o-hair-park-novato"]
+    }   
+]
diff --git a/emission/load_testing/Dockerfile b/emission/load_testing/Dockerfile
new file mode 100644
index 00000000..61ec66fd
--- /dev/null
+++ b/emission/load_testing/Dockerfile
@@ -0,0 +1,11 @@
+# Choose base image
+
+#pull from github
+
+#insatll the conda environment
+
+#Pull in the locust file
+
+#pull in the conf file
+
+#Get the base url for the webserver
\ No newline at end of file
diff --git a/emission/load_testing/__init__.py b/emission/load_testing/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/emission/load_testing/conf/datagen_client.json b/emission/load_testing/conf/datagen_client.json
new file mode 100644
index 00000000..4acb4d5c
--- /dev/null
+++ b/emission/load_testing/conf/datagen_client.json
@@ -0,0 +1,5 @@
+{
+    "emission_server_base_url": "http://localhost:8080",
+    "register_user_endpoint": "/profile/create",
+    "user_cache_endpoint": "/usercache/put"
+}
\ No newline at end of file
diff --git a/emission/load_testing/conf/user1.json b/emission/load_testing/conf/user1.json
new file mode 100644
index 00000000..0034800f
--- /dev/null
+++ b/emission/load_testing/conf/user1.json
@@ -0,0 +1,36 @@
+{
+            "email" : "fake_user_129",
+
+            "locations" :
+            [
+               {
+                    "label": "home",
+                    "coordinate": [37.77264255,-122.399714854263]
+                },
+
+                {
+                    "label": "work",
+                    "coordinate": [37.42870635,-122.140926605802]
+                },
+                {
+                    "label": "family",
+                    "coordinate": [37.87119, -122.27388]
+                }
+            ],
+            "transition_probabilities":
+            [
+                [0.32833882, 0.06245342, 0.60920776],
+                [0.57634164, 0.20089474, 0.22276363],
+                [0.85068322, 0.07665405, 0.07266273]
+            ],
+
+            "modes" :
+            {
+                "CAR" : [["home", "family"]],
+                "TRANSIT" : [["home", "work"], ["work", "home"]]
+            },
+
+            "default_mode": "CAR",
+            "initial_state" : "home",
+            "radius" : ".1"
+}
diff --git a/emission/load_testing/data_generator.py b/emission/load_testing/data_generator.py
new file mode 100644
index 00000000..e69de29b
diff --git a/emission/load_testing/harness.py b/emission/load_testing/harness.py
new file mode 100644
index 00000000..e69de29b
diff --git a/emission/load_testing/random_email_gen.py b/emission/load_testing/random_email_gen.py
new file mode 100644
index 00000000..6f9240ba
--- /dev/null
+++ b/emission/load_testing/random_email_gen.py
@@ -0,0 +1,6 @@
+import string
+import random
+
+def id_generator(size=6, chars=string.ascii_uppercase + string.digits):
+    """Script borrowed from here: https://stackoverflow.com/questions/2257441/random-string-generation-with-upper-case-letters-and-digits-in-python"""
+    return ''.join(random.choice(chars) for _ in range(size))
\ No newline at end of file
diff --git a/emission/load_testing/user1.py b/emission/load_testing/user1.py
new file mode 100644
index 00000000..643d00e2
--- /dev/null
+++ b/emission/load_testing/user1.py
@@ -0,0 +1,85 @@
+from locust import HttpLocust, TaskSet, task
+from emission.load_testing.random_email_gen import id_generator
+from emission.simulation.client import EmissionFakeDataGenerator
+from bin.purge_database import purgeAllData
+from emission.simulation.fake_user import FakeUser
+import json
+
+#TODO: Seems like there is no need for DataGenClient now that we are using locust. Need to rewrite some stuff.
+#Currently breaking a lot of abstraction barriers.
+
+class UserBehavior(TaskSet):
+    def on_start(self):
+        """ on_start is called when a Locust start before any task is scheduled """
+        self._user_conf_file = open('emission/load_testing/conf/user1.json')
+        self._client_conf_file = open('emission/load_testing/conf/datagen_client.json')
+        user_config = json.load(self._user_conf_file)
+        #Create a random email for this user.
+        user_config['email'] = id_generator(20)
+        client_config = json.load(self._client_conf_file)
+        self._config = client_config
+
+        self.user = self.create_fake_user(user_config)
+
+    def on_stop(self):
+        """ on_stop is called when the TaskSet is stopping """
+        #Close files
+        self._user_conf_file.close()
+        self._client_conf_file.close()
+        #Purge Database
+        purgeAllData()
+
+    @task(1)
+    def take_trip(self):
+        measurements = self.user.take_trip()
+        self.user._flush_cache()
+
+        measurements_no_id = [self._remove_id_field(entry) for entry in measurements]
+        data = {
+            'phone_to_server': measurements_no_id,
+            'user': self.user._email
+        }
+        url = self._config['user_cache_endpoint']
+
+        r = self.client.post(url, json=data)
+        # Check if successful
+        if r.ok:
+            print("%d entries were successfully synced to the server" % len(measurements_no_id))
+        else:
+            print(
+                'Something went wrong when trying to sync your data. Try again or use save_cache_to_file to save your data.')
+            print(r.content)
+
+    @task(2)
+    def sync_data_to_server(self):
+        pass
+
+
+    def create_fake_user(self, config):
+        #TODO: parse the config object
+        uuid = self._register_fake_user(config['email'])
+        config['uuid'] = uuid
+        config['upload_url'] = self._config['emission_server_base_url'] + self._config['user_cache_endpoint']
+        return FakeUser(config)
+
+    def _register_fake_user(self, email):
+        data = {'user': email}
+        url = self._config['register_user_endpoint']
+        r = self.client.post(url, json=data)
+        r.raise_for_status()
+        uuid = r.json()['uuid']
+        #TODO: This is a hack to make all the genereated entries JSON encodeable.
+        #Might be a bad Idead to stringify the uuid. For instance,
+        # the create_entry function expects uuid of type UUID
+        return str(uuid)
+
+    @staticmethod
+    def _remove_id_field(entry):
+        copy = entry.copy()
+        del copy['_id']
+        return copy
+
+class WebsiteUser(HttpLocust):
+    task_set = UserBehavior
+    min_wait = 5000
+    max_wait = 9000
\ No newline at end of file
diff --git a/emission/net/api/cfc_webapp.py b/emission/net/api/cfc_webapp.py
index 93e69cf0..1fa5b3f5 100644
--- a/emission/net/api/cfc_webapp.py
+++ b/emission/net/api/cfc_webapp.py
@@ -45,6 +45,7 @@ import emission.net.auth.auth as enaa
 import emission.net.ext_service.habitica.proxy as habitproxy
 from emission.core.wrapper.client import Client
 from emission.core.wrapper.user import User
+import emission.core.wrapper.suggestion_sys as suggsys
 from emission.core.get_database import get_uuid_db, get_mode_db
 import emission.core.wrapper.motionactivity as ecwm
 import emission.storage.timeseries.timequery as estt
@@ -240,6 +241,16 @@ def putIntoCache():
   from_phone = request.json['phone_to_server']
   return usercache.sync_phone_to_server(user_uuid, from_phone)
 
+@post('/usercache/putone')
+def putIntoOneEntry():
+  logging.debug("Called userCache.putone with request " % request)
+  user_uuid=getUUID(request)
+  logging.debug("user_uuid %s" % user_uuid)
+  the_entry = request.json['the_entry']
+  # sync_phone_to_server requires a list, so we wrap our one entry in the list
+  from_phone = [the_entry]
+  return usercache.sync_phone_to_server(user_uuid, from_phone)
+
 @post('/timeline/getTrips/<day>')
 def getTrips(day):
   logging.debug("Called timeline.getTrips/%s" % day)
@@ -252,6 +263,26 @@ def getTrips(day):
   logging.debug("type(ret_dict) = %s" % type(ret_dict))
   return ret_dict
 
+@post('/suggestion_sys/getSug')
+def getSuggestion():
+  logging.debug("Called suggestion")
+  user_uuid=getUUID(request)
+  logging.debug("user_uuid %s" % user_uuid)
+  ret_dir = suggsys.calculate_yelp_server_suggestion_nominatim(user_uuid)
+  logging.debug("type(ret_dir) = %s" % type(ret_dir))
+  logging.debug("Output of ret_dir = %s" % ret_dir)
+  return ret_dir
+
+@post('/suggestion_sys/getSing/<tripid>')
+def getSingleTripSuggestion(tripid):
+  logging.debug("Called suggestion.getSingleTrip")
+  user_uuid=getUUID(request)
+  logging.debug("user_uuid %s" % user_uuid)
+  ret_dir = suggsys.calculate_yelp_server_suggestion_singletrip_nominatim(user_uuid, tripid)
+  logging.debug("type(ret_dir) = %s" % type(ret_dir))
+  logging.debug("Output of ret_dir = %s" % ret_dir)
+  return ret_dir
+
 @post('/profile/create')
 def createUserProfile():
   try:
diff --git a/emission/net/ext_service/geocoder/nominatim.py b/emission/net/ext_service/geocoder/nominatim.py
index 901f321c..6a9ab47b 100644
--- a/emission/net/ext_service/geocoder/nominatim.py
+++ b/emission/net/ext_service/geocoder/nominatim.py
@@ -9,13 +9,19 @@ from builtins import object
 import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse
 import logging
 import json
+import re
+import requests
 
 from emission.core.wrapper.trip_old import Coordinate
 from pygeocoder import Geocoder as pyGeo  ## We fall back on this if we have to
+from math import sin, cos, sqrt, atan2, radians
 
 try:
     googlemaps_key_file = open("conf/net/ext_service/googlemaps.json")
-    GOOGLE_MAPS_KEY = json.load(googlemaps_key_file)["api_key"]
+    googlemaps_json = json.load(googlemaps_key_file)
+    GOOGLE_MAPS_KEY = googlemaps_json["access_token"]
+    BACKUP_GOOGLE_MAPS_KEY = googlemaps_json["backup_access_token"]
+    NEARBY_URL = googlemaps_json["nearby_base_url"]
 except:
     print("google maps key not configured, falling back to nominatim")
 
@@ -26,7 +32,7 @@ except:
     print("nominatim not configured either, place decoding must happen on the client")
 
 class Geocoder(object):
-
+ 
     def __init__(self):
         pass
         
@@ -40,6 +46,7 @@ class Geocoder(object):
         query_url = NOMINATIM_QUERY_URL + "/search?"
         encoded_params = urllib.parse.urlencode(params)
         url = query_url + encoded_params
+        logging.debug("For geocoding, using URL %s" % url)
         return url
 
     @classmethod
@@ -72,6 +79,7 @@ class Geocoder(object):
         query_url = NOMINATIM_QUERY_URL + "/reverse?"
         encoded_params = urllib.parse.urlencode(params)
         url = query_url + encoded_params
+        logging.debug("For reverse geocoding, using URL %s" % url)
         return url
 
     @classmethod
@@ -84,16 +92,218 @@ class Geocoder(object):
 
     @classmethod
     def reverse_geocode(cls, lat, lng):
-        # try:
-        #     jsn = cls.get_json_reverse(lat, lng)
-        #     address = jsn["display_name"]
-        #     return address
-
-        # except:
-        #     print "defaulting"
-        return _do_google_reverse(lat, lng) # Just in case
+        try:
+            jsn = cls.get_json_reverse(lat, lng)
+            business_name = jsn["display_name"]
+            address = jsn["address"]
+            return business_name, address
+        except:
+            print("defaulting")
+            return _do_google_reverse(lat, lng) # Just in case
 
 ## Failsafe section
+
+'''
+GOOGLE LOOKUP VERS: Function that RETURNS a list of business locations near or at the latitude 
+and longitude point given. 
+
+Uses the helper function check_against_business_location. 
+
+The lat, lon are converted into a string, so that it is easier to have it all in one variable 
+in querying for the results through the API call. 
+
+Moved these functions from suggestion_sys.py to nominatim.py because wanted to reduce the 
+number of times of opening the same json file and nominatim.py was already calling 
+the google maps and nominatim json files, so that's why these lookup functions are now 
+in nominatim.py
+
+Attempted to replace the google reverse lookup function with the nominatim.py version of the 
+function, but it encountered an error in the pygeocoder file that is in anaconda.
+Thus, decided to move the original google reverse functions from suggestion_sys.py 
+to nominatim.py
+'''
+def check_against_business_location(lat, lon, address = ''):
+    location_first = lat + ',' + lon
+    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location_first):
+        raise ValueError('Location Invalid')
+    base_url = NEARBY_URL
+    location = 'location=' + location_first
+    try:
+        key_string = '&key=' + GOOGLE_MAPS_KEY
+        radius = '&radius=10'
+        url = base_url + location + radius + key_string
+        result = requests.get(url).json()
+        cleaned = result['results']
+        for i in cleaned:
+            logging.debug("For amenity %s, comparing address %s with nearby business %s" %
+                (i['name'], address, i['vicinity']))
+            #If the street address matches the street address of this business, we return a tuple
+            #signifying success and the business name
+            if address == i['vicinity']:
+                return (True, i['name'])
+        else:
+            return (False, '')
+    except:
+        try:
+            key_string = '&key=' + BACKUP_GOOGLE_MAPS_KEY
+            radius = '&radius=10'
+            url = base_url + location + radius + key_string
+            result = requests.get(url).json()
+            cleaned = result['results']
+            for i in cleaned:
+                if address == i['vicinity']:
+                    return (True, i['name'])
+            else:
+                return (False, '')
+        except:
+            raise ValueError("Something went wrong")
+
+def return_address_from_location_google(lat, lon):
+    """
+    Creates a Google Maps API call that returns the addresss given a lat, lon
+    """
+    location = lat + ',' + lon
+    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
+        raise ValueError('Location Invalid')
+    base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'
+    latlng = 'latlng=' + location
+    try:
+        #This try block is for our first 150,000 requests. If we exceed this, use Jack's Token.
+        key_string = '&key=' + GOOGLE_MAPS_KEY
+        url = base_url + latlng + key_string #Builds the url
+        # logging.debug("About to query google with URL %s" % url)
+        result = requests.get(url).json() #Gets google maps json file
+        cleaned = result['results'][0]['address_components']
+        logging.debug("Components from address lookup = %s" % cleaned)
+        #Address to check against value of check_against_business_location
+        chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
+        business_tuple = check_against_business_location(lat, lon, chk)
+        logging.debug("After checking = %s, got business tuple %s " % (chk, business_tuple))
+        location_is_service = isLocationService(cleaned)
+        address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name']
+        if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
+            #, cleaned[3]['short_name'], address_comp
+            business_name = business_tuple[1]
+        else:
+            business_name = None
+
+        return business_name, address_comp, cleaned[3]['short_name'], location_is_service
+    except:
+        try:
+            #Use Jack's Token in case of some invalid request problem with other API Token
+            key_string = '&key=' + BACKUP_GOOGLE_MAPS_KEY
+            url = base_url + latlng + key_string #Builds the url
+            result = requests.get(url).json() #Gets google maps json file
+            cleaned = result['results'][0]['address_components']
+            location_is_service = isLocationService(cleaned)
+            #Address to check against value of check_against_business_location
+            chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
+            business_tuple = check_against_business_location(lat, lon, chk)
+            if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
+                address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] 
+                return business_tuple[1], cleaned[3]['short_name'], address_comp, location_is_service
+            else: #otherwise, we just return the address
+                return cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name'] + ', ' + cleaned[3]['short_name'], location_is_service
+        except:
+            raise ValueError("Something went wrong")
+
+
+def return_list_of_addresses_from_location_google(lat, lon):
+    """
+    Creates a Google Maps API call that returns the addresss given a lat, lon
+    """
+    location = lat + ',' + lon
+    if not re.compile('^(\-?\d+(\.\d+)?),\s*(\-?\d+(\.\d+)?)$').match(location):
+        raise ValueError('Location Invalid')
+    base_url = 'https://maps.googleapis.com/maps/api/geocode/json?'
+    latlng = 'latlng=' + location
+    addresses = []
+    try:
+        #This try block is for our first 150,000 requests. If we exceed this, use Jack's Token.
+        key_string = '&key=' + GOOGLE_MAPS_KEY
+        url = base_url + latlng + key_string #Builds the url
+        # logging.debug("About to query google with URL %s" % url)
+        result = requests.get(url).json() #Gets google maps json file
+        count = 0
+        for r in result['results']:
+            cleaned = r['address_components']
+            logging.debug("Components from address lookup = %s" % cleaned)
+            #Address to check against value of check_against_business_location
+            chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
+            business_tuple = check_against_business_location(lat, lon, chk)
+            logging.debug("After checking = %s, got business tuple %s " % (chk, business_tuple))
+            location_is_service = isLocationService(cleaned)
+            address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name']
+            if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
+                #, cleaned[3]['short_name'], address_comp
+                business_name = business_tuple[1]
+            else:
+                business_name = None
+            count+=1
+            addresses.append((business_name, address_comp, cleaned[3]['short_name'], location_is_service))
+            print(addresses)
+        return addresses
+            
+        # print(addresses)
+        # return addresses
+
+        # cleaned = result['results'][0]['address_components']
+        # logging.debug("Components from address lookup = %s" % cleaned)
+        # #Address to check against value of check_against_business_location
+        # chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
+        # business_tuple = check_against_business_location(lat, lon, chk)
+        # logging.debug("After checking = %s, got business tuple %s " % (chk, business_tuple))
+        # location_is_service = isLocationService(cleaned)
+        # address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name']
+        # if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
+        #     #, cleaned[3]['short_name'], address_comp
+        #     business_name = business_tuple[1]
+        # else:
+        #     business_name = None
+
+    except:
+        try:
+            #Use Jack's Token in case of some invalid request problem with other API Token
+            key_string = '&key=' + BACKUP_GOOGLE_MAPS_KEY
+            url = base_url + latlng + key_string #Builds the url
+            result = requests.get(url).json() #Gets google maps json file
+            count = 0
+            for r in result['results']:
+                cleaned = r['address_components']
+                logging.debug("Components from address lookup = %s" % cleaned)
+                #Address to check against value of check_against_business_location
+                chk = cleaned[0]['long_name'] + ' ' + cleaned[1]['long_name'] + ', ' + cleaned[3]['long_name']
+                business_tuple = check_against_business_location(lat, lon, chk)
+                logging.debug("After checking = %s, got business tuple %s " % (chk, business_tuple))
+                location_is_service = isLocationService(cleaned)
+                address_comp = cleaned[0]['long_name'] + ' ' + cleaned[1]['short_name']
+                if business_tuple[0]: #If true, the lat, lon matches a business location and we return business name
+                    #, cleaned[3]['short_name'], address_comp
+                    business_name = business_tuple[1]
+                else:
+                    business_name = None
+                count +=1
+                addresses.append((business_name, address_comp, cleaned[3]['short_name'], location_is_service))
+            print(addresses)
+            return addresses
+            
+            # return addresses
+        except:
+            raise ValueError("Something went wrong")
+
+'''
+Function that checks if location was a place of service or a residential area. RETURNS TRUE 
+if it is a location of service, FALSE otherwise
+'''
+def isLocationService(address_components):
+    for a in address_components:
+        types_of_service = a["types"]
+        longname = a["long_name"]
+        for t in types_of_service:
+            if t == "premise" or t == "neighborhood" and "Downtown" not in longname:
+                return False
+    return True
+
 def _do_google_geo(address):
     geo = pyGeo(GOOGLE_MAPS_KEY)
     results = geo.geocode(address)
@@ -103,3 +313,75 @@ def _do_google_reverse(lat, lng):
     geo = pyGeo(GOOGLE_MAPS_KEY)
     address = geo.reverse_geocode(lat, lng)
     return address[0]
+
+#google API call to find nearby places
+def places_nearby_google(lat, lon):
+    trial_type = "restaurant"
+    url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json?location=" + lat + "," + lon + "&radius=6" + "&type=" + trial_type + "&key=" + GOOGLE_MAPS_KEY
+    result = requests.get(url).json()
+    i = 0
+    types = ["art_gallery", "bank", "bakery", "beauty_salon", "cafe", "city_hall", "clothing_store", "convenience_store", "department_store", "dentist", "gas_station", "hospital", "jewelry_store", "local_government_office", "lodging", "library", "school", "spa", "store", "supermarket"]
+    while len(result.get("results")) == 0 and i < len(types) - 1:
+        i += 1
+        trial_type = types[i]
+        print(trial_type)
+        url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json?location=" + lat + "," + lon + "&radius=6" + "&type=" + trial_type + "&key=" + GOOGLE_MAPS_KEY
+        result = requests.get(url).json()
+    if i == len(types) - 1:
+        return "No result found for this location"
+    return result.get("results")[0].get("name")
+
+def places_nearby_google_using_address(lat, lon):
+    address = return_address_from_location_google(lat, lon)
+    street_and_number = address[1]
+    street_and_number = street_and_number.split(" ")
+    city = address[2]
+    city = city.split(" ")
+    url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input="
+    for i in range(0, len(street_and_number)):
+        url += "%20" + street_and_number[i]
+    url += "%2C"
+    for i in range(len(city)):
+        url += "%20" + city[i]
+    url += "&inputtype=textquery&key=" + GOOGLE_MAPS_KEY + "&fields=formatted_address,name,place_id,opening_hours,rating,types" + "&locationbias=circle:100@" + lat + "," + lon
+    return requests.get(url).json()
+
+def businesses_nearby_google(lat, lon):
+    address = return_address_from_location_google(lat, lon)
+    start_url = "https://maps.googleapis.com/maps/api/place/textsearch/json?query=businesses+near"
+    street_and_number = address[1]
+    street_and_number = street_and_number.split(" ")
+    city = address[2]
+    city = city.split(" ")
+    for i in range(0, len(street_and_number)):
+        start_url += "+" + street_and_number[i]
+    for i in range(0, len(city)):
+        start_url += "+" + city[i]
+    start_url += "&radius=1" + "&key=" + GOOGLE_MAPS_KEY
+    businesses = {}
+    types = ["restaurant", "art_gallery", "bank", "bakery", "beauty_salon", "cafe", "city_hall", "clothing_store", "convenience_store", "department_store", "dentist", "gas_station", "hospital", "jewelry_store", "local_government_office", "lodging", "library", "school", "shopping_center", "spa", "store", "supermarket"]
+    i = 0
+    while i < len(types) - 1:
+        url = start_url + "&type=" + types[i]
+        result = requests.get(url).json()
+        for j in range(len(result.get("results"))):
+            businesses[result.get("results")[j].get("name")] = distance_latitude_longitude(float(lat), float(lon), 
+                float(result.get("results")[j].get("geometry").get("location").get("lat")),
+                float(result.get("results")[j].get("geometry").get("location").get("lng")))
+        i += 1
+    print(sorted(businesses, key=businesses.get, reverse = False))
+    return sorted(businesses, key=businesses.get, reverse = False)[0]
+
+def distance_latitude_longitude(lat1, lon1, lat2, lon2):
+    R = 6373.0
+    lat1 = radians(lat1)
+    lon1 = radians(lon1)
+    lat2 = radians(lat2)
+    lon2 = radians(lon2)
+    dlon = lon2 - lon1
+    dlat = lat2 - lat1
+    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2
+    c = 2 * atan2(sqrt(a), sqrt(1 - a))
+    distance = R * c
+    return distance 
+
diff --git a/emission/net/ext_service/otp/otp.py b/emission/net/ext_service/otp/otp.py
index ca47fa72..2d0d0606 100644
--- a/emission/net/ext_service/otp/otp.py
+++ b/emission/net/ext_service/otp/otp.py
@@ -2,6 +2,7 @@ from __future__ import print_function
 from __future__ import division
 from __future__ import unicode_literals
 from __future__ import absolute_import
+
 ## Library to make calls to our Open Trip Planner server
 ## Hopefully similiar to googlemaps.py
 
@@ -16,6 +17,13 @@ from past.utils import old_div
 import urllib.request, urllib.parse, urllib.error, urllib.request, urllib.error, urllib.parse, datetime, time, random
 import geojson as gj
 import arrow
+from polyline.codec import PolylineCodec
+from geopy.distance import great_circle
+import requests
+import pandas as pd
+from uuid import UUID
+import random
+import logging
 # from traffic import get_travel_time
 
 # Our imports
@@ -29,6 +37,15 @@ import emission.storage.timeseries.abstract_timeseries as esta
 import emission.core.wrapper.rawtrip as ecwrt
 import emission.core.wrapper.entry as ecwe
 import emission.core.wrapper.section as ecws
+# new imports
+import emission.core.wrapper.transition as ecwt
+import emission.core.wrapper.location as ecwl
+import emission.core.wrapper.rawplace as ecwrp
+import emission.core.wrapper.stop as ecwrs
+import emission.core.wrapper.motionactivity as ecwm
+import emission.analysis.intake.segmentation.trip_segmentation as eaist 
+import emission.analysis.intake.segmentation.section_segmentation as eaiss
+import emission.storage.decorations.analysis_timeseries_queries as esda
 
 try:
     import json
@@ -83,7 +100,8 @@ class OTP(object):
         query_url = "%s/otp/routers/default/plan?" % address
         encoded_params = urllib.parse.urlencode(params)
         url = query_url + encoded_params
-        print(url)
+        #print(url)
+        add_file.close()
         return url
 
     def get_json(self):
@@ -98,104 +116,250 @@ class OTP(object):
         for itin in range(num_its):
             trps.append(self.turn_into_trip(_id, user_id, trip_id, False, itin))
         return trps
+    
+    def get_measurements_along_route(self, user_id):
+        """
+        Returns a list of measurements along trip based on OTP data. Measurements inlcude
+        location entries and motion entries. Motion entries are included so the pipeline can
+        determine the mode of transportation for each section of the trip. 
+        """
+        measurements = []
+        otp_json = self.get_json()
+        self._raise_exception_if_no_plan(otp_json)
+        time_stamps_seen = set()
 
-    def turn_into_new_trip(self, user_id):
-        print("new trip")
-        ts = esta.TimeSeries.get_time_series(user_id)
-        trip = ecwrt.Rawtrip()
-        sections = []
-        our_json = self.get_json()
-        mode_list = set ( )
+        #We iterate over the legs and create loation entries for based on the leg geometry.
+        #the leg geometry is just a long list of coordinates along the leg.
+        for i, leg in enumerate(otp_json["plan"]["itineraries"][0]['legs']):
+            #If there are points along this leg 
+            if leg['legGeometry']['length'] > 0:
+                #Add a new motion measurement based on the leg mode. This is necessary for the
+                #pipeline to detect the mode of transportation and to differentiate sections.
+                measurements.append(create_motion_entry_from_leg(leg, user_id))
+                
+                #TODO: maybe we shoudl check if the leg start time is less than the last timestamp to ensure
+                #that we are allways moving forward in time
+                leg_start = otp_time_to_ours(leg['startTime'])
+                leg_end = otp_time_to_ours(leg['endTime'])
+                leg_start_time = leg_start.timestamp + leg_start.microsecond/1e6
+                leg_end_time = leg_end.timestamp + leg_end.microsecond/1e6
 
+                coordinates = PolylineCodec().decode(leg['legGeometry']['points'])
+                prev_coord = coordinates[0]
+                velocity = get_average_velocity(leg_start_time, leg_end_time, float(leg['distance']))
+                altitude = 0 
+                time_at_prev_coord = leg_start_time
+                #print('Speed along leg(m/s)', velocity)
 
-        if "plan" not in our_json:
-            print("While querying alternatives from %s to %s" % (self.start_point, self.end_point))
-            print("query URL is %s" % self.make_url())
-            print("Response %s does not have a plan " % our_json)
-            raise PathNotFoundException(our_json['debugOutput'])
-
-        trip.start_loc = gj.Point( (float(our_json["plan"]["from"]["lat"]), float(our_json["plan"]["from"]["lon"])) ) 
-        trip.end_loc = gj.Point( (float(our_json["plan"]["to"]["lat"]), float(our_json["plan"]["to"]["lon"])) ) 
-        trip.start_local_dt = ecsdlq.get_local_date(otp_time_to_ours(
-            our_json['plan']['itineraries'][0]["startTime"]).timestamp, "UTC")
-        trip.end_local_dt = ecsdlq.get_local_date(otp_time_to_ours(
-            our_json['plan']['itineraries'][0]["endTime"]).timestamp, "UTC")
-        trip_id = ts.insert(ecwe.Entry.create_entry(user_id, "segmentation/raw_trip", trip))
-
-        for leg in our_json["plan"]["itineraries"][0]['legs']:
-            section = ecws.Section()
-            section.trip_id = trip_id
-            section.start_local_dt = ecsdlq.get_local_date(otp_time_to_ours(
-                leg["startTime"]).timestamp, "UTC")
-            section.end_local_dt = ecsdlq.get_local_date(otp_time_to_ours(
-                leg["endTime"]).timestamp, "UTC")
-            section.distance = float(leg["distance"])
-            section.start_loc = gj.Point( (float(leg["from"]["lat"]), float(leg["from"]["lon"])) )
-            section.end_loc = gj.Point( (float(leg["to"]["lat"]), float(leg["to"]["lon"])) )
-            ts.insert_data(user_id, "segmentation/raw_section", section)
- 
-    def turn_into_trip(self, _id, user_id, trip_id, is_fake=False, itinerary=0):
-        sections = [ ]
-        our_json = self.get_json()
-        mode_list = set()
-        car_dist = 0
-        if "plan" not in our_json:
+                for j, curr_coordinate in enumerate(coordinates):
+                    if j == 0:
+                        curr_timestamp = leg_start_time
+                    elif j == len(coordinates) - 1:
+                        #We store the last coordinate so we can duplicate it at a later point in time.
+                        # This is necessary for the piepline to detect that the trip has ended. 
+                        # TODO: should we make sure the last timestamp is the same as leg['endTime']?  
+                        last_coordinate = curr_coordinate
+                        curr_timestamp = get_time_at_next_location(curr_coordinate, prev_coord, time_at_prev_coord, velocity)
+                    else:
+                        #Estimate the time at the current location
+                        curr_timestamp = get_time_at_next_location(curr_coordinate, prev_coord, time_at_prev_coord, velocity)
+                        #TODO: Check if two time stamps are equal, add a lil extra time to make sure all timestamps are unique
+                        #Hack to make the timestamps unique. 
+                        # Also, we only need to keep track of previous timestamp.
+                        while int(curr_timestamp) in time_stamps_seen:
+                            #print(curr_timestamp)
+                            curr_timestamp += 1 
+
+                    time_stamps_seen.add(int(curr_timestamp))
+                    ##TODO: remove this debug print statement
+                    #print(arrow.get(curr_timestamp).format(), curr_coordinate)
+
+                    measurements.append(create_measurement(curr_coordinate, float(curr_timestamp), velocity, altitude, user_id))
+                    prev_coord = curr_coordinate
+                    time_at_prev_coord = curr_timestamp
+    
+        # We need to add one more measurement to indicate to the pipeline that the trip has ended. This value is hardcoded
+        # based on the dwell segmentation dist filter time delta threshold.
+        idle_time_stamp = arrow.get(curr_timestamp).shift(seconds=+ 1000).timestamp
+        #print(arrow.get(idle_time_stamp), last_coordinate) 
+        measurements.append(create_measurement(last_coordinate, float(idle_time_stamp), 0, altitude, user_id))            
+        return measurements
+
+    def _raise_exception_if_no_plan(self, otp_json):
+        if "plan" not in otp_json:
             print("While querying alternatives from %s to %s" % (self.start_point, self.end_point))
             print("query URL is %s" % self.make_url())
-            print("Response %s does not have a plan " % our_json)
-            raise PathNotFoundException(our_json['debugOutput'])
-
-        for leg in our_json["plan"]["itineraries"][itinerary]['legs']:
-            coords = [ ]
-            var = 'steps'
-            if leg['mode'] == 'RAIL' or leg['mode'] == 'SUBWAY':
-                var = 'intermediateStops'
-                for step in leg[var]:
-                    coords.append(Coordinate(step['lat'], step['lon'])) 
-
-            start_time = otp_time_to_ours(leg["startTime"])
-            end_time = otp_time_to_ours(leg["endTime"])
-            distance = float(leg['distance'])
-            start_loc = Coordinate(float(leg["from"]["lat"]), float(leg["from"]["lon"]))
-            end_loc = Coordinate(float(leg["to"]["lat"]), float(leg["to"]["lon"]))
-            coords.insert(0, start_loc)
-            coords.append(end_loc)
-            mode = leg["mode"]
-            mode_list.add(mode)
-            fake_id = random.random()
-            points = [ ]
-            for step in leg['steps']:
-                c = Coordinate(step["lat"], step['lon'])
-                #print c
-                points.append(c)
-            #print "len of points is %s" % len(points)
-            section = Section(str(fake_id), user_id, trip_id, distance, "move", start_time, end_time, start_loc, end_loc, mode, mode, points)
-            #section.points = coords
-            sections.append(section)
-            if mode == 'CAR':
-                car_dist = distance
-                car_start_coordinates = Coordinate(float(leg["from"]["lat"]), float(leg["from"]["lon"]))    
-                car_end_coordinates = Coordinate(float(leg["to"]["lat"]), float(leg["to"]["lon"]))
-        
-        print("len(sections) = %s" % len(sections))
-        final_start_loc = Coordinate(float(our_json["plan"]["from"]["lat"]), float(our_json["plan"]["from"]["lon"]))         
-        final_end_loc = Coordinate(float(our_json["plan"]["to"]["lat"]), float(our_json["plan"]["to"]["lon"]))
-        final_start_time = otp_time_to_ours(our_json['plan']['itineraries'][0]["startTime"])
-        final_end_time = otp_time_to_ours(our_json['plan']['itineraries'][0]["endTime"])
-        cost = 0
-        if "RAIL" in mode_list or "SUBWAY" in mode_list:
-            try:
-                cost = old_div(float(our_json['plan']['itineraries'][0]['fare']['fare']['regular']['cents']), 100.0)   #gives fare in cents 
-            except:
-                cost = 0
-        elif "CAR" in mode_list:
-            # TODO calculate car cost
-            cost = 0
-        mode_list = list(mode_list)
-        if is_fake:
-            return Trip(_id, user_id, trip_id, sections, final_start_time, final_end_time, final_start_loc, final_end_loc)
-        return Alternative_Trip(_id, user_id, trip_id, sections, final_start_time, final_end_time, final_start_loc, final_end_loc, 0, cost, mode_list)
+            print("Response %s does not have a plan " % otp_json)
+            raise PathNotFoundException(otp_json['debugOutput'])
+
+   
+#####Helpers######
+def get_time_at_next_location(next_loc, prev_loc, time_at_prev, velocity):
+    """
+    Returns timestamp for next location entry.
+    Note: Velocity must be given in meters/second
+    """
+    time_at_prev_arrow = arrow.get(time_at_prev)
+    distance = great_circle(prev_loc, next_loc).meters
+    time_delta_seconds = distance/velocity
+    time_at_next = time_at_prev_arrow.shift(seconds=+time_delta_seconds)
+    new_time = time_at_next.timestamp + time_at_next.microsecond/1e6
+    #print('time at next loc', new_time)
+    return new_time
+
+def create_measurement(coordinate, timestamp, velocity, altitude, user_id):
+    #TODO: Rename to create_location_measurement
+    """
+    Creates location entry.
+    """
+    new_loc = ecwl.Location(
+        ts = timestamp, 
+        latitude = coordinate[0],
+        longitude = coordinate[1],
+        sensed_speed = velocity,
+        accuracy = 0,
+        bearing = 0,
+        filter = 'distance',
+        fmt_time = arrow.get(timestamp).to('UTC').format(),
+        #This should not be neseceary. TODO: Figure out how we can avoind this.
+        loc = gj.Point( (coordinate[1], coordinate[0]) ),
+        local_dt = ecsdlq.get_local_date(timestamp, 'UTC'),
+        altitude = altitude 
+    )
+    entry = ecwe.Entry.create_entry(user_id,"background/filtered_location", new_loc, create_id=True)
+    #This field ('type') is required by the server when we push the entry to the user cache
+    # so we add it here. Also we just chose an abritrary formater. In the future we might want to 
+    # create a fromater group called fake user. 
+    entry['metadata']['type'] = 'sensor-data'
+    entry['metadata']['platform'] = 'android'
+    #entry['data']['bearing'] = 0
+    return entry
+
+def get_average_velocity(start_time, end_time, distance):
+    """
+    Calculates average velocity in meters per second
+    """
+    start_time_arrow = arrow.get(start_time)
+    end_time_arrow = arrow.get(end_time)
+    time_delta = end_time_arrow - start_time_arrow
+    velocity = distance/time_delta.total_seconds()
+    return velocity
+
+def get_elevation(coordinate):
+    #Code borrowed form here: https://stackoverflow.com/questions/19513212/can-i-get-the-altitude-with-geopy-in-python-with-longitude-latitude
+    #Consider hosting our own instance of open-elevation
+    query = "https://api.open-elevation.com/api/v1/lookup?locations={0},{1}".format(coordinate[0], coordinate[1])
+    r = requests.get(query).json()  # json object, various ways you can extract value
+    # one approach is to use pandas json functionality:
+    elevation = pd.io.json.json_normalize(r, 'results')['elevation'].values[0]
+    return float(elevation)
 
 def otp_time_to_ours(otp_str):
     return arrow.get(old_div(int(otp_str),1000))
 
+
+def create_motion_entry_from_leg(leg, user_id):
+    #TODO: Update with all possible/supported OTP modes. Also check for leg == None
+    #Also, make sure this timestamp is correct 
+    timestamp = float(otp_time_to_ours(leg['startTime']).timestamp)
+    print("*** Leg Start Time: %s" % arrow.get(timestamp).format())
+    opt_mode_to_motion_type = {
+        'BICYCLE': ecwm.MotionTypes.BICYCLING.value,
+        'CAR': ecwm.MotionTypes.IN_VEHICLE.value,
+        'RAIL': ecwm.MotionTypes.IN_VEHICLE.value,
+        'WALK': ecwm.MotionTypes.WALKING.value
+    }
+    new_motion_activity = ecwm.Motionactivity(
+        ts = timestamp,
+        type = opt_mode_to_motion_type[leg['mode']],
+        #The following two lines were added to satisfy the formatters/android/motion_activity.py script
+        zzaKM = opt_mode_to_motion_type[leg['mode']],
+        zzaKN = 100.0, 
+        fmt_time = arrow.get(timestamp).to('UTC').format(),
+        local_dt = ecsdlq.get_local_date(timestamp, 'UTC'),
+        confidence = 100.0
+    )
+    entry = ecwe.Entry.create_entry(user_id, "background/motion_activity", new_motion_activity, create_id=True) 
+    #This field ('type') is required by the server when we push the entry to the user cache
+    # so we add it here.
+    entry['metadata']['type'] = 'sensor-data'
+    #For some reason the android formater overwrites ts with metadata.write_ts. 
+    #so we need to set write_ts to ts to make sure they become the same. 
+    entry['metadata']['write_ts'] = timestamp
+    entry['metadata']['platform'] = 'android'
+    return entry
+
+def create_start_location_from_trip_plan(plan):
+    #TODO: Old function. Should be removed
+    converted_time = otp_time_to_ours(plan['itineraries'][0]["startTime"])
+    time_stamp = converted_time.timestamp
+    local_dt = ecsdlq.get_local_date(time_stamp, 'UTC')
+    fmt_time = converted_time.to("UTC").format()
+    loc = gj.Point( (float(plan["from"]["lon"]), float(plan["from"]["lat"])) )
+    start_loc = ecwl.Location(
+        ts =time_stamp, 
+        local_dt =local_dt,
+        fmt_time= fmt_time,
+        loc = loc
+    )
+    return start_loc
+
+def create_end_location_from_trip_plan(plan):
+    #TODO: Old function. Should be removed
+    converted_time = otp_time_to_ours(plan['itineraries'][0]["endTime"])
+    time_stamp = converted_time.timestamp
+    local_dt = ecsdlq.get_local_date(time_stamp, 'UTC')
+    fmt_time = converted_time.to("UTC").format()
+    loc = gj.Point( (float(plan["to"]["lon"]), float(plan["to"]["lat"])) )
+    end_loc = ecwl.Location(
+        ts =time_stamp, 
+        local_dt =local_dt,
+        fmt_time= fmt_time,
+        loc = loc
+    )
+    return end_loc
+
+
+def create_start_location_from_leg(leg):
+    #TODO: Old function. Should be removed
+    converted_time = otp_time_to_ours(leg['startTime'])
+    time_stamp = converted_time.timestamp
+    local_dt = ecsdlq.get_local_date(time_stamp, 'UTC')
+    fmt_time = converted_time.to("UTC").format()
+    loc = gj.Point( (float(leg["from"]["lon"]), float(leg["from"]["lat"])) )
+    start_loc = ecwl.Location(
+        ts =time_stamp, 
+        local_dt =local_dt,
+        fmt_time= fmt_time,
+        loc = loc
+    )
+    return start_loc
+
+def create_end_location_from_leg(leg):
+    #TODO: Old function. Should be removed
+    converted_time = otp_time_to_ours(leg['endTime'])
+    time_stamp = converted_time.timestamp
+    local_dt = ecsdlq.get_local_date(time_stamp, 'UTC')
+    fmt_time = converted_time.to("UTC").format()
+    loc = gj.Point( (float(leg["to"]["lon"]), float(leg["to"]["lat"])) )
+    end_loc = ecwl.Location(
+        ts =time_stamp, 
+        local_dt =local_dt,
+        fmt_time= fmt_time,
+        loc = loc
+    )
+    return end_loc
+
+def opt_mode_to_motiontype(opt_mode):
+    #TODO: this needs to be made more sophisticated. This should include all modes supported by OTP client
+    # and emission server.
+    mapping = {
+        'CAR': ecwm.MotionTypes.IN_VEHICLE,
+        'RAIL': ecwm.MotionTypes.IN_VEHICLE,
+        'WALK': ecwm.MotionTypes.WALKING
+    }
+    if opt_mode in mapping.keys():
+        return mapping[opt_mode]
+    else:
+        return ecwm.MotionTypes.UNKNOWN
+
diff --git a/emission/net/ext_service/otp/planner.json b/emission/net/ext_service/otp/planner.json
index 8d7aef40..86d9f997 100644
--- a/emission/net/ext_service/otp/planner.json
+++ b/emission/net/ext_service/otp/planner.json
@@ -1,3 +1,3 @@
 {
-	"open_trip_planner_instance_address" : "http://54.162.140.55:8080"
+	"open_trip_planner_instance_address" : "http://18.209.111.117"
 }
\ No newline at end of file
diff --git a/emission/net/ext_service/otp/test_otp.py b/emission/net/ext_service/otp/test_otp.py
new file mode 100644
index 00000000..e591ec73
--- /dev/null
+++ b/emission/net/ext_service/otp/test_otp.py
@@ -0,0 +1,144 @@
+import unittest
+import random
+import datetime 
+import emission.net.ext_service.otp.otp as otp
+import emission.core.wrapper.location as ecwl
+import emission.storage.decorations.local_date_queries as ecsdlq
+import emission.core.wrapper.user as ecwu
+import emission.storage.timeseries.cache_series as estcs
+import emission.storage.timeseries.abstract_timeseries as esta
+from past.utils import old_div
+import arrow
+import geocoder
+import requests
+
+
+class TestOTPMethods(unittest.TestCase):
+    def setUp(self):
+        start_point_1 = (37.77264255,-122.399714854263)
+        end_point_1 = (37.42870635,-122.140926605802)
+        start_point_2 = (37.42870635,-122.140926605802)
+        end_point_2 = (37.76624, -122.43456)
+        start_point_3 = (37.76976, -122.43422)
+        end_point_3 = (37.87119, -122.27388)
+        mode_1 = "TRANSIT"
+        mode_2 = 'CAR'
+        mode_3 = 'CAR'
+        curr_time = datetime.datetime.now()
+        curr_month = curr_time.month
+        curr_year = curr_time.year
+        curr_minute = curr_time.minute
+        curr_day = random.randint(1, 9)
+        hour_1 = random.randint(0, 10)
+        hour_2 = hour_1 + 5
+        hour_3 = hour_2 + 5
+        date = "%s-%s-%s" % (curr_month, curr_day, curr_year)
+        time_1 = "%s:%s" % (hour_1, curr_minute) 
+        time_2 = "%s:%s" % (hour_2, curr_minute) 
+        time_3 = "%s:%s" % (hour_3, curr_minute) 
+
+        self.opt_trip_1 = otp.OTP(start_point_1, end_point_1, mode_1, date, time_1, bike=True)
+        self.opt_trip_2 = otp.OTP(start_point_2, end_point_2, mode_2, date, time_2, bike=False)
+        self.opt_trip_3 = otp.OTP(start_point_2, end_point_2, mode_2, date, time_3, bike=False)
+
+    def test_create_start_location_form_leg(self):
+        legs = self.opt_trip_1.get_json()["plan"]["itineraries"][0]['legs']
+        first_leg = legs[0]
+        start_loc = otp.create_start_location_from_leg(first_leg)
+        self.assertEqual(start_loc.ts,otp.otp_time_to_ours(first_leg['startTime']).timestamp )
+        self.assertEqual(start_loc.local_dt, ecsdlq.get_local_date(start_loc.ts, 'UTC'))
+        #print(start_loc)
+
+    def test_create_start_location_form_trip_plan(self):
+        trip_plan = self.opt_trip_1.get_json()["plan"]
+        start_loc = otp.create_start_location_from_trip_plan(trip_plan)
+
+    def test_legs_json(self):
+       #legs = self.opt_trip_1.get_json()["plan"]["itineraries"][0]['legs']
+       pass 
+    
+    def test_turn_into_new_trip(self):
+        #fake_user_email = 'test_otp_insert'
+        #user = ecwu.User.register(fake_user_email)
+        #override_uuid = user.uuid
+        #self.opt_trip_1.turn_into_new_trip(override_uuid)
+        pass 
+    
+    def test_get_measurements_along_route(self):
+        ##Test that the last 
+        #fake_user_email = 'test_time_delta'
+        #user = ecwu.User.register(fake_user_email)
+        #locations = self.opt_trip_1.get_locations_along_route(user.uuid)
+        #print(locations[-1], locations[-2])
+        #time_delta = arrow.get(locations[-1].data.ts) - arrow.get(locations[-2].data.ts)
+        #self.assertGreater(time_delta.total_seconds(), 300)
+        pass 
+    def test_get_average_velocity(self):
+        start_time = arrow.utcnow().timestamp 
+        end_time  = arrow.utcnow().shift(seconds=+200).timestamp
+        distance = 500
+        velocity = otp.get_average_velocity(start_time, end_time, distance)
+        self.assertAlmostEquals(velocity, 2.5)
+
+    def test_get_time_at_next_location(self):
+        prev_loc, next_loc, time_at_prev, velocity = (37.77264255,-122.399714854263), (37.42870635,-122.140926605802), arrow.utcnow().timestamp, 10 
+        time_at_next_loc = otp.get_time_at_next_location(prev_loc, next_loc, time_at_prev, velocity)
+        #print(arrow.get(time_at_prev).humanize())
+        #print(arrow.get(time_at_next_loc).humanize())
+        self.assertGreater(time_at_next_loc, time_at_prev)
+
+    def test_create_measurement_obj(self):
+        coorindate = (37.77264255,-122.399714854263)
+        time_stamp = arrow.utcnow().timestamp
+        user_id = 123
+        velocity = 5
+        altitude = 0.1
+        new_measurement = otp.create_measurement(coorindate, time_stamp, velocity, altitude, user_id)
+        #print(new_measurement)
+
+    def test_save_entries_to_db(self):
+        fake_user_email = 'test_insert_fake_data_84'
+        user = ecwu.User.register(fake_user_email)
+        override_uuid = user.uuid
+        location_entries = self.opt_trip_1.get_measurements_along_route(override_uuid)
+        ts = esta.TimeSeries.get_time_series(override_uuid)
+        #result = ts.bulk_insert(location_entries)
+        #print(type(location_entries[-1].data.ts))
+        (tsdb_count, ucdb_count) = estcs.insert_entries(override_uuid, location_entries)
+        print("Finished loading %d entries into the usercache and %d entries into the timeseries" %
+        (ucdb_count, tsdb_count))
+        
+        #Trip 2
+        location_entries = self.opt_trip_2.get_measurements_along_route(override_uuid)
+        (tsdb_count, ucdb_count) = estcs.insert_entries(override_uuid, location_entries)
+        print("Finished loading %d entries into the usercache and %d entries into the timeseries" %
+        (ucdb_count, tsdb_count))
+
+        # Trip 3
+        location_entries = self.opt_trip_3.get_measurements_along_route(override_uuid)
+        (tsdb_count, ucdb_count) = estcs.insert_entries(override_uuid, location_entries)
+        print("Finished loading %d entries into the usercache and %d entries into the timeseries" %
+        (ucdb_count, tsdb_count))
+
+    def test_create_motion_entry(self):
+        time_stamp = arrow.utcnow().timestamp
+        user_id = 123
+        start_time = arrow.utcnow().timestamp
+        leg = {
+            'mode': "BICYCLE",
+            'startTime' : start_time,
+            'endTime':arrow.utcnow().shift(minutes=+60).timestamp 
+        }
+        new_motion_entry = otp.create_motion_entry_from_leg(leg, user_id)
+        #print(new_motion_entry)
+        #self.assertEqual(start_time, new_motion_entry.data.ts)
+
+    def test_get_elevation(self):
+        coordinate = (37.77264255,-122.399714854263)
+        #print('Elevation',otp.get_elevation(coordinate))
+
+
+if __name__ == '__main__':
+    unittest.main()
+
+
diff --git a/emission/net/usercache/builtin_usercache_handler.py b/emission/net/usercache/builtin_usercache_handler.py
index 73c1c046..94d49916 100644
--- a/emission/net/usercache/builtin_usercache_handler.py
+++ b/emission/net/usercache/builtin_usercache_handler.py
@@ -22,7 +22,7 @@ import emission.analysis.configs.config as eacc
 
 import emission.net.usercache.formatters.formatter as enuf
 import emission.storage.pipeline_queries as esp
-import emission.storage.decorations.tour_model_queries as esdtmpq
+# import emission.storage.decorations.tour_model_queries as esdtmpq
 
 import emission.core.wrapper.trip as ecwt
 import emission.core.wrapper.entry as ecwe
diff --git a/emission/net/usercache/formatters/android/destination_confirm.py b/emission/net/usercache/formatters/android/destination_confirm.py
new file mode 100644
index 00000000..7e83d379
--- /dev/null
+++ b/emission/net/usercache/formatters/android/destination_confirm.py
@@ -0,0 +1,12 @@
+from __future__ import unicode_literals
+from __future__ import print_function
+from __future__ import division
+from __future__ import absolute_import
+from future import standard_library
+standard_library.install_aliases()
+from builtins import *
+import logging
+import emission.net.usercache.formatters.generic.userlabel as fgl
+
+def format(entry):
+    return fgl.format(entry)
diff --git a/emission/net/usercache/formatters/android/motion_activity.py b/emission/net/usercache/formatters/android/motion_activity.py
index 6f404be6..2edec942 100644
--- a/emission/net/usercache/formatters/android/motion_activity.py
+++ b/emission/net/usercache/formatters/android/motion_activity.py
@@ -22,6 +22,8 @@ def format(entry):
     fc.expand_metadata_times(metadata)
     formatted_entry.metadata = metadata
 
+    #logging.info('*** Motion Data write_ts: %d' % metadata.write_ts)
+    
     data = ad.AttrDict()
     if 'agb' in entry.data:
         data.type = ecwa.MotionTypes(entry.data.agb).value
@@ -31,8 +33,10 @@ def format(entry):
         data.type = ecwa.MotionTypes(entry.data.zzbjA).value
     elif 'ajO' in entry.data:
         data.type = ecwa.MotionTypes(entry.data.ajO).value
-    else:
+    elif 'zzaKM' in entry.data:
         data.type = ecwa.MotionTypes(entry.data.zzaKM).value
+    else:
+        data.type = ecwa.MotionTypes(entry.data.zzbhB).value
 
 
     if 'agc' in entry.data:
@@ -43,8 +47,10 @@ def format(entry):
         data.confidence = entry.data.zzbjB
     elif 'ajP' in entry.data:
         data.confidence = entry.data.ajP
-    else:
+    elif 'zzaKN' in entry.data:
         data.confidence = entry.data.zzaKN
+    else:
+        data.confidence = entry.data.zzbhC
 
     data.ts = formatted_entry.metadata.write_ts
     data.local_dt = formatted_entry.metadata.write_local_dt
diff --git a/emission/net/usercache/formatters/ios/destination_confirm.py b/emission/net/usercache/formatters/ios/destination_confirm.py
new file mode 100644
index 00000000..7e83d379
--- /dev/null
+++ b/emission/net/usercache/formatters/ios/destination_confirm.py
@@ -0,0 +1,12 @@
+from __future__ import unicode_literals
+from __future__ import print_function
+from __future__ import division
+from __future__ import absolute_import
+from future import standard_library
+standard_library.install_aliases()
+from builtins import *
+import logging
+import emission.net.usercache.formatters.generic.userlabel as fgl
+
+def format(entry):
+    return fgl.format(entry)
diff --git a/emission/simulation/client.py b/emission/simulation/client.py
new file mode 100644
index 00000000..8b12da83
--- /dev/null
+++ b/emission/simulation/client.py
@@ -0,0 +1,57 @@
+from abc import ABC, abstractmethod
+from emission.simulation.fake_user import FakeUser
+from emission.simulation.error import AddressNotFoundError
+import requests
+
+class Client(ABC):
+    def __init__(self):
+        super().__init__()
+    
+    @abstractmethod
+    def create_fake_user(self, config):
+        pass 
+    @abstractmethod
+    def _parse_user_config(self, config):
+        pass  
+
+class EmissionFakeDataGenerator(Client):
+    def __init__(self, config):
+        #TODO: Check that the config object has keys: emission_server_base_url, register_user_endpoint, user_cache_endpoint
+        self._config = config
+        self._user_factory = FakeUser
+
+    def create_fake_user(self, config):
+        #TODO: parse the config object
+        uuid = self._register_fake_user(config['email'])
+        config['uuid'] = uuid
+        config['upload_url'] = self._config['emission_server_base_url'] + self._config['user_cache_endpoint']
+        return self._user_factory(config)
+
+    def _register_fake_user(self, email):
+        data = {'user': email}
+        url = self._config['emission_server_base_url'] + self._config['register_user_endpoint'] 
+        r = requests.post(url, json=data)
+        r.raise_for_status()
+        uuid = r.json()['uuid']
+        #TODO: This is a hack to make all the genereated entries JSON encodeable. 
+        #Might be a bad Idead to stringify the uuid. For instance, 
+        # the create_entry function expects uuid of type UUID
+        return str(uuid)
+
+    def _parse_user_config(self, config):
+        #TODO: This function shoudl be used to parser user config object and check that the paramaters are valid.
+        try: 
+            locations = config['locations']
+        except KeyError:
+            print("You must specify a set of addresses")
+            raise AddressNotFoundError
+
+        #check that all addresses are supported by the trip planner software
+        #for address in addresses:
+        #    if not self._trip_planer_client.has_address(address):
+        #        message = ("%s, is not supported by the Trip Planer", address) 
+        #        raise AddressNotFoundError(message, address)
+
+        #check that all teh transition probabilites for every address adds up to one
+
+        
diff --git a/emission/simulation/config_parser.py b/emission/simulation/config_parser.py
new file mode 100644
index 00000000..e69de29b
diff --git a/emission/simulation/entry_formater.py b/emission/simulation/entry_formater.py
new file mode 100644
index 00000000..b5bc3de5
--- /dev/null
+++ b/emission/simulation/entry_formater.py
@@ -0,0 +1 @@
+#This is how we format the entries
\ No newline at end of file
diff --git a/emission/simulation/error.py b/emission/simulation/error.py
new file mode 100644
index 00000000..c18dd2bc
--- /dev/null
+++ b/emission/simulation/error.py
@@ -0,0 +1,10 @@
+class Error(Exception):
+    pass 
+
+class AddressNotFoundError(Error):
+    """ Exception raised for Addresses that are not found in the trip planner client.
+    """
+    def __init__(self, message, address):
+        self.message = message
+        self.address = address 
+
diff --git a/emission/simulation/fake_user.py b/emission/simulation/fake_user.py
new file mode 100644
index 00000000..39f01b8e
--- /dev/null
+++ b/emission/simulation/fake_user.py
@@ -0,0 +1,130 @@
+
+from abc import ABC, abstractmethod
+from prob140 import MarkovChain 
+import numpy as np
+import datetime
+import arrow 
+import requests
+#emission imports
+import emission.core.wrapper.user as ecwu
+from emission.net.ext_service.otp.otp import OTP, PathNotFoundException
+
+class FakeUser:
+    """
+    Fake user class used to genreate synthetic data.
+    """
+#TODO: Make FakeUser an abstract class and create a concrete implementation called EmissionFakeUser
+    def __init__(self, config={}):
+        self._config = config
+        self._email = config['email']
+        self._uuid = config['uuid'] 
+        # We need to set the time of ther user in the past to that the pipeline can find the entries.
+        self._time_object = arrow.utcnow().shift(years=-1) 
+        self._trip_planer_client = OTP
+        self._current_state = config['initial_state']
+        self._markov_model = self._create_markow_model(config) #MarkovChain(config['addresses'], config['transition_probabilities'])
+        self._path = [self._current_state]
+        self._label_to_coordinate_map = self._create_label_to_coordinate_map(config)
+        self._trip_to_mode_map = self._create_trip_to_mode_map(config)
+        self._measurements_cache = []
+
+    def take_trip(self):
+        #TODO: If we have already completed a trip, we could potentially cache the location data 
+        # we get from Open Trip Planner and only modify the timestamps next time we take the same trip. 
+        curr_loc = self._current_state
+        next_loc = self._markov_model.simulate_path(self._current_state, 1)[-1]
+
+       #If the next location is the same as the current location, return an empty list
+        if next_loc == self._current_state:
+            print('>> Staying at', curr_loc)
+            return []
+
+        curr_coordinate = self._label_to_coordinate_map[curr_loc] 
+        next_coordinate = self._label_to_coordinate_map[next_loc]
+
+        trip_planer_client = self._create_new_otp_trip(curr_coordinate, next_coordinate, curr_loc, next_loc)
+
+        # Get the measurements along the route. This includes location entries
+        # and a motion entry for each section.
+       #TODO: If get_measurements_along_route returns a PathNotFound Exception, we should catch this and return an empty list(?) 
+        print('>> Traveling from', curr_loc,'to', next_loc, '| Mode of transportation:', trip_planer_client.mode)
+        measurements = trip_planer_client.get_measurements_along_route(self._uuid)
+
+       # Here we update the current state 
+       # We also update the time_object to make sure the next trip starts at a later time 
+        if len(measurements) > 0:
+            #print(measurements[0].metadata.write_ts)
+            end_time_last_trip = measurements[-1].data.ts
+            self._update_time(end_time_last_trip)
+            self._current_state = next_loc
+            self._path.append(next_loc)
+            #Update measurements cache
+            self._measurements_cache += measurements
+            #TODO: if the user cache has more than 5000 entries notify the user so they can sync the data. 
+
+        return measurements
+    def sync_data_to_server(self):
+        #Remove the _id field
+        measurements_no_id = [self._remove_id_field(entry) for entry in self._measurements_cache]
+        #Send data to server
+        data = {
+            'phone_to_server': measurements_no_id,
+            'user': self._email
+        }
+
+        r = requests.post(self._config['upload_url'], json=data)
+
+        #Check if sucessful
+        if r.ok:
+            self._flush_cache()
+            print("%d entries were sucessfully synced to the server" % len(measurements_no_id))
+        else:
+            print('Something went wrong when trying to sync your data. Try again or use save_cache_to_file to save your data.')
+            print(r.content)
+
+    def _create_new_otp_trip(self, curr_coordinate, next_coordinate, cur_loc, next_loc):
+        try:
+            mode = self._trip_to_mode_map[(cur_loc, next_loc)]
+        except KeyError:
+            mode = self._config['default_mode']
+
+        date = "%s-%s-%s" % (self._time_object.month, self._time_object.day, self._time_object.year)
+        time = "%s:%s" % (self._time_object.hour, self._time_object.minute)
+        
+        #TODO: Figure out how we should set bike
+        return self._trip_planer_client(curr_coordinate, next_coordinate, mode, date, time, bike=True)
+    
+    def _update_time(self, prev_trip_end_time):
+        # TODO: 3 hours is an arbritrary value. Not sure what makes sense. 
+        self._time_object = arrow.get(prev_trip_end_time).shift(hours=+3)
+    
+    def _create_markow_model(self, config):
+        labels = [elem['label'].lower() for elem in config['locations']]
+        transitions_probabilities = config['transition_probabilities']
+        return MarkovChain(labels, transitions_probabilities)
+
+    def _create_label_to_coordinate_map(self, config):
+        locations = config['locations']
+        new_map = {}
+        for loc in locations:
+            new_map[loc['label']] = tuple(loc['coordinate'])
+
+        return new_map
+    
+    def _create_trip_to_mode_map(self, config):
+        new_map = {}
+        for k, v in config['modes'].items():
+            for edge in v:
+                new_map[tuple(edge)] = k
+        return new_map
+    
+    @staticmethod
+    def _remove_id_field(entry):
+        copy = entry.copy()
+        del copy['_id']
+        return copy
+    
+    def _flush_cache(self):
+        self._measurements_cache = []
+
+        
diff --git a/emission/simulation/input.json b/emission/simulation/input.json
index a888b150..5c1aa8ba 100644
--- a/emission/simulation/input.json
+++ b/emission/simulation/input.json
@@ -2,18 +2,18 @@
 	"radius" : ".1",
 	"starting centroids" :
 	{
-		"2703 Hallmark Dr Belmont Ca" : 100,
-		"ATT Park" : 20, 
-		"Skyline County Park Napa, CA" : 10, 
+		"2703 Hallmark Dr Belmont" : 100,
+		"AT&T Park" : 20, 
+		"Skyline Wilderness Park" : 10, 
 		"UC Berkeley" : 50
 
 	},
 	"ending centroids" :
 	{
-		"Skyline County Park Napa, CA" : 10,
-		"ATT Park" : 100, 
+		"Skyline Wilderness Park" : 10,
+		"AT&T Park" : 100, 
 		"UC Berkeley" : 75,
-		"2703 Hallmark Dr Belmont Ca" : 100
+		"2703 Hallmark Dr Belmont" : 100
 
 	},
 	"modes" : 
diff --git a/emission/simulation/trip_gen.py b/emission/simulation/trip_gen.py
index 8ce00bae..c9b71459 100644
--- a/emission/simulation/trip_gen.py
+++ b/emission/simulation/trip_gen.py
@@ -37,6 +37,15 @@ class Address(object):
     def __str__(self):
         return self.text
 
+    def __eq__(self, other):
+        return (self.text.lower(), self.cord) == (other.text.lower(), self.cord)
+
+    def __lt__(self, other):
+        return (self.text.lower(), self.cord) < (other.text.lower(), other.cord)
+    
+    def __hash__(self):
+        return hash((self.text, self.cord))
+
 class Creator(object): 
 
     def __init__(self, new=False):
@@ -47,9 +56,9 @@ class Creator(object):
         self.num_trips = None
         self.radius = None
         self.amount_missed = 0
-        self.starting_counter = esmmc.Counter( )
-        self.ending_counter = esmmc.Counter( )
-        self.mode_counter = esmmc.Counter( )
+        self.starting_counter = esmmc.Counter()
+        self.ending_counter = esmmc.Counter()
+        self.mode_counter = esmmc.Counter()
         self.prog_bar = ""
 
     def set_up(self):
@@ -135,6 +144,7 @@ def save_section_to_db(section):
 def geocode_address(address):
     if address.cord is None:
         business_geocoder = enn.Geocoder()
+        # TODO: if the geocoder fails then what?
         results = business_geocoder.geocode(address.text)
         address.cord = results
     else:
@@ -179,6 +189,7 @@ def create_fake_trips(user_name=None, new=False):
     ### This is the main function, its the only thing you need to run
     my_creator = Creator(new)
     my_creator.set_up()
+    #TODO: If we cant find coordintates for one of the addresses, tell the user. We must decide how the user shoudl enter the addresses in a meaningfull format. 
     my_creator.get_starting_ending_points()
     my_creator.make_a_to_b()
     my_creator.get_trips_from_a_to_b(user_name)
diff --git a/emission/storage/decorations/trip_queries.py b/emission/storage/decorations/trip_queries.py
index 9a450b24..8dfbc1be 100644
--- a/emission/storage/decorations/trip_queries.py
+++ b/emission/storage/decorations/trip_queries.py
@@ -15,6 +15,7 @@ import emission.core.wrapper.rawtrip as ecwrt
 import emission.core.wrapper.entry as ecwe
 
 import emission.storage.timeseries.abstract_timeseries as esta
+import emission.storage.timeseries.cache_series as estsc
 import emission.storage.decorations.timeline as esdt
 import emission.storage.decorations.analysis_timeseries_queries as esda
 
@@ -90,3 +91,19 @@ def get_user_input_for_trip_object(ts, trip_obj, user_input_key):
     ret_val = ts.get_entry_from_id(user_input_key, most_recent_entry_id)
     logging.debug("and is mapped to entry %s" % ret_val)
     return ret_val
+
+# This is almost an exact copy of get_user_input_for_trip_object, but it
+# retrieves an interable instead of a dataframe. So almost everything is
+# different and it is hard to unify the implementations. Switching the existing
+# function from get_data_df to find_entries may help us unify in the future
+
+def get_user_input_from_cache_series(user_id, trip_obj, user_input_key):
+    tq = estt.TimeQuery("data.start_ts", trip_obj.data.start_ts, trip_obj.data.end_ts)
+    potential_candidates = estsc.find_entries(user_id, [user_input_key], tq)
+    if len(potential_candidates) == 0:
+        return None
+    sorted_pc = sorted(potential_candidates, key=lambda c:c["metadata"]["write_ts"])
+    most_recent_entry = potential_candidates[-1]
+    logging.debug("most recent entry has id %s" % most_recent_entry["_id"])
+    logging.debug("and is mapped to entry %s" % most_recent_entry)
+    return ecwe.Entry(most_recent_entry)
diff --git a/emission/storage/pipeline_queries.py b/emission/storage/pipeline_queries.py
index 42b9897d..978aa4f8 100644
--- a/emission/storage/pipeline_queries.py
+++ b/emission/storage/pipeline_queries.py
@@ -252,7 +252,7 @@ def get_time_range_for_stage(user_id, stage):
 def get_current_state(user_id, stage):
     curr_state_doc = edb.get_pipeline_state_db().find_one({"user_id": user_id,
                                                             "pipeline_stage": stage.value})
-    # logging.debug("returning curr_state_doc  %s for stage %s " % (curr_state_doc, stage))
+    #logging.debug("returning curr_state_doc  %s for stage %s " % (curr_state_doc, stage))
     if curr_state_doc is not None:
         return ps.PipelineState(curr_state_doc)
     else:
diff --git a/emission/storage/timeseries/builtin_timeseries.py b/emission/storage/timeseries/builtin_timeseries.py
index 987f0a28..1fde69e5 100644
--- a/emission/storage/timeseries/builtin_timeseries.py
+++ b/emission/storage/timeseries/builtin_timeseries.py
@@ -20,7 +20,7 @@ ts_enum_map = {
     esta.EntryType.ANALYSIS_TYPE: edb.get_analysis_timeseries_db()
 }
 
-INVALID_QUERY = {'1': '2'}
+INVALID_QUERY = {'metadata.key': 'invalid'}
 
 class BuiltinTimeSeries(esta.TimeSeries):
     def __init__(self, user_id):
@@ -59,6 +59,7 @@ class BuiltinTimeSeries(esta.TimeSeries):
                 "manual/incident": self.timeseries_db,
                 "manual/mode_confirm": self.timeseries_db,
                 "manual/purpose_confirm": self.timeseries_db,
+                "manual/destination_confirm": self.timeseries_db,
                 "segmentation/raw_trip": self.analysis_timeseries_db,
                 "segmentation/raw_place": self.analysis_timeseries_db,
                 "segmentation/raw_section": self.analysis_timeseries_db,
diff --git a/emission/tests/simulationTests/test_client.py b/emission/tests/simulationTests/test_client.py
new file mode 100644
index 00000000..69c8b7e6
--- /dev/null
+++ b/emission/tests/simulationTests/test_client.py
@@ -0,0 +1,27 @@
+import unittest
+from emission.simulation.client import EmissionFakeDataGenerator
+from emission.simulation.error import AddressNotFoundError
+
+class TestClientMethods(unittest.TestCase):
+    def setUp(self):
+        client_config = {
+            'emission_server_base_url': 'http://localhost:8080',
+            'register_user_endpoint': '/profile/create',
+             'user_cache_endpoint': '/usercache'
+        }
+        self.emission_data_generator = EmissionFakeDataGenerator(client_config)
+
+    def test_register_fake_user(self):
+        email = 'register_fake@user'
+        uuid = self.emission_data_generator._register_fake_user(email)
+        print(uuid)
+
+    def test_parse_user_config(self):
+        pass
+        #TODO Test for invalid modes as well, modes supported by the OTP server 
+        
+        #self.assertRaises(AddressNotFoundError, lambda: self.emission_data_generator._parse_user_config(config_invalid_address))
+
+if __name__ == '__main__':
+    unittest.main()
+        
diff --git a/emission/tests/simulationTests/test_prob140.py b/emission/tests/simulationTests/test_prob140.py
new file mode 100644
index 00000000..02689b15
--- /dev/null
+++ b/emission/tests/simulationTests/test_prob140.py
@@ -0,0 +1,30 @@
+import unittest
+import datascience 
+import prob140
+import numpy as np
+import warnings
+
+class TestProb140Methods(unittest.TestCase):
+    def setUp(self):
+        self.states = ['A', 'B', 'C', 'D'] 
+        self.transition_matrix = [
+            np.random.dirichlet(np.ones(len(self.states)), size=1)[0],
+            np.random.dirichlet(np.ones(len(self.states)), size=1)[0],
+            np.random.dirichlet(np.ones(len(self.states)), size=1)[0],
+            np.random.dirichlet(np.ones(len(self.states)), size=1)[0]
+        ] 
+        self.initial_state = 'A'
+
+    def test_create_markov_chain(self):
+        table = prob140.MarkovChain.from_matrix(self.states, self.transition_matrix)
+        print(table)
+
+    def test_take_step(self):
+        mc = prob140.MarkovChain.from_matrix(self.states, self.transition_matrix)
+        next_state = mc.simulate_path(self.initial_state, 1)[-1]
+        print(next_state)
+        next_state = mc.simulate_path(next_state, 1)[-1]
+        print(next_state)
+
+if __name__ == '__main__':
+    unittest.main()
\ No newline at end of file
diff --git a/emission/tests/simulationTests/test_user.py b/emission/tests/simulationTests/test_user.py
new file mode 100644
index 00000000..72d08763
--- /dev/null
+++ b/emission/tests/simulationTests/test_user.py
@@ -0,0 +1,90 @@
+import unittest
+from emission.simulation.fake_user import FakeUser
+from emission.simulation.error import AddressNotFoundError
+import datascience 
+import prob140
+import numpy as np
+
+class TestFakeUserMethods(unittest.TestCase):
+    def setUp(self):
+        self.config = {
+            "email" : 'my_fake_user',
+            "uuid" : '124',
+            "upload_url" : 'http://localhost:8080/usercache/put',
+	        "locations" : 
+	        [
+               {
+                    'label': 'home',
+                    'coordinate': [37.77264255,-122.399714854263]
+                },
+
+                {
+                    'label': 'work',
+                    'coordinate': [37.42870635,-122.140926605802]
+                },
+                {
+                    'label': 'family',
+                    'coordinate': [37.87119, -122.27388]
+                }
+            ],
+            "transition_probabilities":
+            [
+                np.random.dirichlet(np.ones(3), size=1)[0],
+                np.random.dirichlet(np.ones(3), size=1)[0],
+                np.random.dirichlet(np.ones(3), size=1)[0]
+            ],
+            "modes" : 
+            {
+                "CAR" : [['home', 'family']],
+                "TRANSIT" : [['home, work'], ['work', 'home']]  
+            },
+
+            "default_mode": "CAR",
+	        "initial_state" : "home",
+            "radius" : ".1"
+        }
+        #email = 'test_fake_user'
+        self.fake_user = FakeUser(self.config)
+    
+    def test_init(self):
+        self.assertEqual(self.fake_user._email, 'my_fake_user')
+
+    def test_upload_to_server(self):
+        self.fake_user.take_trip()
+        self.fake_user.sync_data_to_server()
+
+    def test_take_trip(self):
+        self.assertEqual(self.fake_user._current_state, self.config['initial_state'])
+        measurements = self.fake_user.take_trip()
+        #print(self.fake_user._current_state)
+
+
+    def test_take_many_trips(self):
+        for _ in range(10):
+            self.fake_user.take_trip()
+            print(self.fake_user._current_state)
+
+        print(self.fake_user._path)
+    
+    def test_trip_to_mode_map(self):
+        new_map = self.fake_user._create_trip_to_mode_map(self.config)
+        edges = []
+        for k,v in self.config['modes'].items():
+            for edge in v:
+                edges.append(tuple(edge))
+        
+        for edge in edges:
+            self.assertTrue(edge in new_map.keys())
+
+    def test_create_otp_trip(self):
+        home = (37.77264255,-122.399714854263)
+        work = (37.42870635,-122.140926605802)
+        otp = self.fake_user._create_new_otp_trip(home, work, home, work)
+        measurements = otp.get_measurements_along_route(self.fake_user._uuid)
+        print(len(measurements))
+
+
+
+if __name__ == '__main__':
+    unittest.main()
+        
diff --git a/emission/tests/storageTests/TestTripQueries.py b/emission/tests/storageTests/TestTripQueries.py
index ddc4b62a..261d6f5c 100644
--- a/emission/tests/storageTests/TestTripQueries.py
+++ b/emission/tests/storageTests/TestTripQueries.py
@@ -21,11 +21,14 @@ import emission.storage.decorations.analysis_timeseries_queries as esda
 import emission.storage.timeseries.timequery as estt
 import emission.storage.timeseries.abstract_timeseries as esta
 
+import emission.net.api.usercache as enau
+
 import emission.core.get_database as edb
 import emission.core.wrapper.userlabel as ecul
 import emission.core.wrapper.rawtrip as ecwrt
 import emission.core.wrapper.section as ecwc
 import emission.core.wrapper.stop as ecws
+import emission.core.wrapper.entry as ecwe
 
 import emission.tests.storageTests.analysis_ts_common as etsa
 import emission.tests.common as etc
@@ -37,6 +40,7 @@ class TestTripQueries(unittest.TestCase):
     
     def tearDown(self):
         edb.get_analysis_timeseries_db().delete_many({'user_id': self.testUserId})
+        edb.get_usercache_db().delete_many({'user_id': self.testUserId})
 
     def create_fake_trip(self):
         return etsa.createNewTripLike(self, esda.RAW_TRIP_KEY, ecwrt.Rawtrip)
@@ -78,9 +82,9 @@ class TestTripQueries(unittest.TestCase):
         user_input = esdt.get_user_input_for_trip(esda.RAW_TRIP_KEY, self.testUserId, new_trip.get_id(), "manual/mode_confirm")
         self.assertIsNone(user_input)
 
-    def testUserInputForTripOneInput(self):
+    def testUserInputForTripOneInputFromCache(self):
         """
-        Test the case in which the user has not provided any inputs
+        Test the case in which the user has provided exactly one input
         """
         MODE_CONFIRM_KEY = "manual/mode_confirm"
 
@@ -88,13 +92,15 @@ class TestTripQueries(unittest.TestCase):
         new_mc = ecul.Userlabel()
         new_mc["start_ts"] = new_trip.data.start_ts + 1
         new_mc["end_ts"] = new_trip.data.end_ts + 1
-        ts = esta.TimeSeries.get_time_series(self.testUserId)
-        ts.insert_data(self.testUserId, MODE_CONFIRM_KEY, new_mc) 
+        new_mc["label"] = "roller_blading"
+        new_mce = ecwe.Entry.create_entry(self.testUserId, MODE_CONFIRM_KEY, new_mc)
+        new_mce["metadata"]["type"] = "message"
+
+        enau.sync_phone_to_server(self.testUserId, [new_mce])
         
-        user_input = esdt.get_user_input_for_trip(esda.RAW_TRIP_KEY, self.testUserId,
-            new_trip.get_id(), MODE_CONFIRM_KEY)
+        user_input = esdt.get_user_input_from_cache_series(self.testUserId, new_trip, MODE_CONFIRM_KEY)
 
-        self.assertEqual(new_mc, user_input.data)
+        self.assertEqual(new_mce, user_input)
 
     def testUserInputForTripOneInput(self):
         """
@@ -114,6 +120,42 @@ class TestTripQueries(unittest.TestCase):
 
         self.assertEqual(new_mc, user_input.data)
 
+    def testUserInputForTripTwoInputFromCache(self):
+        """
+        Test the case in which the user has provided exactly one input
+        """
+        MODE_CONFIRM_KEY = "manual/mode_confirm"
+
+        new_trip = self.create_fake_trip()
+        new_mc = ecul.Userlabel()
+        new_mc["start_ts"] = new_trip.data.start_ts + 1
+        new_mc["end_ts"] = new_trip.data.end_ts + 1
+        new_mc["label"] = "roller_blading"
+        new_mce = ecwe.Entry.create_entry(self.testUserId, MODE_CONFIRM_KEY, new_mc)
+        new_mce["metadata"]["type"] = "message"
+
+        enau.sync_phone_to_server(self.testUserId, [new_mce])
+
+        user_input = esdt.get_user_input_from_cache_series(self.testUserId, new_trip, MODE_CONFIRM_KEY)
+
+        # WHen there is only one input, it is roller_blading
+        self.assertEqual(new_mce, user_input)
+        self.assertEqual(user_input.data.label, 'roller_blading')
+
+        new_mc["label"] = 'pogo_sticking'
+
+        new_mce = ecwe.Entry.create_entry(self.testUserId, MODE_CONFIRM_KEY, new_mc)
+        new_mce["metadata"]["type"] = "message"
+
+        enau.sync_phone_to_server(self.testUserId, [new_mce])
+
+        user_input = esdt.get_user_input_from_cache_series(self.testUserId, new_trip, MODE_CONFIRM_KEY)
+
+        # When it is overridden, it is pogo sticking
+        self.assertEqual(new_mce, user_input)
+        self.assertEqual(user_input.data.label, 'pogo_sticking')
+
+
     def testUserInputForTripTwoInput(self):
         """
         Test the case in which the user has provided two inputs
diff --git a/setup/alvin_environment.yml b/setup/alvin_environment.yml
new file mode 100644
index 00000000..e69de29b
diff --git a/setup/environment27.yml b/setup/environment27.yml
deleted file mode 100644
index a6a6da2b..00000000
--- a/setup/environment27.yml
+++ /dev/null
@@ -1,70 +0,0 @@
-name: py27
-dependencies:
-- certifi=2016.2.28=py27_0
-- cycler=0.10.0=py27_0
-- freetype=2.5.5=2
-- functools32=3.2.3.2=py27_0
-- icu=54.1=0
-- libpng=1.6.30=1
-- matplotlib=2.0.2=np113py27_0
-- mkl=2017.0.3=0
-- numpy=1.13.1=py27_0
-- openssl=1.0.2l=0
-- pandas=0.20.3=py27_0
-- patsy=0.4.1=py27_0
-- pip=9.0.1=py27_1
-- pyparsing=2.2.0=py27_0
-- pyqt=5.6.0=py27_2
-- python=2.7.13=0
-- python-dateutil=2.6.1=py27_0
-- pytz=2017.2=py27_0
-- qt=5.6.2=2
-- readline=6.2=2
-- scikit-learn=0.19.0=np113py27_0
-- scipy=0.19.1=np113py27_0
-- seaborn=0.8=py27_0
-- setuptools=36.4.0=py27_1
-- sip=4.18=py27_0
-- six=1.10.0=py27_0
-- sqlite=3.13.0=0
-- statsmodels=0.8.0=np113py27_0
-- subprocess32=3.2.7=py27_0
-- tk=8.5.18=0
-- wheel=0.29.0=py27_0
-- zlib=1.2.11=0
-- pip:
-  - arrow==0.12.0
-  - asn1crypto==0.23.0
-  - attrdict==2.0.0
-  - backports.functools-lru-cache==1.4
-  - cachetools==2.0.1
-  - cffi==1.11.2
-  - chardet==3.0.4
-  - cheroot==5.10.0
-  - cherrypy==12.0.1
-  - cryptography==2.1.4
-  - enum34==1.1.6
-  - future==0.16.0
-  - geojson==2.3.0
-  - google-auth==1.2.1
-  - idna==2.6
-  - ipaddress==1.0.18
-  - jaraco.classes==1.4.3
-  - jwcrypto==0.4.2
-  - lxml==4.1.1
-  - portend==2.2
-  - pyasn1==0.4.2
-  - pyasn1-modules==0.2.1
-  - pycparser==2.18
-  - pyfcm==1.4.3
-  - pygeocoder==1.2.5
-  - pykml==0.1.3
-  - pymongo==3.5.1
-  - python-crontab==2.2.7
-  - requests==2.18.4
-  - requests-toolbelt==0.8.0
-  - rsa==3.4.2
-  - tempora==1.9
-  - urllib3==1.22
-  - utm==0.4.2
-  - xmltodict==0.11.0
diff --git a/setup/environment36.exported.yml b/setup/environment36.exported.yml
new file mode 100644
index 00000000..04797fc9
--- /dev/null
+++ b/setup/environment36.exported.yml
@@ -0,0 +1,57 @@
+name: minimal_emission
+channels:
+- conda-forge
+- defaults
+dependencies:
+- arrow=0.12.1=py36_1002
+- attrdict=2.0.0=py_1
+- ca-certificates=2018.11.29=ha4d7672_0
+- cachetools=2.1.0=py_0
+- certifi=2018.11.29=py36_1000
+- cheroot=6.2.4=py36_0
+- future=0.16.0=py36_1002
+- geojson=2.3.0=py_0
+- google-auth=1.2.1=py_0
+- jsonpickle=0.9.6=py_1
+- more-itertools=4.3.0=py36_1000
+- ncurses=5.9=10
+- openssl=1.0.2p=h1de35cc_1002
+- pandas=0.20.1=np112py36_0
+- pip=9.0.1=py36_1
+- pyasn1=0.4.4=py_1
+- pyasn1-modules=0.2.3=py_0
+- python=3.6.1=2
+- python-dateutil=2.6.0=py36_0
+- pytz=2017.2=py36_0
+- readline=6.2=0
+- rsa=3.4.2=py_1
+- setuptools=40.8.0=py36_0
+- six=1.12.0=py36_1000
+- sqlite=3.13.0=1
+- tk=8.5.19=2
+- utm=0.4.2=py36_0
+- wheel=0.33.0=py36_0
+- xmltodict=0.11.0=py_1
+- xz=5.2.4=h1de35cc_1001
+- zlib=1.2.11=h1de35cc_1004
+- blas=1.0=mkl
+- intel-openmp=2019.1=144
+- mkl=2017.0.4=h1fae6ae_0
+- numpy=1.12.1=py36_0
+- requests=2.14.2=py36_0
+- scikit-learn=0.18.1=np112py36_1
+- scipy=0.19.0=np112py36_0
+- pip:
+  - asn1crypto==0.24.0
+  - cffi==1.11.5
+  - cryptography==2.5
+  - jwcrypto==0.4.2
+  - lxml==4.3.1
+  - pycparser==2.19
+  - pyfcm==1.4.3
+  - pygeocoder==1.2.5
+  - pykml==0.1.3
+  - pymongo==3.5.1
+  - requests-toolbelt==0.9.1
+prefix: /Users/shankari/OSS/anaconda/envs/minimal_emission
+
diff --git a/setup/environment36.nomkl.exported.yml b/setup/environment36.nomkl.exported.yml
new file mode 100644
index 00000000..88ac20fb
--- /dev/null
+++ b/setup/environment36.nomkl.exported.yml
@@ -0,0 +1,58 @@
+name: minimal_emission_nomkl
+channels:
+- conda-forge
+- defaults
+dependencies:
+- arrow=0.12.1=py36_1002
+- attrdict=2.0.0=py_1
+- blas=1.1=openblas
+- ca-certificates=2018.11.29=ha4d7672_0
+- cachetools=2.1.0=py_0
+- certifi=2018.11.29=py36_1000
+- cheroot=6.2.4=py36_0
+- future=0.16.0=py36_1002
+- geojson=2.3.0=py_0
+- google-auth=1.2.1=py_0
+- jsonpickle=0.9.6=py_1
+- more-itertools=4.3.0=py36_1000
+- ncurses=5.9=10
+- numpy=1.12.1=py36_blas_openblas_200
+- openblas=0.2.19=2
+- openssl=1.0.2p=h1de35cc_1002
+- pandas=0.20.1=np112py36_0
+- pip=9.0.1=py36_1
+- pyasn1=0.4.4=py_1
+- pyasn1-modules=0.2.3=py_0
+- python=3.6.1=2
+- python-dateutil=2.6.0=py36_0
+- pytz=2017.2=py36_0
+- readline=6.2=0
+- rsa=3.4.2=py_1
+- scikit-learn=0.18.1=np112py36_blas_openblas_200
+- scipy=0.19.0=np112py36_blas_openblas_202
+- setuptools=40.8.0=py36_0
+- six=1.12.0=py36_1000
+- sqlite=3.13.0=1
+- tk=8.5.19=2
+- utm=0.4.2=py36_0
+- wheel=0.33.0=py36_0
+- xmltodict=0.11.0=py_1
+- xz=5.2.4=h1de35cc_1001
+- zlib=1.2.11=h1de35cc_1004
+- libgfortran=3.0.1=h93005f0_2
+- nomkl=3.0=0
+- requests=2.14.2=py36_0
+- pip:
+  - asn1crypto==0.24.0
+  - cffi==1.11.5
+  - cryptography==2.5
+  - jwcrypto==0.4.2
+  - lxml==4.3.1
+  - pycparser==2.19
+  - pyfcm==1.4.3
+  - pygeocoder==1.2.5
+  - pykml==0.1.3
+  - pymongo==3.5.1
+  - requests-toolbelt==0.9.1
+prefix: /Users/shankari/OSS/anaconda/envs/minimal_emission_nomkl
+
diff --git a/setup/environment36.nomkl.yml b/setup/environment36.nomkl.yml
new file mode 100644
index 00000000..7a1bfe8f
--- /dev/null
+++ b/setup/environment36.nomkl.yml
@@ -0,0 +1,32 @@
+name: emission
+channels:
+- conda-forge
+- defaults
+dependencies:
+- arrow=0.12.1
+- attrdict=2.0.0
+- cheroot=6.2.*=py36_0
+- future=0.16.0
+- geojson=2.3.0
+- google-auth=1.2.1
+- jsonpickle=0.9.6
+- nomkl
+- numpy=1.12.1
+- pandas=0.20.1
+- pip=9.0.1=py36_1
+- python=3.6.1=2
+- python-dateutil=2.6.0=py36_0
+- pytz=2017.2=py36_0
+- requests=2.14.2=py36_0
+- scikit-learn=0.18.1
+- scipy=0.19.0
+- sqlite=3.13.0
+- utm=0.4.2
+- xmltodict=0.11.0
+- pip:
+  - jwcrypto==0.4.2
+  - pyfcm==1.4.3
+  - pygeocoder==1.2.5
+  - pykml==0.1.3
+  - pymongo==3.5.1
+prefix: /Users/shankari/OSS/anaconda/envs/emission
diff --git a/setup/environment36.notebook.additions.yml b/setup/environment36.notebook.additions.yml
new file mode 100644
index 00000000..bf7ca0a8
--- /dev/null
+++ b/setup/environment36.notebook.additions.yml
@@ -0,0 +1,9 @@
+name: emission
+channels:
+- conda-forge
+- defaults
+dependencies:
+- branca=0.2.0=py_1
+- folium=0.5.0=py_0
+- ipython=5.3.0=py36_0
+- jupyter=1.0.0=py36_3
diff --git a/setup/environment36.notebook.exported.yml b/setup/environment36.notebook.exported.yml
new file mode 100644
index 00000000..56ba48e7
--- /dev/null
+++ b/setup/environment36.notebook.exported.yml
@@ -0,0 +1,118 @@
+name: emission-new
+channels:
+- conda-forge
+- defaults
+dependencies:
+- altair=2.3.0=py36_1001
+- appnope=0.1.0=py36_1000
+- arrow=0.12.1=py36_1002
+- attrdict=2.0.0=py_1
+- attrs=18.2.0=py_0
+- bleach=3.1.0=py_0
+- branca=0.2.0=py_1
+- ca-certificates=2018.11.29=ha4d7672_0
+- cachetools=2.1.0=py_0
+- certifi=2018.11.29=py36_1000
+- cheroot=6.2.4=py36_0
+- decorator=4.3.2=py_0
+- entrypoints=0.3=py36_1000
+- folium=0.5.0=py_0
+- future=0.16.0=py36_1002
+- geojson=2.3.0=py_0
+- google-auth=1.2.1=py_0
+- icu=58.2=h0a44026_1000
+- ipykernel=5.1.0=py36h24bf2e0_1002
+- ipython=5.3.0=py36_0
+- ipython_genutils=0.2.0=py_1
+- ipywidgets=7.4.2=py_0
+- jinja2=2.10=py_1
+- jpeg=9c=h1de35cc_1001
+- jsonpickle=0.9.6=py_1
+- jsonschema=3.0.0a3=py36_1000
+- jupyter_client=5.2.4=py_1
+- jupyter_console=5.2.0=py36_1
+- jupyter_core=4.4.0=py_0
+- libcxx=7.0.0=h2d50403_2
+- libpng=1.6.36=ha441bb4_1000
+- libsodium=1.0.16=h1de35cc_1001
+- llvm-meta=7.0.0=0
+- markupsafe=1.1.0=py36h1de35cc_1000
+- mistune=0.8.4=py36h1de35cc_1000
+- more-itertools=4.3.0=py36_1000
+- nbconvert=5.3.1=py_1
+- nbformat=4.4.0=py_1
+- ncurses=5.9=10
+- notebook=5.7.4=py36_1000
+- openssl=1.0.2p=h1de35cc_1002
+- pandas=0.20.1=np112py36_0
+- pandoc=2.6=1
+- pandocfilters=1.4.2=py_1
+- pexpect=4.6.0=py36_1000
+- pickleshare=0.7.5=py36_1000
+- pip=9.0.1=py36_1
+- prometheus_client=0.5.0=py_0
+- prompt_toolkit=1.0.15=py_1
+- ptyprocess=0.6.0=py36_1000
+- pyasn1=0.4.4=py_1
+- pyasn1-modules=0.2.3=py_0
+- pygments=2.3.1=py_0
+- pyqt=5.6.0=py36hc26a216_1008
+- pyrsistent=0.14.10=py36h1de35cc_0
+- python=3.6.1=2
+- python-dateutil=2.6.0=py36_0
+- pytz=2017.2=py36_0
+- pyzmq=17.1.2=py36h111632d_1001
+- qt=5.6.2=h9e3eb04_4
+- qtconsole=4.4.3=py_0
+- readline=6.2=0
+- rsa=3.4.2=py_1
+- send2trash=1.5.0=py_0
+- setuptools=40.8.0=py36_0
+- simplegeneric=0.8.1=py_1
+- sip=4.18.1=py36h0a44026_1000
+- six=1.12.0=py36_1000
+- sqlite=3.13.0=1
+- terminado=0.8.1=py36_1001
+- testpath=0.4.2=py36_1000
+- tk=8.5.19=2
+- toolz=0.9.0=py_1
+- tornado=5.1.1=py36h1de35cc_1000
+- traitlets=4.3.2=py36_1000
+- utm=0.4.2=py36_0
+- vincent=0.4.4=py_1
+- wcwidth=0.1.7=py_1
+- webencodings=0.5.1=py_1
+- wheel=0.33.0=py36_0
+- widgetsnbextension=3.4.2=py36_1000
+- xmltodict=0.11.0=py_1
+- xz=5.2.4=h1de35cc_1001
+- zeromq=4.2.5=h0a44026_1006
+- zlib=1.2.11=h1de35cc_1004
+- blas=1.0=mkl
+- intel-openmp=2019.1=144
+- jupyter=1.0.0=py36_3
+- mkl=2017.0.4=h1fae6ae_0
+- numpy=1.12.1=py36_0
+- requests=2.14.2=py36_0
+- scikit-learn=0.18.1=np112py36_1
+- scipy=0.19.0=np112py36_0
+- pip:
+  - asn1crypto==0.24.0
+  - cffi==1.11.5
+  - cryptography==2.5
+  - ipython-genutils==0.2.0
+  - jupyter-client==5.2.4
+  - jupyter-console==5.2.0
+  - jupyter-core==4.4.0
+  - jwcrypto==0.4.2
+  - lxml==4.3.1
+  - prometheus-client==0.5.0
+  - prompt-toolkit==1.0.15
+  - pycparser==2.19
+  - pyfcm==1.4.3
+  - pygeocoder==1.2.5
+  - pykml==0.1.3
+  - pymongo==3.5.1
+  - requests-toolbelt==0.9.1
+prefix: /Users/shankari/OSS/anaconda/envs/emission-new
+
diff --git a/setup/environment36.notebook.yml b/setup/environment36.notebook.yml
new file mode 100644
index 00000000..9bfa55f5
--- /dev/null
+++ b/setup/environment36.notebook.yml
@@ -0,0 +1,35 @@
+name: emission
+channels:
+- conda-forge
+- defaults
+dependencies:
+- branca=0.2.0=py_1
+- folium=0.5.0=py_0
+- ipython=5.3.0=py36_0
+- jupyter=1.0.0=py36_3
+- arrow=0.12.1
+- attrdict=2.0.0
+- cheroot=6.2.*=py36_0
+- future=0.16.0
+- geojson=2.3.0
+- google-auth=1.2.1
+- jsonpickle=0.9.6
+- numpy=1.12.1=py36_0
+- pandas=0.20.1=np112py36_0
+- pip=9.0.1=py36_1
+- python=3.6.1=2
+- python-dateutil=2.6.0=py36_0
+- pytz=2017.2=py36_0
+- requests=2.14.2=py36_0
+- scikit-learn=0.18.1=np112py36_1
+- scipy=0.19.0=np112py36_0
+- sqlite=3.13.0
+- utm=0.4.2
+- xmltodict=0.11.0
+- pip:
+  - jwcrypto==0.4.2
+  - pyfcm==1.4.3
+  - pygeocoder==1.2.5
+  - pykml==0.1.3
+  - pymongo==3.5.1
+prefix: /Users/shankari/OSS/anaconda/envs/emission
diff --git a/setup/environment36.yml b/setup/environment36.yml
index ad0a513b..e5f3954d 100644
--- a/setup/environment36.yml
+++ b/setup/environment36.yml
@@ -3,219 +3,29 @@ channels:
 - conda-forge
 - defaults
 dependencies:
-- altair=1.2.1=py_0
-- branca=0.2.0=py_1
-- folium=0.5.0=py_0
-- vega=0.4.4=py36_1
-- vincent=0.4.4=py36_0
-- _license=1.1=py36_1
-- alabaster=0.7.10=py36_0
-- anaconda=4.4.0=np112py36_0
-- anaconda-client=1.6.3=py36_0
-- anaconda-navigator=1.6.2=py36_0
-- anaconda-project=0.6.0=py36_0
-- asn1crypto=0.22.0=py36_0
-- astroid=1.4.9=py36_0
-- astropy=1.3.2=np112py36_0
-- babel=2.4.0=py36_0
-- backports=1.0=py36_0
-- beautifulsoup4=4.6.0=py36_0
-- bitarray=0.8.1
-- blaze=0.10.1=py36_0
-- bleach=1.5.0=py36_0
-- bokeh=0.12.5=py36_1
-- boto=2.46.1=py36_0
-- bottleneck=1.2.1=np112py36_0
-- cffi=1.10.0=py36_0
-- chardet=3.0.3=py36_0
-- click=6.7=py36_0
-- cloudpickle=0.2.2=py36_0
-- clyent=1.2.2=py36_0
-- colorama=0.3.9=py36_0
-- contextlib2=0.5.5=py36_0
-- cryptography=1.8.1=py36_0
-- curl=7.52.1
-- cycler=0.10.0=py36_0
-- cython=0.25.2=py36_0
-- cytoolz=0.8.2=py36_0
-- dask=0.14.3=py36_1
-- datashape=0.5.4=py36_0
-- decorator=4.0.11=py36_0
-- distributed=1.16.3=py36_0
-- docutils=0.13.1=py36_0
-- entrypoints=0.2.2=py36_1
-- et_xmlfile=1.0.1=py36_0
-- fastcache=1.0.2=py36_1
-- flask=0.12.2=py36_0
-- flask-cors=3.0.2=py36_0
-- freetype=2.5.5
-- get_terminal_size=1.0.0=py36_0
-- gevent=1.2.1=py36_0
-- greenlet=0.4.12=py36_0
-- h5py=2.7.0=np112py36_0
-- heapdict=1.0.0=py36_1
-- html5lib=0.999=py36_0
-- idna=2.5=py36_0
-- imagesize=0.7.1=py36_0
-- ipykernel=4.6.1=py36_0
-- ipython=5.3.0=py36_0
-- ipython_genutils=0.2.0=py36_0
-- ipywidgets=6.0.0=py36_0
-- isort=4.2.5=py36_0
-- itsdangerous=0.24=py36_0
-- jdcal=1.3=py36_0
-- jedi=0.10.2=py36_2
-- jinja2=2.9.6=py36_0
-- jpeg=9b
-- jsonschema=2.6.0=py36_0
-- jupyter=1.0.0=py36_3
-- jupyter_client=5.0.1=py36_0
-- jupyter_console=5.1.0=py36_0
-- jupyter_core=4.3.0=py36_0
-- lazy-object-proxy=1.2.2=py36_0
-- libiconv=1.14
-- libpng=1.6.27
-- libtiff=4.0.6
-- libxml2=2.9.4
-- libxslt=1.1.29
-- llvmlite=0.18.0=py36_0
-- locket=0.2.0=py36_1
-- lxml=3.7.3=py36_0
-- markupsafe=0.23=py36_2
-- matplotlib=2.0.2=np112py36_0
-- mistune=0.7.4=py36_0
-- mkl=2017.0.1=0
-- mkl-service=1.1.2=py36_3
-- mpmath=0.19=py36_1
-- msgpack-python=0.4.8=py36_0
-- multipledispatch=0.4.9=py36_0
-- navigator-updater=0.1.0=py36_0
-- nbconvert=5.1.1=py36_0
-- nbformat=4.3.0=py36_0
-- networkx=1.11=py36_0
-- nltk=3.2.3=py36_0
-- nose=1.3.7=py36_1
-- notebook=5.0.0=py36_0
-- numba=0.33.0=np112py36_0
-- numexpr=2.6.2=np112py36_0
+- arrow=0.12.1
+- attrdict=2.0.0
+- cheroot=6.2.*=py36_0
+- future=0.16.0
+- geojson=2.3.0
+- google-auth=1.2.1
+- jsonpickle=0.9.6
 - numpy=1.12.1=py36_0
-- numpydoc=0.6.0=py36_0
-- odo=0.5.0=py36_1
-- olefile=0.44=py36_0
-- openpyxl=2.4.7=py36_0
-- openssl=1.0.2l
-- packaging=16.8=py36_0
 - pandas=0.20.1=np112py36_0
-- pandocfilters=1.4.1=py36_0
-- partd=0.3.8=py36_0
-- path.py=10.3.1=py36_0
-- pathlib2=2.2.1=py36_0
-- patsy=0.4.1=py36_0
-- pep8=1.7.0=py36_0
-- pexpect=4.2.1=py36_0
-- pickleshare=0.7.4=py36_0
-- pillow=4.1.1=py36_0
 - pip=9.0.1=py36_1
-- ply=3.10=py36_0
-- prompt_toolkit=1.0.14=py36_0
-- psutil=5.2.2=py36_0
-- py=1.4.33=py36_0
-- pycosat=0.6.2=py36_0
-- pycparser=2.17=py36_0
-- pycrypto=2.6.1=py36_6
-- pycurl=7.43.0=py36_2
-- pyflakes=1.5.0=py36_0
-- pygments=2.2.0=py36_0
-- pylint=1.6.4=py36_1
-- pyodbc=4.0.16=py36_0
-- pyopenssl=17.0.0=py36_0
-- pyparsing=2.1.4=py36_0
-- pyqt=5.6.0
-- pytest=3.0.7=py36_0
 - python=3.6.1=2
 - python-dateutil=2.6.0=py36_0
 - pytz=2017.2=py36_0
-- pywavelets=0.5.2=np112py36_0
-- pyyaml=3.12=py36_0
-- pyzmq=16.0.2=py36_0
-- qt=5.6.2
-- qtawesome=0.4.4=py36_0
-- qtconsole=4.3.0=py36_0
-- qtpy=1.2.1=py36_0
 - requests=2.14.2=py36_0
-- rope=0.9.4=py36_1
-- ruamel_yaml=0.11.14=py36_1
-- scikit-image=0.13.0=np112py36_0
 - scikit-learn=0.18.1=np112py36_1
 - scipy=0.19.0=np112py36_0
-- seaborn=0.7.1=py36_0
-- setuptools=27.2.0
-- simplegeneric=0.8.1=py36_1
-- singledispatch=3.4.0.3=py36_0
-- sip=4.18=py36_0
-- six=1.10.0=py36_0
-- snowballstemmer=1.2.1=py36_0
-- sortedcollections=0.5.3=py36_0
-- sortedcontainers=1.5.7=py36_0
-- sphinx=1.5.6=py36_0
-- spyder=3.1.4=py36_0
-- sqlalchemy=1.1.9=py36_0
 - sqlite=3.13.0
-- statsmodels=0.8.0=np112py36_0
-- sympy=1.0=py36_0
-- tblib=1.3.2=py36_0
-- testpath=0.3=py36_0
-- tk=8.5.18
-- toolz=0.8.2=py36_0
-- tornado=4.5.1=py36_0
-- traitlets=4.3.2=py36_0
-- unicodecsv=0.14.1=py36_0
-- wcwidth=0.1.7=py36_0
-- werkzeug=0.12.2=py36_0
-- wheel=0.29.0=py36_0
-- widgetsnbextension=2.0.0=py36_0
-- wrapt=1.10.10=py36_0
-- xlrd=1.0.0=py36_0
-- xlsxwriter=0.9.6=py36_0
-- xlwt=1.2.0=py36_0
-- xz=5.2.2
-- yaml=0.1.6=0
-- zict=0.1.2=py36_0
-- zlib=1.2.8
+- utm=0.4.2
+- xmltodict=0.11.0
 - pip:
-  - arrow==0.12.0
-  - attrdict==2.0.0
-  - backports.shutil-get-terminal-size==1.0.0
-  - cachetools==2.0.1
-  - certifi==2017.11.5
-  - cheroot==5.10.0
-  - enum34==1.1.6
-  - et-xmlfile==1.0.1
-  - future==0.16.0
-  - geojson==2.3.0
-  - google-auth==1.2.1
-  - ipython-genutils==0.2.0
-  - jaraco.classes==1.4.3
-  - jsonpickle==0.9.5
-  - jupyter-client==5.0.1
-  - jupyter-console==5.1.0
-  - jupyter-core==4.3.0
   - jwcrypto==0.4.2
-  - portend==2.2
-  - prompt-toolkit==1.0.14
-  - pyasn1==0.4.2
-  - pyasn1-modules==0.2.1
   - pyfcm==1.4.3
   - pygeocoder==1.2.5
   - pykml==0.1.3
   - pymongo==3.5.1
-  - python-crontab==2.2.7
-  - requests-toolbelt==0.8.0
-  - rope-py3k==0.9.4.post1
-  - rsa==3.4.2
-  - tables==3.3.0
-  - tempora==1.9
-  - urllib3==1.22
-  - utm==0.4.2
-  - xmltodict==0.11.0
 prefix: /Users/shankari/OSS/anaconda/envs/emission
diff --git a/setup/setup.sh b/setup/setup.sh
index fa174592..eafcc66c 100755
--- a/setup/setup.sh
+++ b/setup/setup.sh
@@ -6,4 +6,3 @@
 # - on Windows: C:/Users/<user>/Miniconda3/Scripts/conda
 conda env update --name emission --file setup/environment36.yml
 source activate emission
-pip install six --upgrade
diff --git a/setup/setup_nomkl.sh b/setup/setup_nomkl.sh
new file mode 100755
index 00000000..845e7a9a
--- /dev/null
+++ b/setup/setup_nomkl.sh
@@ -0,0 +1,8 @@
+# If the conda binary is not found, specify the full path to it
+# you can find it by searching for "conda" under the miniconda3 directory
+# typical paths are:
+# - on linux: /home/<user>/miniconda3/bin/conda
+# - on OSX: /Users/<user>/miniconda3/bin/conda
+# - on Windows: C:/Users/<user>/Miniconda3/Scripts/conda
+conda env update --name emission --file setup/environment36.nomkl.yml
+source activate emission
diff --git a/setup/setup_notebook.sh b/setup/setup_notebook.sh
new file mode 100755
index 00000000..21f24619
--- /dev/null
+++ b/setup/setup_notebook.sh
@@ -0,0 +1,9 @@
+# If the conda binary is not found, specify the full path to it
+# you can find it by searching for "conda" under the miniconda3 directory
+# typical paths are:
+# - on linux: /home/<user>/miniconda3/bin/conda
+# - on OSX: /Users/<user>/miniconda3/bin/conda
+# - on Windows: C:/Users/<user>/Miniconda3/Scripts/conda
+conda env update --name emission --file setup/environment36.yml
+conda env update --name emission --file setup/environment36.notebook.additions.yml
+source activate emission
diff --git a/setup/setup_tests.sh b/setup/setup_tests.sh
index 9d05e67e..c46bc1e0 100755
--- a/setup/setup_tests.sh
+++ b/setup/setup_tests.sh
@@ -7,7 +7,6 @@ echo "Check with 'conda -V'"
 echo "Upgrade with 'conda update conda' from the *root* environment"
 conda env create --prefix ${CONDA_TEMP_PREFIX} --file setup/environment36.yml
 source activate ${CONDA_TEMP_PREFIX}
-pip install six --upgrade
 python bin/deploy/habitica_conf.py
 python bin/deploy/push_conf.py
 python bin/deploy/model_copy.py
diff --git a/webapp/www/css/index.css b/webapp/www/css/index.css
new file mode 100644
index 00000000..a1d86889
--- /dev/null
+++ b/webapp/www/css/index.css
@@ -0,0 +1,179 @@
+body {
+	background: #eff2f2;
+}
+
+h1 { font-family: "EB Garamond"; font-size: 24px; font-style: normal; font-variant: normal; font-weight: 700; line-height: 26.4px; } h3 { font-family: "EB Garamond"; font-size: 14px; font-style: normal; font-variant: normal; font-weight: 700; line-height: 15.4px; } p { font-family: "EB Garamond"; font-size: 14px; font-style: normal; font-variant: normal; font-weight: 400; line-height: 20px; } blockquote { font-family: "EB Garamond"; font-size: 21px; font-style: normal; font-variant: normal; font-weight: 400; line-height: 30px; } pre { font-family: "EB Garamond"; font-size: 13px; font-style: normal; font-variant: normal; font-weight: 400; line-height: 18.5714px; }
+
+.top_bar {
+	display: flex;
+	flex-direction: row;
+	justify-content: space-between;
+}
+
+.item {
+	font-family: "EB Garamond"; 
+	font-size: 20px; 
+	font-style: normal; 
+	font-variant: normal; 
+	color: #204f2f;
+	margin-top: 30px;
+	font-weight: bold;
+}
+
+#logo {
+	margin-top: -10px;
+}
+
+.button {
+	width: 175px;
+	height: 30px;
+	border-width: .5px;
+	border: solid;
+	border-color: #204f2f;
+	font-family: "EB Garamond";
+	color: #204f2f;
+	font-size: 24px; 
+	text-align: center; 
+	justify-content: center;
+	margin-top: 15px;
+	display: inline-block;
+	padding: 5px;
+	/*font-weight: bold; */
+}
+
+.big_box {
+	background-color: #FFEDC2;
+	position: absolute; /* or absolute */
+  	width: 900px;
+  	height: 400px;
+  	text-align: center; 
+  	opacity: .7;
+  	left: 10%;
+
+}
+
+.large_text {
+	font-family: "EB Garamond";
+	font-size: 80px;
+	font-weight: .1;
+	margin-top: 75px;
+	opacity: 1;
+}
+
+.smaller_text {
+	font-family: "EB Garamond";
+	font-size: 20px;
+	margin-top: 30px;
+	opacity: 1;
+}
+
+#learn {
+	width: 300px;
+	margin-top: 30px;
+	color: black;
+	border-color: black;
+	font-weight: bold;
+	opacity: 1;
+}
+
+.background_image {
+	margin-top: 100px;
+	margin-left: 60px;
+}
+
+#contact {
+	left: 40%;
+	position: absolute;
+}
+
+#second_page {
+	background-color: #278e29;
+	opacity: .8;
+	height: 400px;
+}
+
+#learn_image {
+	margin-top: 150px;
+}
+
+#large_text_1 {
+	margin-top: 30px;
+}
+
+#incentive_box {
+	height: 500px;
+	background-color: rgba(82, 41, 165, 0.6);
+}
+
+#incentive_image {
+	margin-top: 175px;
+}
+
+#large_text_2 {
+	margin-top: 20px;
+}
+
+a {
+	text-decoration: none;
+	color: #204f2f;
+}
+
+div.button a {
+	color: black;
+}
+
+div.smaller_text a {
+	text-decoration: none;
+	color: black;
+}
+
+.student_info {
+	display: flex;
+	margin: 20px;
+	background-color: #FFEDC2;
+}
+
+.text {
+	display: flex;
+	flex-direction: column;
+}
+
+#large_text_3 {
+	margin-top: 10px;
+	margin-left: 30%;
+}
+
+.name {
+	font-family: "EB Garamond";
+	font-size: 40px;
+	margin-left: 30px;
+}
+
+.background {
+	font-family: "EB Garamond";
+	margin-left: 30px;
+	font-size: 20px;
+}
+
+#large_text_4 {
+	margin-top: 20px;
+}
+
+#support_box {
+	height: 450px;
+	background-color: rgb(96, 207, 247);
+}
+
+#related_work {
+	background-color: rgb(98, 135, 52);
+
+}
+
+#bears {
+	margin-top: 20px;
+}
+
+a:visited { text-decoration: none; color: #204f2f;}
+a:hover { text-decoration: none; color: #204f2f;}
+a:focus { text-decoration: none; color: #204f2f;}
+a:hover, a:active { text-decoration: none; color: #204f2f;}
\ No newline at end of file
diff --git a/webapp/www/img/bill.jpg b/webapp/www/img/bill.jpg
new file mode 100644
index 00000000..16eaae91
Binary files /dev/null and b/webapp/www/img/bill.jpg differ
diff --git a/webapp/www/img/client-setup-background.jpg b/webapp/www/img/client-setup-background.jpg
new file mode 100644
index 00000000..421bc23f
Binary files /dev/null and b/webapp/www/img/client-setup-background.jpg differ
diff --git a/webapp/www/img/emma.jpg b/webapp/www/img/emma.jpg
new file mode 100644
index 00000000..2cbc7785
Binary files /dev/null and b/webapp/www/img/emma.jpg differ
diff --git a/webapp/www/img/greentrip_logo.png b/webapp/www/img/greentrip_logo.png
new file mode 100644
index 00000000..7efe1ed5
Binary files /dev/null and b/webapp/www/img/greentrip_logo.png differ
diff --git a/webapp/www/img/greentrip_qr_code_as.png b/webapp/www/img/greentrip_qr_code_as.png
new file mode 100644
index 00000000..2ce0d413
Binary files /dev/null and b/webapp/www/img/greentrip_qr_code_as.png differ
diff --git a/webapp/www/img/greentrip_qr_code_gp.png b/webapp/www/img/greentrip_qr_code_gp.png
new file mode 100644
index 00000000..927f7b59
Binary files /dev/null and b/webapp/www/img/greentrip_qr_code_gp.png differ
diff --git a/webapp/www/img/incentive_image.jpg b/webapp/www/img/incentive_image.jpg
new file mode 100644
index 00000000..fb926b76
Binary files /dev/null and b/webapp/www/img/incentive_image.jpg differ
diff --git a/webapp/www/img/join_study.png b/webapp/www/img/join_study.png
new file mode 100644
index 00000000..bbf85b81
Binary files /dev/null and b/webapp/www/img/join_study.png differ
diff --git a/webapp/www/img/join_study_control.png b/webapp/www/img/join_study_control.png
new file mode 100644
index 00000000..0f541071
Binary files /dev/null and b/webapp/www/img/join_study_control.png differ
diff --git a/webapp/www/img/learn_more_image.jpg b/webapp/www/img/learn_more_image.jpg
new file mode 100644
index 00000000..63eba94b
Binary files /dev/null and b/webapp/www/img/learn_more_image.jpg differ
diff --git a/webapp/www/img/polar_bears.jpg b/webapp/www/img/polar_bears.jpg
new file mode 100644
index 00000000..2b9e0029
Binary files /dev/null and b/webapp/www/img/polar_bears.jpg differ
diff --git a/webapp/www/img/related_work.jpg b/webapp/www/img/related_work.jpg
new file mode 100644
index 00000000..53cdc75f
Binary files /dev/null and b/webapp/www/img/related_work.jpg differ
diff --git a/webapp/www/img/samantha.JPG b/webapp/www/img/samantha.JPG
new file mode 100644
index 00000000..2008fa1b
Binary files /dev/null and b/webapp/www/img/samantha.JPG differ
diff --git a/webapp/www/img/sf_background.jpg b/webapp/www/img/sf_background.jpg
new file mode 100644
index 00000000..0be5878d
Binary files /dev/null and b/webapp/www/img/sf_background.jpg differ
diff --git a/webapp/www/img/shankari.jpg b/webapp/www/img/shankari.jpg
new file mode 100644
index 00000000..530cf35f
Binary files /dev/null and b/webapp/www/img/shankari.jpg differ
diff --git a/webapp/www/img/supporters.jpg b/webapp/www/img/supporters.jpg
new file mode 100644
index 00000000..45cb80b8
Binary files /dev/null and b/webapp/www/img/supporters.jpg differ
diff --git a/webapp/www/img/trevor.jpg b/webapp/www/img/trevor.jpg
new file mode 100644
index 00000000..1f3623ce
Binary files /dev/null and b/webapp/www/img/trevor.jpg differ
diff --git a/webapp/www/img/vanessa.jpg b/webapp/www/img/vanessa.jpg
new file mode 100644
index 00000000..295ebdca
Binary files /dev/null and b/webapp/www/img/vanessa.jpg differ
diff --git a/webapp/www/index.html b/webapp/www/index.html
index c24fae0a..1776669f 100644
--- a/webapp/www/index.html
+++ b/webapp/www/index.html
@@ -1,83 +1,21 @@
-<!DOCTYPE html>
 <html>
-  <head>
-    <meta charset="utf-8">
-    <meta name="viewport" content="initial-scale=1, maximum-scale=1, user-scalable=no, width=device-width">
-    <title></title>
-    
-    <link rel="shortcut icon" type="image/x-icon" href="img/favicon-96x96.png">
-    <link href="lib/ionic/css/ionic.css" rel="stylesheet">
-    <link href="css/style.css" rel="stylesheet">
-    <link href="css/redirect.css" rel="stylesheet">
-    <link href="css/home.css" rel="stylesheet">
-    <link href="lib/leaflet/dist/leaflet.css" rel="stylesheet">
-    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">
-    <link href='https://fonts.googleapis.com/css?family=Roboto:400,700,500,300' rel='stylesheet' type='text/css'>
-    <link rel="stylesheet" href="lib/nvd3/build/nv.d3.css">
-    <!-- IF using Sass (run gulp sass first), then uncomment below and remove the CSS includes above
-    <link href="css/ionic.app.css" rel="stylesheet">
-    -->
-
-    <!-- ionic/angularjs js -->
-    <script src="lib/ionic/js/ionic.bundle.js"></script>
-
-    <!-- other javascript libraries -->
-    <script src="lib/moment/min/moment.min.js"></script>
-    <script src="lib/angular-simple-logger/dist/angular-simple-logger.js"></script>
-    <script src="lib/leaflet/dist/leaflet.js"></script>
-    <script src="lib/ui-leaflet/dist/ui-leaflet.min.js"></script>
-    <script src="lib/simple-leaflet-plugins/leaflet-heat.js"></script>
-    <script src="lib/angular-bootstrap/ui-bootstrap-tpls.min.js"></script>
-    <script src="lib/d3/d3.js"></script>
-    <script src="lib/nvd3/build/nv.d3.js"></script> <!-- or use another assembly -->
-    <script src="lib/angular-nvd3/dist/angular-nvd3.js"></script>
-    <script src="lib/qrcode-generator/js/qrcode.js"></script>
-    <script src="lib/qrcode-generator/js/qrcode_UTF8.js"></script>
-    <script src="lib/angular-qrcode/angular-qrcode.js"></script>
-
-    <!-- cordova script (this will be a 404 during development) -->
-    <script src="cordova.js"></script>
-
-    <!-- your app's js -->
-    <script src="js/logger.js"></script>
-    <script src="js/incident/post-trip-manual.js"></script>
-    <script src="js/app.js"></script>
-    <script src="js/controllers.js"></script>
-    <script src="js/services.js"></script>
-    <script src="js/directives.js"></script>
-    <script src="js/heatmap.js"></script>
-    <script src="js/metrics.js"></script>
-  </head>
-  <body ng-app="starter">
-    <!--
-      The nav bar that will be updated as we navigate between views.
-    -->
-    <ion-nav-bar class="bar-position">
-      <ion-nav-buttons side="left">
-        <button class="button button-icon" ui-sref="home">
-        <i class="icon-left ion-home"></i> Home
-        </button>
-        <button class="button button-icon" ui-sref="heatmap">
-            <i class="icon-left ion-fireball"></i> Analysis
-        </button>
-        <button class="button button-icon" ui-sref="metrics">
-            <i class="icon-left ion-ios-analytics"></i> Metrics
-        </button>
-        <button class="button button-icon" ui-sref="trip-planning">
-            <i class="icon-left ion-android-compass"></i> Trip Planning
-        </button>
-        <button class="button button-icon" ui-sref="game">
-            <i class="icon-left ion-checkmark"></i> Game
-        </button>
-      </ion-nav-buttons-->
-    </ion-nav-bar>
-      <!--ion-nav-back-button>
-      </ion-nav-back-button-->
-    <!--
-      The views will be rendered in the <ion-nav-view> directive below
-      Templates are in the /templates folder (but you could also
-      have templates inline in this html file if you'd like).
-    -->
-    <ion-nav-view></ion-nav-view>
-  </body>
-</html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "templates/index_copy.html"> <img src = "img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "templates/incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "templates/who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "templates/supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "templates/related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "templates/client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	</head>
+	<div class = "big_box"> 
+		<div class = "large_text"> An Emission Study </div>
+		<div class = "smaller_text"> Sustainable suggestions. Decreasing carbon emissions. </div>
+		<div class = "button" id = "learn"> <a href = "templates/learn_more.html"> LEARN MORE </a> </div>
+	</div>
+	<div class = "background_image"> <img src = "img/sf_background.jpg" style = "width: 95%; height: 400px;"> </div>
+	<div class = "button" id = "contact"> <a href = "templates/contact.html"> CONTACT US </a> </div>
+</html>
\ No newline at end of file
diff --git a/webapp/www/js/client_setup.js b/webapp/www/js/client_setup.js
new file mode 100644
index 00000000..9812fb7f
--- /dev/null
+++ b/webapp/www/js/client_setup.js
@@ -0,0 +1,18 @@
+$(document).ready(function(){
+        var group = 0;
+        var min = 1;
+        var max = 3;
+        var group = Math.floor(Math.random() * (+max - +min)) + +min;
+        console.log(group);
+
+        if (group == 1) {
+                // Then experimental group
+                document.getElementById("join_link").href = "emission://change_client?new_client=greentrip&clear_local_storage=true&clear_usercache=true";
+                $("#customize").attr("src", "../img/join_study.png");
+        } else {
+                document.getElementById("join_link").href = "emission://change_client?new_client=greentripcontrol&clear_local_storage=true&clear_usercache=true";
+                $("#customize").attr("src", "../img/join_study_control.png");
+        };
+
+});
+
diff --git a/webapp/www/templates/client_setup.html b/webapp/www/templates/client_setup.html
index b071de5e..f65f8d1f 100644
--- a/webapp/www/templates/client_setup.html
+++ b/webapp/www/templates/client_setup.html
@@ -1,17 +1,39 @@
 <ion-view view-title="Setup">
   <ion-content>
+  <link rel="stylesheet" type="text/css" href="../css/index.css">
+  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+  <div class = "top_bar">
+      <div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+      <div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+      <div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+      <div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+      <div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+      <div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+  </div>
+
       <div class="redirect">
         <div>
-          <img id="logo" alt="{{base_app}} logo" ng-src="img/{{base_app}}-icon-96x96.png">
+          <img id="logo" ng-src="img/favicon-96x96.png">
         </div>
-        <div>
-          <h2>Thank you for participating - only two steps left!</h2>
+        <div class = "background_image"> <img src = "../img/client-setup-background.jpg" style = "width: 95%; height: 400px;"> </div>
+
+        <div style="padding: 5%">
+          <h2>
+            <div class = "large_text" id = "large_text_2">
+              Thank you for participating - only two steps left!
+            </div>
+          </h2>
+
           <p>
-            Please open the links below <b>on your phone</b>, or read the QR codes from a laptop display using a QR code reader <b>on your phone.</b>
+            <div style="font-family: EB Garamond; font-size: 50">
+              In order to join the study, you must first download our app [step 1] and then you can click our link [in step 2].</h3>
+            </div>
           </p>
         </div>
-        <div>
-          <svg aria-label="Step 1" width="58px" height="49px" viewBox="0 0 58 49" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
+
+        <div style="padding-left: 5%; padding-bottom: 2%">
+          <svg width="58px" height="49px" viewBox="0 0 58 49" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
               <!-- Generator: Sketch 43.1 (39012) - http://www.bohemiancoding.com/sketch -->
               <desc>Created with Sketch.</desc>
               <defs></defs>
@@ -26,20 +48,62 @@
                   </g>
               </g>
           </svg>
-        <h4>Install the {{base_app}} app</h4>
-        </div>
-        <div class="row responsive-sm">
-          <a class="col" href='{{android_base_app}}'><img style="height:75px;" alt='Get it on Google Play' src='https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png'/></a>
-          <qrcode class="col" aria-label="qrcode for google play installation" data="{{android_base_app}}" size="200"></qrcode>
-            <!-- <br style="clear:both;"/> -->
+
+        <h4>
+          <div style="font-family: EB Garamond; font-size: 40px;">
+            Install the emTripLog app
+          </div>
+        </h4>
+
+        <div style="font-family: EB Garamond; font-size: 30px;">
+          Click on the AppStore or Google Play logos to download the app.
         </div>
-        <div class="row responsive-sm">
-          <a class="col" href="{{ios_base_app}}"><img alt='Get it on the iOS app store' ng-src="img/apple-badge.svg"></a>
-          <qrcode class="col" aria-label="qrcode for iOS app store installation" data="{{ios_base_app}}" size="200"></qrcode>
-            <!-- <br style="clear:both;"/> -->
-        </div>
-        <div>
-          <svg aria-label="Step 2" width="58px" height="49px" viewBox="0 0 58 49" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
+      </div>
+
+      <div style="padding-left: 5%">
+        <table style="width:50%">
+        <tr>
+          <th>
+            <h4 style="font-family: EB Garamond; font-size: 30px">
+              Android Devices
+            </h4>
+          </th>
+
+          <th>
+            <h4 style="font-family: EB Garamond; font-size: 30px">
+              Apple Devices
+            </h4>
+          </th>
+        </tr>
+
+        <tr>
+          <td>
+            <center>
+              <div class="row responsive-sm" style="margin-bottom: 20px;">
+                <a class="col" href='https://play.google.com/store/apps/details?id=edu.berkeley.eecs.embase'><img style="height:75px;" alt='Get it on Google Play'  src='https://play.google.com/intl/en_us/badges/images/generic/en_badge_web_generic.png'/></a>
+                <p><img src = "../img/greentrip_qr_code_gp.png"></p>
+                <!-- <br style="clear:both;"/> -->
+              </div>
+            </center>
+          </td>
+
+          <td>
+            <center>
+              <div class="row responsive-sm" style="margin-bottom: 20px">
+                <a class="col" href="https://itunes.apple.com/us/app/emtriplog/id1362434685"><img style="height:75px;" alt='Get in on the iOS app store' ng-src = "../img/apple_badge.svg" src='../img/apple-badge.svg'/></a>
+                <qrcode class="col" data="https://itunes.apple.com/us/app/emtriplog/id1362434685" size="200"></qrcode>
+                <!-- <br style="clear:both;"/> -->
+                <p><img src = "../img/greentrip_qr_code_as.png"></p>
+              </div>
+            </center>
+          </td>
+
+        </tr>
+        </table>
+      </div>
+
+        <div style="padding-left: 5%; padding-top: 3%">
+          <svg width="58px" height="49px" viewBox="0 0 58 49" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
               <!-- Generator: Sketch 43.1 (39012) - http://www.bohemiancoding.com/sketch -->
               <desc>Created with Sketch.</desc>
               <defs></defs>
@@ -54,17 +118,42 @@
                   </g>
               </g>
           </svg>
-          <h4>Join this study</h4>
+            <h4>
+              <div style="font-size: 40">
+                Join this study
+              </div>
+            </h4>
         </div>
-        <div id="downloadRow">
-          <a id="groupLink" href="emission://change_client?new_client={{client_label}}&clear_local_storage={{clear_local_storage_flag}}&clear_usercache={{clear_usercache_flag}}">
-            <p style="color: #417505;">Open this link on your phone to launch the app and join the study</p>
-            <p style="color: black;">emission://change_client?new_client={{client_label}}&clear_local_storage={{clear_local_storage_flag}}&clear_usercache={{clear_usercache_flag}}</p>
-          </a>
+
+
+        <div id="downloadRow" style="padding-left: 5%">
+          <div style="font-size: 30">
+            When you have the app installed, you can press the "Join" button below on mobile. This will take you to the app to begin the study. <b>If you are on this website on your computer, you must scan the QR code below directly from your emTripLog app to join. </b> The app has a QR scanner to use.
+          </div>
+
+          <p> <div class = "button">
+          <div>
+            <a id="join_link" href="jschooses">
+              Join for mobile
+            </a>
+           </div>
+          </div> </p>
+
         </div>
-        <div>
-          <qrcode class="col" aria-label="qrcode to join the study" data="emission://change_client?new_client={{client_label}}&clear_local_storage={{clear_local_storage_flag}}&clear_usercache={{clear_usercache_flag}}" size="200"></qrcode>
+
+        <div style ="padding-left: 5%">
+          <qrcode class="col" data="emission://change_client?new_client={{greentrip}}&clear_local_storage={{clear_local_storage_flag}}&clear_usercache={{clear_usercache_flag}}" size="200"></qrcode>
+          <img id = "customize" src = "../img/join_study.png">
         </div>
       </div>
+      <!-- https://youtu.be/CV1rGkRn9xM video displaying qr code testing -->
+      <div class = "button" id = "contact"> <a href = "contact.html"> CONTACT US </a> </div>
+
+      <div style="padding-bottom: 5%">
+      </div>
+
   </ion-content>
+  <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min.js"></script>
+  <script src="../js/client_setup.js"></script>
 </ion-view>
+
diff --git a/webapp/www/templates/contact.html b/webapp/www/templates/contact.html
new file mode 100644
index 00000000..4a49941f
--- /dev/null
+++ b/webapp/www/templates/contact.html
@@ -0,0 +1,23 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+
+	<div class = "large_text" id = "large_text_3"> Contact Us </div>
+
+	<div class = "button" style = "margin-left: 39%"> <a href="mailto:greentrip@lists.eecs.berkeley.edu"> Link to Email </a> </div>
+
+	<div class = "background_image" id = "bears"> <img src = "../img/polar_bears.jpg" style = "width: 95%; height: 400px;"> </div>
+
+
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/incentive.html b/webapp/www/templates/incentive.html
new file mode 100644
index 00000000..fa2a497c
--- /dev/null
+++ b/webapp/www/templates/incentive.html
@@ -0,0 +1,24 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+	<div class = "big_box" id = "incentive_box"> 
+		<div class = "large_text" id = "large_text_2"> Incentivization </div>
+		<div class = "smaller_text"> <i class="fas fa-smile"></i> All participants will receive $10, given out in doses of $5 per month </div>
+		<div class = "smaller_text"> <i class="fas fa-smile"></i> This is contingent on the fact that the user continues to use the application and have it downloaded for the full 2 months of the study </div>
+		<div class = "smaller_text"> <i class="fas fa-smile"></i> Greentrip will also hopefully encourage users to take up less carbon emissions, so another incentive is saving the environment, making the world a better place on application at a time</div>
+		<div class = "button" id = "learn"> <a href = "learn_more.html"> LEARN MORE </a> </div>
+	</div>
+	<div class = "background_image" id = "incentive_image"> <img src = "../img/incentive_image.jpg" style = "width: 95%; height: 400px;"> </div>
+	<div class = "button" id = "contact"> <a href = "contact.html"> CONTACT US </a> </div>
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/index_copy.html b/webapp/www/templates/index_copy.html
new file mode 100644
index 00000000..d6254858
--- /dev/null
+++ b/webapp/www/templates/index_copy.html
@@ -0,0 +1,21 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	</head>
+	<div class = "big_box"> 
+		<div class = "large_text"> An Emission Study </div>
+		<div class = "smaller_text"> Sustainable suggestions. Decreasing carbon emissions. </div>
+		<div class = "button" id = "learn"> <a href = "learn_more.html"> LEARN MORE </a> </div>
+	</div>
+	<div class = "background_image"> <img src = "../img/sf_background.jpg" style = "width: 95%; height: 400px;"> </div>
+	<div class = "button" id = "contact"> <a href = "contact.html"> CONTACT US </a> </div>
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/learn_more.html b/webapp/www/templates/learn_more.html
new file mode 100644
index 00000000..24116135
--- /dev/null
+++ b/webapp/www/templates/learn_more.html
@@ -0,0 +1,24 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond">
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+	<div class = "big_box" id = "second_page"> 
+		<div class = "large_text" id = "large_text_1"> Learn More </div>
+		<div class = "smaller_text"> <i class="fas fa-leaf"></i> Greentrip is a study examining how sustainable information affects travel behavior.  </div>
+		<div class = "smaller_text"> <i class="fas fa-leaf"></i> Users will also be given surveys regarding their transportation patterns and opinions on the application. </div>
+		<div class = "smaller_text"> <i class="fas fa-leaf"></i> The experiment will run for approximately 2 months and there will be compensation for all participants
+  </div>
+	</div>
+	<div class = "background_image" id = "learn_image"> <img src = "../img/learn_more_image.jpg" style = "width: 95%; height: 400px;"> </div>
+	<div class = "button" id = "contact"> <a href = "contact.html"> CONTACT US </a> </div>
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/related_work.html b/webapp/www/templates/related_work.html
new file mode 100644
index 00000000..829fc3f4
--- /dev/null
+++ b/webapp/www/templates/related_work.html
@@ -0,0 +1,23 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+	<div class = "big_box" id = "related_work">
+		<div class = "large_text" id = "large_text_1"> Related Work </div> 
+		<div class = "smaller_text"> The previous group working with the emission study used polar bears as a representation of the emotional connectivity to reducing our environmental impact and used a simple suggestion system as a representation of informative connectivity. The suggestion system used for Greentrip was largely based on the previous group's suggestion system model.
+ 		</div>
+ 		<div class = "smaller_text"> <a href = "https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-2.html"> https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-2.html </a> </div>
+	</div>
+	<div class = "background_image" id = "learn_image"> <img src = "../img/related_work.jpg" style = "width: 95%; height: 400px;"> </div>
+
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/supporters.html b/webapp/www/templates/supporters.html
new file mode 100644
index 00000000..9728891a
--- /dev/null
+++ b/webapp/www/templates/supporters.html
@@ -0,0 +1,27 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+	<div class = "big_box" id = "support_box"> 
+		<div class = "large_text" id = "large_text_4"> Supporters </div>
+		<div class = "smaller_text"> <i class="fas fa-handshake"></i> Greentrip is a project based on the emission platform (<a href = "https://github.com/e-mission"> https://github.com/e-mission </a>) and is the second study conducted at UC Berkeley involving it </div>
+		<div class = "smaller_text"> <i class="fas fa-handshake"></i> 
+		Greentrip was a project developed by students working in the UC Berkeley <a href = "https://rise.cs.berkeley.edu/"> RISE Lab </a>
+		</div>
+		<div class = "smaller_text"> <i class="fas fa-handshake"></i> Special thanks to David Culler, and Krista Schnell for assisting in experimental design and providing feedback  
+ 		</div>
+		<div class = "button" id = "learn"> <a href = "learn_more.html"> LEARN MORE </a> </div>
+	</div>
+<div class = "background_image"> <img src = "../img/supporters.jpg" style = "width: 95%; height: 400px;"> </div>
+<div class = "button" id = "contact"> <a href = "contact.html"> CONTACT US </a> </div>
+</html>
\ No newline at end of file
diff --git a/webapp/www/templates/who_we_are.html b/webapp/www/templates/who_we_are.html
new file mode 100644
index 00000000..1f5212f9
--- /dev/null
+++ b/webapp/www/templates/who_we_are.html
@@ -0,0 +1,61 @@
+<html>
+	<head>
+		<div class = "top_bar">
+			<div class = "item" id = "logo"> <a href = "index_copy.html"> <img src = "../img/greentrip_logo.png" style = "width:150px; height:100px;"> </a> </div>
+			<div class = "item"> <a href = "incentive.html"> Incentivization </a> </div>
+			<div class = "item"> <a href = "who_we_are.html"> Who We Are </a> </div>
+			<div class = "item"> <a href = "supporters.html"> Supporters </a> </div>
+			<div class = "item"> <a href = "related_work.html"> Related Works </a> </div>
+			<div class = "button"> <a href = "client_setup.html"> JOIN STUDY </a> </div>
+		</div>
+	<link rel="stylesheet" type="text/css" href="../css/index.css">
+	<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=EB+Garamond" />
+	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
+	</head>
+	<div class = "large_text" id = "large_text_3"> Who We Are </div>
+	<div class = "student_info">
+		<img src = "../img/vanessa.jpg" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> Vanessa Lin</div>
+			<div class = "background"> Vanessa is a second year computer science major studying at UC Berkeley. Vanessa was in charge of setting up the suggestion system and the back-end development of the study. Vanessa will be working as an Engineering Practicum intern at Google this upcoming summer. </div>
+		</div>
+	</div>
+	<div class = "student_info">
+		<img src = "../img/trevor.jpg" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> Trevor Wu</div>
+			<div class = "background"> Trevor is a second year Civil Engineering and EECS student at UC Berkeley. He was in charge of front-end setup, testing, and developing some front-end features. Trevor has previously worked for the San Francisco Municipal Transportation Agency as a student design intern. </div>
+		</div>
+	</div>
+	<div class = "student_info">
+		<img src = "../img/emma.jpg" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> Emma Vickery</div>
+			<div class = "background"> Emma is a second year Electrical Engineering and Computer Science major studying at UC Berkeley. Emma was in charge of server setup, maintenance and system debugging. She will be working as a software development engineer intern at Amazon this upcoming summer. </div>
+		</div>
+	</div>
+	<div class = "student_info">
+		<img src = "../img/bill.jpg" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> Bill Cao</div>
+			<div class = "background"> Bill is a second year computer science major with a public policy minor studying at UC Berkeley. Bill was in charge of various tasks including funding and some server setup. He will be working as a software engineering intern at Blend Labs this upcoming summer. </div>
+		</div>
+	</div>
+	<div class = "student_info">
+		<img src = "../img/samantha.JPG" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> Samantha Banchik</div>
+			<div class = "background"> Samantha is a third year computer science major studying at UC Berkeley. She was in charge of some server setup, but largely front-end integration. Samantha will be working as a software engineering intern at Uber this upcoming summer.  </div>
+		</div>
+	</div>
+	<div class = "student_info">
+		<img src = "../img/shankari.jpg" style = "width: 100px%; height: 150px;">
+		<div class = "text">
+			<div class = "name"> K. Shankari </div>
+			<div class = "background"> Shankari is a PhD candidate in EECS with a designated emphasis in Global Metropolitan Studies. She is the maintainer and primary contributor to the e-mission platform, which was used for this study. Her overarching goal is to mainstream and democratize sustainable transportation and planning. </div>
+		</div>
+	</div>
+
+
+	</div>
+</html>
\ No newline at end of file
